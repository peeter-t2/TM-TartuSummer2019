startsecond	text
12.787	America's favorite pie is?
16.632	Audience: Apple.
16.632	Kenneth Cukier: Apple. Of course it is.
20.138	How do we know it?
21.369	Because of data.
24.122	You look at supermarket sales.
26.188	You look at supermarket
26.188	sales of 30-centimeter pies
29.054	that are frozen, and apple wins, no contest.
33.129	The majority of the sales are apple.
38.309	But then supermarkets started selling
41.273	smaller, 11-centimeter pies,
43.856	and suddenly, apple fell to fourth or fifth place.
48.03	Why? What happened?
50.905	Okay, think about it.
53.723	When you buy a 30-centimeter pie,
57.571	the whole family has to agree,
59.832	and apple is everyone's second favorite.
63.623	(Laughter)
65.558	But when you buy an individual 11-centimeter pie,
69.173	you can buy the one that you want.
72.918	You can get your first choice.
76.933	You have more data.
78.574	You can see something
80.128	that you couldn't see
81.26	when you only had smaller amounts of it.
85.213	Now, the point here is that more data
87.688	doesn't just let us see more,
89.971	more of the same thing we were looking at.
91.825	More data allows us to see new.
95.438	It allows us to see better.
98.532	It allows us to see different.
102.188	In this case, it allows us to see
105.361	what America's favorite pie is:
108.274	not apple.
110.816	Now, you probably all have heard the term big data.
114.43	In fact, you're probably sick of hearing the term
116.487	big data.
118.117	It is true that there is a lot of hype around the term,
121.447	and that is very unfortunate,
123.779	because big data is an extremely important tool
126.825	by which society is going to advance.
130.559	In the past, we used to look at small data
134.12	and think about what it would mean
135.824	to try to understand the world,
137.32	and now we have a lot more of it,
139.311	more than we ever could before.
142.033	What we find is that when we have
143.91	a large body of data, we can fundamentally do things
146.634	that we couldn't do when we
146.634	only had smaller amounts.
149.91	Big data is important, and big data is new,
152.551	and when you think about it,
154.328	the only way this planet is going to deal
156.544	with its global challenges —
158.333	to feed people, supply them with medical care,
161.87	supply them with energy, electricity,
164.68	and to make sure they're not burnt to a crisp
166.469	because of global warming —
167.707	is because of the effective use of data.
171.902	So what is new about big 
171.902	data? What is the big deal?
175.772	Well, to answer that question, let's think about
178.289	what information looked like,
180.185	physically looked like in the past.
183.219	In 1908, on the island of Crete,
186.83	archaeologists discovered a clay disc.
191.565	They dated it from 2000 B.C., so it's 4,000 years old.
195.624	Now, there's inscriptions on this disc,
197.628	but we actually don't know what it means.
198.955	It's a complete mystery, but the point is that
201.053	this is what information used to look like
202.981	4,000 years ago.
205.07	This is how society stored
207.618	and transmitted information.
211.142	Now, society hasn't advanced all that much.
215.302	We still store information on discs,
218.776	but now we can store a lot more information,
221.96	more than ever before.
223.22	Searching it is easier. Copying it easier.
226.313	Sharing it is easier. Processing it is easier.
229.813	And what we can do is we can reuse this information
232.579	for uses that we never even imagined
234.413	when we first collected the data.
237.608	In this respect, the data has gone
239.86	from a stock to a flow,
243.392	from something that is stationary and static
247.33	to something that is fluid and dynamic.
250.939	There is, if you will, a liquidity to information.
254.962	The disc that was discovered off of Crete
258.436	that's 4,000 years old, is heavy,
262.2	it doesn't store a lot of information,
264.162	and that information is unchangeable.
267.278	By contrast, all of the files
271.289	that Edward Snowden took
273.15	from the National Security
273.15	Agency in the United States
275.771	fits on a memory stick
278.19	the size of a fingernail,
281.2	and it can be shared at the speed of light.
285.945	More data. More.
291.2	Now, one reason why we have
291.2	so much data in the world today
293.174	is we are collecting things
294.606	that we've always collected information on,
297.886	but another reason why is we're taking things
300.542	that have always been informational
303.354	but have never been rendered into a data format
305.84	and we are putting it into data.
308.259	Think, for example, the question of location.
311.567	Take, for example, Martin Luther.
313.816	If we wanted to know in the 1500s
315.413	where Martin Luther was,
318.08	we would have to follow him at all times,
320.172	maybe with a feathery quill and an inkwell,
322.309	and record it,
323.985	but now think about what it looks like today.
326.168	You know that somewhere,
328.29	probably in a telecommunications carrier's database,
330.736	there is a spreadsheet or at least a database entry
333.772	that records your information
335.86	of where you've been at all times.
337.923	If you have a cell phone,
339.283	and that cell phone has GPS,
339.283	but even if it doesn't have GPS,
342.13	it can record your information.
344.515	In this respect, location has been datafied.
348.599	Now think, for example, of the issue of posture,
353.2	the way that you are all sitting right now,
354.485	the way that you sit,
356.515	the way that you sit, the way that you sit.
359.286	It's all different, and it's a function of your leg length
361.363	and your back and the contours of your back,
363.456	and if I were to put sensors, 
363.456	maybe 100 sensors
365.987	into all of your chairs right now,
367.753	I could create an index that's fairly unique to you,
371.353	sort of like a fingerprint, but it's not your finger.
375.762	So what could we do with this?
378.731	Researchers in Tokyo are using it
381.128	as a potential anti-theft device in cars.
385.516	The idea is that the carjacker sits behind the wheel,
388.44	tries to stream off, but the car recognizes
390.544	that a non-approved driver is behind the wheel,
392.906	and maybe the engine just stops, unless you
395.07	type in a password into the dashboard
398.247	"to say, ""Hey, I have authorization to drive."" Great."
402.905	What if every single car in Europe
405.458	had this technology in it?
406.915	What could we do then?
410.08	Maybe, if we aggregated the data,
412.32	maybe we could identify telltale signs
416.134	that best predict that a car accident
418.843	is going to take place in the next five seconds.
424.736	And then what we will have datafied
427.293	is driver fatigue,
429.076	and the service would be when the car senses
431.41	that the person slumps into that position,
434.847	automatically knows, hey, set an internal alarm
438.841	that would vibrate the steering wheel, honk inside
440.866	"to say, ""Hey, wake up,"
442.587	"pay more attention to the road."""
444.491	These are the sorts of things we can do
446.344	when we datafy more aspects of our lives.
449.165	So what is the value of big data?
452.84	Well, think about it.
455.03	You have more information.
457.442	You can do things that you couldn't do before.
460.783	One of the most impressive areas
462.459	where this concept is taking place
464.188	is in the area of machine learning.
467.495	Machine learning is a branch of artificial intelligence,
470.572	which itself is a branch of computer science.
473.95	The general idea is that instead of
475.493	instructing a computer what do do,
477.61	we are going to simply throw data at the problem
480.23	and tell the computer to figure it out for itself.
483.436	And it will help you understand it
485.213	by seeing its origins.
488.765	In the 1950s, a computer scientist
491.153	at IBM named Arthur Samuel liked to play checkers,
494.745	so he wrote a computer program
496.147	so he could play against the computer.
498.96	He played. He won.
501.671	He played. He won.
503.774	He played. He won,
506.789	because the computer only knew
508.567	what a legal move was.
510.794	Arthur Samuel knew something else.
512.881	Arthur Samuel knew strategy.
517.51	So he wrote a small sub-program alongside it
519.906	operating in the background, and all it did
521.88	was score the probability
523.697	that a given board configuration would likely lead
526.26	to a winning board versus a losing board
529.17	after every move.
531.678	He plays the computer. He wins.
534.828	He plays the computer. He wins.
537.336	He plays the computer. He wins.
541.067	And then Arthur Samuel leaves the computer
543.344	to play itself.
545.571	It plays itself. It collects more data.
549.08	It collects more data. It increases
549.08	the accuracy of its prediction.
553.389	And then Arthur Samuel goes back to the computer
555.493	and he plays it, and he loses,
557.811	and he plays it, and he loses,
559.88	and he plays it, and he loses,
561.927	and Arthur Samuel has created a machine
564.526	that surpasses his ability in a task that he taught it.
570.814	And this idea of machine learning
573.312	is going everywhere.
577.239	How do you think we have self-driving cars?
580.388	Are we any better off as a society
582.525	enshrining all the rules of the road into software?
585.81	No. Memory is cheaper. No.
588.408	Algorithms are faster. No. Processors are better. No.
592.402	All of those things matter, but that's not why.
595.174	It's because we changed the nature of the problem.
598.315	We changed the nature of the problem from one
599.845	in which we tried to overtly and explicitly
602.09	explain to the computer how to drive
604.671	to one in which we say,
605.987	"""Here's a lot of data around the vehicle."
607.863	You figure it out.
609.396	You figure it out that that is a traffic light,
611.263	that that traffic light is red and not green,
613.344	that that means that you need to stop
615.358	"and not go forward."""
618.441	Machine learning is at the basis
619.959	of many of the things that we do online:
621.95	search engines,
623.807	Amazon's personalization algorithm,
627.608	computer translation,
629.82	voice recognition systems.
634.11	Researchers recently have looked at
636.945	the question of biopsies,
640.14	cancerous biopsies,
642.907	and they've asked the computer to identify
645.222	by looking at the data and survival rates
647.693	to determine whether cells are actually
652.36	cancerous or not,
654.904	and sure enough, when you throw the data at it,
656.682	through a machine-learning algorithm,
658.729	the machine was able to identify
660.606	the 12 telltale signs that best predict
662.868	that this biopsy of the breast cancer cells
666.167	are indeed cancerous.
669.385	The problem: The medical literature
671.883	only knew nine of them.
674.672	Three of the traits were ones
676.472	that people didn't need to look for,
679.447	but that the machine spotted.
684.978	Now, there are dark sides to big data as well.
690.903	It will improve our lives, but there are problems
692.977	that we need to be conscious of,
695.617	and the first one is the idea
698.24	that we may be punished for predictions,
700.926	that the police may use big data for their purposes,
704.796	"a little bit like ""Minority Report."""
707.147	Now, it's a term called predictive policing,
709.588	or algorithmic criminology,
711.951	and the idea is that if we take a lot of data,
713.987	for example where past crimes have been,
716.146	we know where to send the patrols.
718.689	That makes sense, but the problem, of course,
720.804	is that it's not simply going to stop on location data,
725.348	it's going to go down to the level of the individual.
728.307	Why don't we use data about the person's
730.557	high school transcript?
732.785	Maybe we should use the fact that
734.346	they're unemployed or not, their credit score,
736.374	their web-surfing behavior,
737.926	whether they're up late at night.
739.804	Their Fitbit, when it's able
739.804	to identify biochemistries,
742.965	will show that they have aggressive thoughts.
747.201	We may have algorithms that are likely to predict
749.422	what we are about to do,
751.055	and we may be held accountable
752.299	before we've actually acted.
754.889	Privacy was the central challenge
756.621	in a small data era.
759.501	In the big data age,
761.65	the challenge will be safeguarding free will,
766.173	moral choice, human volition,
769.952	human agency.
774.54	There is another problem:
776.765	Big data is going to steal our jobs.
780.321	Big data and algorithms are going to challenge
783.833	white collar, professional knowledge work
786.894	in the 21st century
788.547	in the same way that factory automation
790.981	and the assembly line
793.17	challenged blue collar labor in the 20th century.
796.196	Think about a lab technician
798.288	who is looking through a microscope
799.697	at a cancer biopsy
801.321	and determining whether it's cancerous or not.
803.958	The person went to university.
805.93	The person buys property.
807.36	He or she votes.
809.101	He or she is a stakeholder in society.
812.767	And that person's job,
814.161	as well as an entire fleet
815.77	of professionals like that person,
817.739	is going to find that their jobs are radically changed
820.889	or actually completely eliminated.
823.246	Now, we like to think
824.53	that technology creates jobs over a period of time
827.717	after a short, temporary period of dislocation,
831.182	and that is true for the frame of reference
833.123	with which we all live, the Industrial Revolution,
835.265	because that's precisely what happened.
837.593	But we forget something in that analysis:
839.926	There are some categories of jobs
841.756	that simply get eliminated and never come back.
845.176	The Industrial Revolution wasn't very good
847.18	if you were a horse.
851.182	So we're going to need to be careful
853.237	and take big data and adjust it for our needs,
856.751	our very human needs.
859.936	We have to be the master of this technology,
861.89	not its servant.
863.546	We are just at the outset of the big data era,
866.504	and honestly, we are not very good
869.654	at handling all the data that we can now collect.
873.861	It's not just a problem for
873.861	the National Security Agency.
877.191	Businesses collect lots of
877.191	data, and they misuse it too,
880.229	and we need to get better at
880.229	this, and this will take time.
883.896	It's a little bit like the challenge that was faced
885.718	by primitive man and fire.
888.125	This is a tool, but this is a tool that,
890.01	unless we're careful, will burn us.
896.008	Big data is going to transform how we live,
899.128	how we work and how we think.
901.929	It is going to help us manage our careers
903.818	and lead lives of satisfaction and hope
907.452	and happiness and health,
910.444	but in the past, we've often
910.444	looked at information technology
913.75	and our eyes have only seen the T,
915.958	the technology, the hardware,
917.644	because that's what was physical.
919.906	We now need to recast our gaze at the I,
922.83	the information,
924.21	which is less apparent,
925.583	but in some ways a lot more important.
929.692	Humanity can finally learn from the information
933.157	that it can collect,
935.575	as part of our timeless quest
937.69	to understand the world and our place in it,
940.849	and that's why big data is a big deal.
946.48	(Applause)
