startsecond	text
18.33	What technology can we really apply to reducing global poverty?
24.33	And what I found was quite surprising.
28.33	We started looking at things like death rates in the 20th century,
31.33	and how they'd been improved, and very simple things turned out.
34.33	You'd think maybe antibiotics made more difference than clean water,
37.33	but it's actually the opposite.
40.33	And so very simple things -- off-the-shelf technologies
43.33	that we could easily find on the then-early Web --
48.33	would clearly make a huge difference to that problem.
53.33	But I also, in looking at more powerful technologies
57.33	and nanotechnology and genetic engineering and other new emerging
62.33	kind of digital technologies, became very concerned
66.33	about the potential for abuse.
70.33	If you think about it, in history, a long, long time ago
75.33	we dealt with the problem of an individual abusing another individual.
78.33	We came up with something -- the Ten Commandments: Thou shalt not kill.
81.33	That's a, kind of a one-on-one thing.
83.33	We organized into cities. We had many people.
87.33	And to keep the many from tyrannizing the one,
91.33	we came up with concepts like individual liberty.
95.33	And then, to have to deal with large groups,
96.33	say, at the nation-state level,
99.33	and we had to have mutual non-aggression,
101.33	or through a series of conflicts, we eventually came to
105.33	a rough international bargain to largely keep the peace.
111.33	But now we have a new situation, really what people call
116.33	an asymmetric situation, where technology is so powerful
119.33	that it extends beyond a nation-state.
123.33	It's not the nation-states that have potential access
126.33	to mass destruction, but individuals.
131.33	And this is a consequence of the fact that these new technologies tend to be digital.
136.33	We saw genome sequences.
140.33	You can download the gene sequences
141.33	of pathogens off the Internet if you want to,
145.33	and clearly someone recently -- I saw in a science magazine --
150.33	they said, well, the 1918 flu is too dangerous to FedEx around.
155.33	If people want to use it in their labs for working on research,
158.33	just reconstruct it yourself,
161.33	because, you know, it might break in FedEx.
165.33	So that this is possible to do this is not deniable.
170.33	So individuals in small groups super-empowered by access to these
175.33	kinds of self-replicating technologies, whether it be biological
180.33	or other, are clearly a danger in our world.
183.33	And the danger is that they can cause roughly what's a pandemic.
187.33	And we really don't have experience with pandemics,
190.33	and we're also not very good as a society at acting
193.33	to things we don't have direct and sort of gut-level experience with.
197.33	So it's not in our nature to pre-act.
201.33	And in this case, piling on more technology doesn't solve the problem,
206.33	because it only super-empowers people more.
209.33	So the solution has to be, as people like Russell and Einstein
213.33	and others imagine in a conversation that existed
215.33	in a much stronger form, I think, early in the 20th century,
219.33	that the solution had to be not just the head but the heart.
222.33	You know, public policy and moral progress.
227.33	The bargain that gives us civilization is a bargain to not use power.
233.33	We get our individual rights by society protecting us from others
236.33	not doing everything they can do but largely doing only what is legal.
241.33	And so to limit the danger of these new things, we have to limit,
246.33	ultimately, the ability of individuals
248.33	to have access, essentially, to pandemic power.
251.33	We also have to have sensible defense, because no limitation
255.33	is going to prevent a crazy person from doing something.
258.33	And you know, and the troubling thing is that
260.33	it's much easier to do something bad than to defend
262.33	against all possible bad things,
264.33	so the offensive uses really have an asymmetric advantage.
268.33	So these are the kind of thoughts I was thinking in 1999 and 2000,
272.33	and my friends told me I was getting really depressed,
274.33	and they were really worried about me.
276.33	And then I signed a book contract to write more gloomy thoughts about this
279.33	and moved into a hotel room in New York
281.33	with one room full of books on the Plague,
285.33	and you know, nuclear bombs exploding in New York
288.33	where I would be within the circle, and so on.
291.33	And then I was there on September 11th,
295.33	and I stood in the streets with everyone.
296.33	And it was quite an experience to be there.
298.33	I got up the next morning and walked out of the city,
301.33	and all the sanitation trucks were parked on Houston Street
304.33	and ready to go down and start taking the rubble away.
306.33	And I walked down the middle, up to the train station,
308.33	and everything below 14th Street was closed.
311.33	It was quite a compelling experience, but not really, I suppose,
315.33	a surprise to someone who'd had his room full of the books.
318.33	It was always a surprise that it happened then and there,
322.33	but it wasn't a surprise that it happened at all.
326.33	And everyone then started writing about this.
328.33	Thousands of people started writing about this.
329.33	And I eventually abandoned the book, and then Chris called me
331.33	to talk at the conference. I really don't talk about this anymore
334.33	because, you know, there's enough frustrating and depressing things going on.
339.33	But I agreed to come and say a few things about this.
342.33	And I would say that we can't give up the rule of law
345.33	to fight an asymmetric threat, which is what we seem to be doing
349.33	because of the present, the people that are in power,
354.33	because that's to give up the thing that makes civilization.
359.33	And we can't fight the threat in the kind of stupid way we're doing,
362.33	because a million-dollar act
364.33	causes a billion dollars of damage, causes a trillion dollar response
367.33	which is largely ineffective and arguably, probably almost certainly,
370.33	has made the problem worse.
372.33	So we can't fight the thing with a million-to-one cost,
377.33	one-to-a-million cost-benefit ratio.
384.33	So after giving up on the book -- and I had the great honor
389.33	to be able to join Kleiner Perkins about a year ago,
393.33	and to work through venture capital on the innovative side,
400.33	and to try to find some innovations that could address what I saw as
404.33	some of these big problems.
406.33	Things where, you know, a factor of 10 difference
409.33	can make a factor of 1,000 difference in the outcome.
413.33	I've been amazed in the last year at the incredible quality
416.33	and excitement of the innovations that have come across my desk.
421.33	It's overwhelming at times. I'm very thankful for Google and Wikipedia
424.33	so I can understand at least a little of what people are talking about
428.33	who come through the doors.
430.33	But I wanted to share with you three areas
433.33	that I'm particularly excited about and that relate to the problems
436.33	that I was talking about in the Wired article.
441.33	The first is this whole area of education,
443.33	and it really relates to what Nicholas was talking about with a $100 computer.
447.33	And that is to say that there's a lot of legs left in Moore's Law.
451.33	The most advanced transistors today are at 65 nanometers,
455.33	and we've seen, and I've had the pleasure to invest
458.33	in, companies that give me great confidence that we'll extend Moore's Law
464.33	all the way down to roughly the 10 nanometer scale.
467.33	Another factor of, say, six in dimensional reduction,
473.33	which should give us about another factor of 100 in raw improvement
478.33	in what the chips can do. And so, to put that in practical terms,
483.33	if something costs about 1,000 dollars today,
487.33	say, the best personal computer you can buy, that might be its cost,
492.33	I think we can have that in 2020 for 10 dollars. Okay?
498.33	Now, just imagine what that $100 computer will be in 2020
503.33	as a tool for education.
505.33	I think the challenge for us is --
507.33	I'm very certain that that will happen, the challenge is,
509.33	will we develop the kind of educational tools and things with the net
514.33	to let us take advantage of that device?
517.33	I'd argue today that we have incredibly powerful computers,
521.33	but we don't have very good software for them.
523.33	And it's only in retrospect, after the better software comes along,
526.33	and you take it and you run it on a ten-year-old machine, you say,
528.33	God, the machine was that fast?
530.33	I remember when they took the Apple Mac interface
532.33	and they put it back on the Apple II.
535.33	The Apple II was perfectly capable of running that kind of interface,
538.33	we just didn't know how to do it at the time.
541.33	So given that we know and should believe --
543.33	because Moore's Law's been, like, a constant,
546.33	I mean, it's just been very predictable progress
549.33	over the last 40 years or whatever.
552.33	We can know what the computers are going to be like in 2020.
556.33	It's great that we have initiatives to say,
558.33	let's go create the education and educate people in the world,
561.33	because that's a great force for peace.
563.33	And we can give everyone in the world a $100 computer
566.33	or a $10 computer in the next 15 years.
571.33	The second area that I'm focusing on is the environmental problem,
576.33	because that's clearly going to put a lot of pressure on this world.
580.33	We'll hear a lot more about that from Al Gore very shortly.
584.33	The thing that we see as the kind of Moore's Law trend
587.33	that's driving improvement in our ability to address
590.33	the environmental problem is new materials.
594.33	We have a challenge, because the urban population is growing
598.33	in this century from two billion to six billion
601.33	in a very short amount of time. People are moving to the cities.
603.33	They all need clean water, they need energy, they need transportation,
606.33	and we want them to develop in a green way.
610.33	We're reasonably efficient in the industrial sectors.
612.33	We've made improvements in energy and resource efficiency,
615.33	but the consumer sector, especially in America, is very inefficient.
619.33	But these new materials bring such incredible innovations
623.33	that there's a strong basis for hope that these things
627.33	will be so profitable that they can be brought to the market.
629.33	And I want to give you a specific example of a new material
632.33	that was discovered 15 years ago.
635.33	If we take carbon nanotubes, you know, Iijima discovered them in 1991,
640.33	they just have incredible properties.
642.33	And these are the kinds of things we're going to discover
643.33	as we start to engineer at the nano scale.
646.33	Their strength: they're almost the strongest material,
649.33	tensile strength material known.
652.33	They're very, very stiff. They stretch very, very little.
657.33	In two dimensions, if you make, like, a fabric out of them,
660.33	they're 30 times stronger than Kevlar.
663.33	And if you make a three-dimensional structure, like a buckyball,
666.33	they have all sorts of incredible properties.
668.33	If you shoot a particle at them and knock a hole in them,
671.33	they repair themselves; they go zip and they repair the hole
674.33	in femtoseconds, which is not -- is really quick.
677.33	(Laughter)
680.33	If you shine a light on them, they produce electricity.
684.33	In fact, if you flash them with a camera they catch on fire.
687.33	If you put electricity on them, they emit light.
691.33	If you run current through them, you can run 1,000 times more current
694.33	through one of these than through a piece of metal.
698.33	You can make both p- and n-type semiconductors,
701.33	which means you can make transistors out of them.
703.33	They conduct heat along their length but not across --
706.33	well, there is no width, but not in the other direction
708.33	if you stack them up; that's a property of carbon fiber also.
714.33	If you put particles in them, and they go shooting out the tip --
717.33	they're like miniature linear accelerators or electron guns.
720.33	The inside of the nanotubes is so small --
723.33	the smallest ones are 0.7 nanometers --
725.33	that it's basically a quantum world.
727.33	It's a strange place inside a nanotube.
730.33	And so we begin to see, and we've seen business plans already,
733.33	where the kind of things Lisa Randall's talking about are in there.
736.33	I had one business plan where I was trying to learn more about
738.33	Witten's cosmic dimension strings to try to understand
741.33	what the phenomenon was going on in this proposed nanomaterial.
744.33	So inside of a nanotube, we're really at the limit here.
750.33	So what we see is with these and other new materials
754.33	that we can do things with different properties -- lighter, stronger --
758.33	and apply these new materials to the environmental problems.
764.33	New materials that can make water,
765.33	new materials that can make fuel cells work better,
767.33	new materials that catalyze chemical reactions,
771.33	that cut pollution and so on.
774.33	Ethanol -- new ways of making ethanol.
777.33	New ways of making electric transportation.
780.33	The whole green dream -- because it can be profitable.
784.33	And we've dedicated -- we've just raised a new fund,
786.33	we dedicated 100 million dollars to these kinds of investments.
789.33	We believe that Genentech, the Compaq, the Lotus, the Sun,
793.33	the Netscape, the Amazon, the Google in these fields
797.33	are yet to be found, because this materials revolution
800.33	will drive these things forward.
804.33	The third area that we're working on,
806.33	and we just announced last week -- we were all in New York.
810.33	We raised 200 million dollars in a specialty fund
816.33	to work on a pandemic in biodefense.
820.33	And to give you an idea of the last fund that Kleiner raised
823.33	was a $400 million fund, so this for us is a very substantial fund.
828.33	And what we did, over the last few months -- well, a few months ago,
832.33	Ray Kurzweil and I wrote an op-ed in the New York Times
835.33	about how publishing the 1918 genome was very dangerous.
838.33	And John Doerr and Brook and others got concerned, [unclear],
842.33	and we started looking around at what the world was doing
846.33	about being prepared for a pandemic. And we saw a lot of gaps.
851.33	And so we asked ourselves, you know, can we find innovative things
855.33	that will go fill these gaps? And Brooks told me in a break here,
859.33	he said he's found so much stuff he can't sleep,
861.33	because there's so many great technologies out there,
864.33	we're essentially buried. And we need them, you know.
867.33	We have one antiviral that people are talking about stockpiling
870.33	that still works, roughly. That's Tamiflu.
873.33	But Tamiflu -- the virus is resistant. It is resistant to Tamiflu.
878.33	We've discovered with AIDS we need cocktails to work well
882.33	so that the viral resistance -- we need several anti-virals.
885.33	We need better surveillance.
887.33	We need networks that can find out what's going on.
890.33	We need rapid diagnostics so that we can tell if somebody has
894.33	a strain of flu which we have only identified very recently.
898.33	We've got to be able to make the rapid diagnostics quickly.
900.33	We need new anti-virals and cocktails. We need new kinds of vaccines.
903.33	Vaccines that are broad spectrum.
905.33	Vaccines that we can manufacture quickly.
909.33	Cocktails, more polyvalent vaccines.
911.33	You normally get a trivalent vaccine against three possible strains.
914.33	We need -- we don't know where this thing is going.
917.33	We believe that if we could fill these 10 gaps,
920.33	we have a chance to help really reduce the risk of a pandemic.
926.33	And the difference between a normal flu season and a pandemic
930.33	is about a factor of 1,000 in deaths
933.33	and certainly enormous economic impact.
936.33	So we're very excited because we think we can fund 10,
939.33	or speed up 10 projects and see them come to market
943.33	in the next couple years that will address this.
946.33	So if we can address, use technology, help address education,
949.33	help address the environment, help address the pandemic,
952.33	does that solve the larger problem that I was talking about
956.33	in the Wired article? And I'm afraid the answer is really no,
961.33	because you can't solve a problem with the management of technology
965.33	with more technology.
968.33	If we let an unlimited amount of power loose, then we will --
973.33	a very small number of people will be able to abuse it.
975.33	We can't fight at a million-to-one disadvantage.
979.33	So what we need to do is, we need better policy.
982.33	And for example, some things we could do
985.33	that would be policy solutions which are not really in the political air right now
989.33	but perhaps with the change of administration would be -- use markets.
993.33	Markets are a very strong force.
995.33	For example, rather than trying to regulate away problems,
998.33	which probably won't work, if we could price
1000.33	into the cost of doing business, the cost of catastrophe,
1005.33	so that people who are doing things that had a higher cost of catastrophe
1008.33	would have to take insurance against that risk.
1011.33	So if you wanted to put a drug on the market you could put it on.
1013.33	But it wouldn't have to be approved by regulators;
1015.33	you'd have to convince an actuary that it would be safe.
1019.33	And if you apply the notion of insurance more broadly,
1022.33	you can use a more powerful force, a market force,
1025.33	to provide feedback.
1027.33	How could you keep the law?
1028.33	I think the law would be a really good thing to keep.
1030.33	Well, you have to hold people accountable.
1032.33	The law requires accountability.
1034.33	Today scientists, technologists, businessmen, engineers
1037.33	don't have any personal responsibility
1039.33	for the consequences of their actions.
1041.33	So if you tie that -- you have to tie that back with the law.
1045.33	And finally, I think we have to do something that's not really --
1049.33	it's almost unacceptable to say this -- which,
1050.33	we have to begin to design the future.
1053.33	We can't pick the future, but we can steer the future.
1057.33	Our investment in trying to prevent pandemic flu
1059.33	is affecting the distribution of possible outcomes.
1063.33	We may not be able to stop it, but the likelihood
1065.33	that it will get past us is lower if we focus on that problem.
1069.33	So we can design the future if we choose what kind of things
1073.33	we want to have happen and not have happen,
1076.33	and steer us to a lower-risk place.
1079.33	Vice President Gore will talk about how we could steer the climate trajectory
1085.33	into a lower probability of catastrophic risk.
1088.33	But above all, what we have to do is we have to help the good guys,
1091.33	the people on the defensive side,
1093.33	have an advantage over the people who want to abuse things.
1097.33	And what we have to do to do that
1099.33	is we have to limit access to certain information.
1102.33	And growing up as we have, and holding very high
1105.33	the value of free speech, this is a hard thing for us to accept --
1109.33	for all of us to accept.
1110.33	It's especially hard for the scientists to accept who still remember,
1115.33	you know, Galileo essentially locked up,
1117.33	and who are still fighting this battle against the church.
1121.33	But that's the price of having a civilization.
1126.33	The price of retaining the rule of law
1128.33	is to limit the access to the great and kind of unbridled power.
1133.33	Thank you.
1134.33	(Applause)
