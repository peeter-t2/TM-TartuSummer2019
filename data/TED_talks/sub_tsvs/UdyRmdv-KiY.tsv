startsecond	text
18.33	What I want to tell you about today is how I see robots invading our lives
23.33	at multiple levels, over multiple timescales.
26.33	And when I look out in the future, I can't imagine a world, 500 years from now,
30.33	where we don't have robots everywhere.
32.33	Assuming -- despite all the dire predictions from many people about our future --
37.33	assuming we're still around, I can't imagine the world not being populated with robots.
41.33	And then the question is, well, if they're going to be here in 500 years,
44.33	are they going to be everywhere sooner than that?
46.33	Are they going to be around in 50 years?
48.33	Yeah, I think that's pretty likely -- there's going to be lots of robots everywhere.
51.33	And in fact I think that's going to be a lot sooner than that.
54.33	I think we're sort of on the cusp of robots becoming common,
58.33	and I think we're sort of around 1978 or 1980 in personal computer years,
64.33	where the first few robots are starting to appear.
67.33	Computers sort of came around through games and toys.
71.33	And you know, the first computer most people had in the house
74.33	may have been a computer to play Pong,
76.33	a little microprocessor embedded,
78.33	and then other games that came after that.
81.33	And we're starting to see that same sort of thing with robots:
84.33	LEGO Mindstorms, Furbies -- who here -- did anyone here have a Furby?
88.33	Yeah, there's 38 million of them sold worldwide.
91.33	They are pretty common. And they're a little tiny robot,
93.33	a simple robot with some sensors,
95.33	a little bit of processing actuation.
97.33	On the right there is another robot doll, who you could get a couple of years ago.
100.33	And just as in the early days,
102.33	when there was a lot of sort of amateur interaction over computers,
107.33	you can now get various hacking kits, how-to-hack books.
111.33	And on the left there is a platform from Evolution Robotics,
115.33	where you put a PC on, and you program this thing with a GUI
118.33	to wander around your house and do various stuff.
121.33	And then there's a higher price point sort of robot toys --
124.33	the Sony Aibo. And on the right there, is one that the NEC developed,
128.33	the PaPeRo, which I don't think they're going to release.
131.33	But nevertheless, those sorts of things are out there.
134.33	And we've seen, over the last two or three years, lawn-mowing robots,
138.33	Husqvarna on the bottom, Friendly Robotics on top there, an Israeli company.
144.33	And then in the last 12 months or so
146.33	we've started to see a bunch of home-cleaning robots appear.
150.33	The top left one is a very nice home-cleaning robot
153.33	from a company called Dyson, in the U.K. Except it was so expensive --
157.33	3,500 dollars -- they didn't release it.
159.33	But at the bottom left, you see Electrolux, which is on sale.
162.33	Another one from Karcher.
164.33	At the bottom right is one that I built in my lab
166.33	about 10 years ago, and we finally turned that into a product.
169.33	And let me just show you that.
171.33	We're going to give this away I think, Chris said, after the talk.
175.33	This is a robot that you can go out and buy, and that will clean up your floor.
185.33	And it starts off sort of just going around in ever-increasing circles.
190.33	If it hits something -- you people see that?
194.33	Now it's doing wall-following, it's following around my feet
197.33	to clean up around me. Let's see, let's --
201.33	oh, who stole my Rice Krispies? They stole my Rice Krispies!
206.33	(Laughter)
212.33	Don't worry, relax, no, relax, it's a robot, it's smart!
215.33	(Laughter)
218.33	See, the three-year-old kids, they don't worry about it.
222.33	It's grown-ups that get really upset.
224.33	(Laughter)
225.33	We'll just put some crap here.
227.33	(Laughter)
231.33	Okay.
233.33	(Laughter)
237.33	I don't know if you see -- so, I put a bunch of Rice Krispies there,
240.33	I put some pennies, let's just shoot it at that, see if it cleans up.
250.33	Yeah, OK. So --
252.33	we'll leave that for later.
256.33	(Applause)
262.33	Part of the trick was building a better cleaning mechanism, actually;
266.33	the intelligence on board was fairly simple.
270.33	And that's true with a lot of robots.
272.33	We've all, I think, become, sort of computational chauvinists,
276.33	and think that computation is everything,
278.33	but the mechanics still matter.
280.33	Here's another robot, the PackBot,
283.33	that we've been building for a bunch of years.
285.33	It's a military surveillance robot, to go in ahead of troops --
291.33	looking at caves, for instance.
294.33	But we had to make it fairly robust,
296.33	much more robust than the robots we build in our labs.
303.33	(Laughter)
312.33	On board that robot is a PC running Linux.
316.33	It can withstand a 400G shock. The robot has local intelligence:
322.33	it can flip itself over, can get itself into communication range,
328.33	can go upstairs by itself, et cetera.
338.33	Okay, so it's doing local navigation there.
342.33	A soldier gives it a command to go upstairs, and it does.
349.33	That was not a controlled descent.
352.33	(Laughter)
354.33	Now it's going to head off.
356.33	And the big breakthrough for these robots, really, was September 11th.
361.33	We had the robots down at the World Trade Center late that evening.
366.33	Couldn't do a lot in the main rubble pile,
368.33	things were just too -- there was nothing left to do.
371.33	But we did go into all the surrounding buildings that had been evacuated,
376.33	and searched for possible survivors in the buildings
379.33	that were too dangerous to go into.
381.33	Let's run this video.
383.33	Reporter: ...battlefield companions are helping to reduce the combat risks.
386.33	Nick Robertson has that story.
391.33	Rodney Brooks: Can we have another one of these?
398.33	Okay, good.
403.33	So, this is a corporal who had seen a robot two weeks previously.
408.33	He's sending robots into caves, looking at what's going on.
412.33	The robot's being totally autonomous.
414.33	The worst thing that's happened in the cave so far
418.33	was one of the robots fell down ten meters.
428.33	So one year ago, the US military didn't have these robots.
431.33	Now they're on active duty in Afghanistan every day.
433.33	And that's one of the reasons they say a robot invasion is happening.
436.33	There's a sea change happening in how -- where technology's going.
440.33	Thanks.
443.33	And over the next couple of months,
445.33	we're going to be sending robots in production
448.33	down producing oil wells to get that last few years of oil out of the ground.
452.33	Very hostile environments, 150Ëš C, 10,000 PSI.
456.33	Autonomous robots going down, doing this sort of work.
460.33	But robots like this, they're a little hard to program.
463.33	How, in the future, are we going to program our robots
465.33	and make them easier to use?
467.33	And I want to actually use a robot here --
470.33	a robot named Chris -- stand up. Yeah. Okay.
477.33	Come over here. Now notice, he thinks robots have to be a bit stiff.
481.33	He sort of does that. But I'm going to --
484.33	Chris Anderson: I'm just British. RB: Oh.
486.33	(Laughter)
488.33	(Applause)
490.33	I'm going to show this robot a task. It's a very complex task.
493.33	Now notice, he nodded there, he was giving me some indication
496.33	he was understanding the flow of communication.
499.33	And if I'd said something completely bizarre
501.33	he would have looked askance at me, and regulated the conversation.
504.33	So now I brought this up in front of him.
507.33	I'd looked at his eyes, and I saw his eyes looked at this bottle top.
511.33	And I'm doing this task here, and he's checking up.
513.33	His eyes are going back and forth up to me, to see what I'm looking at --
516.33	so we've got shared attention.
518.33	And so I do this task, and he looks, and he looks to me
521.33	to see what's happening next. And now I'll give him the bottle,
525.33	and we'll see if he can do the task. Can you do that?
527.33	(Laughter)
530.33	Okay. He's pretty good. Yeah. Good, good, good.
534.33	I didn't show you how to do that.
536.33	Now see if you can put it back together.
538.33	(Laughter)
540.33	And he thinks a robot has to be really slow.
541.33	Good robot, that's good.
543.33	So we saw a bunch of things there.
546.33	We saw when we're interacting,
549.33	we're trying to show someone how to do something, we direct their visual attention.
553.33	The other thing communicates their internal state to us,
557.33	whether he's understanding or not, regulates a social interaction.
560.33	There was shared attention looking at the same sort of thing,
562.33	and recognizing socially communicated reinforcement at the end.
566.33	And we've been trying to put that into our lab robots
569.33	because we think this is how you're going to want to interact with robots in the future.
573.33	I just want to show you one technical diagram here.
575.33	The most important thing for building a robot that you can interact with socially
579.33	is its visual attention system.
581.33	Because what it pays attention to is what it's seeing
584.33	and interacting with, and what you're understanding what it's doing.
587.33	So in the videos I'm about to show you,
590.33	you're going to see a visual attention system on a robot
594.33	which has -- it looks for skin tone in HSV space,
598.33	so it works across all human colorings.
602.33	It looks for highly saturated colors, from toys.
604.33	And it looks for things that move around.
606.33	And it weights those together into an attention window,
609.33	and it looks for the highest-scoring place --
611.33	the stuff where the most interesting stuff is happening --
613.33	and that is what its eyes then segue to.
617.33	And it looks right at that.
619.33	At the same time, some top-down sort of stuff:
622.33	might decide that it's lonely and look for skin tone,
625.33	or might decide that it's bored and look for a toy to play with.
628.33	And so these weights change.
630.33	And over here on the right,
632.33	this is what we call the Steven Spielberg memorial module.
635.33	"Did people see the movie ""AI""? (Audience: Yes.)"
637.33	RB: Yeah, it was really bad, but --
639.33	remember, especially when Haley Joel Osment, the little robot,
643.33	looked at the blue fairy for 2,000 years without taking his eyes off it?
647.33	Well, this gets rid of that,
649.33	because this is a habituation Gaussian that gets negative,
653.33	and more and more intense as it looks at one thing.
656.33	And it gets bored, so it will then look away at something else.
659.33	So, once you've got that -- and here's a robot, here's Kismet,
663.33	looking around for a toy. You can tell what it's looking at.
667.33	You can estimate its gaze direction from those eyeballs covering its camera,
672.33	and you can tell when it's actually seeing the toy.
675.33	And it's got a little bit of an emotional response here.
677.33	(Laughter)
678.33	But it's still going to pay attention
680.33	if something more significant comes into its field of view --
684.33	such as Cynthia Breazeal, the builder of this robot, from the right.
688.33	It sees her, pays attention to her.
693.33	Kismet has an underlying, three-dimensional emotional space,
697.33	a vector space, of where it is emotionally.
700.33	And at different places in that space, it expresses --
706.33	can we have the volume on here?
708.33	Can you hear that now, out there? (Audience: Yeah.)
710.33	Kismet: Do you really think so? Do you really think so?
717.33	Do you really think so?
720.33	RB: So it's expressing its emotion through its face
723.33	and the prosody in its voice.
725.33	And when I was dealing with my robot over here,
729.33	Chris, the robot, was measuring the prosody in my voice,
732.33	and so we have the robot measure prosody for four basic messages
737.33	that mothers give their children pre-linguistically.
741.33	Here we've got naive subjects praising the robot:
746.33	Voice: Nice robot.
749.33	You're such a cute little robot.
751.33	(Laughter)
753.33	RB: And the robot's reacting appropriately.
755.33	Voice: ...very good, Kismet.
760.33	(Laughter)
762.33	Voice: Look at my smile.
766.33	RB: It smiles. She imitates the smile. This happens a lot.
769.33	These are naive subjects.
771.33	Here we asked them to get the robot's attention
774.33	and indicate when they have the robot's attention.
777.33	Voice: Hey, Kismet, ah, there it is.
781.33	RB: So she realizes she has the robot's attention.
788.33	Voice: Kismet, do you like the toy? Oh.
793.33	RB: Now, here they're asked to prohibit the robot,
795.33	and this first woman really pushes the robot into an emotional corner.
799.33	Voice: No. No. You're not to do that. No.
804.33	(Laughter)
807.33	Not appropriate. No. No.
813.33	(Laughter)
816.33	RB: I'm going to leave it at that.
818.33	We put that together. Then we put in turn taking.
820.33	When we talk to someone, we talk.
823.33	Then we sort of raise our eyebrows, move our eyes,
827.33	give the other person the idea it's their turn to talk.
830.33	And then they talk, and then we pass the baton back and forth between each other.
834.33	So we put this in the robot.
836.33	We got a bunch of naive subjects in,
838.33	we didn't tell them anything about the robot,
840.33	sat them down in front of the robot and said, talk to the robot.
842.33	Now what they didn't know was,
844.33	the robot wasn't understanding a word they said,
846.33	and that the robot wasn't speaking English.
849.33	It was just saying random English phonemes.
851.33	And I want you to watch carefully, at the beginning of this,
853.33	where this person, Ritchie, who happened to talk to the robot for 25 minutes --
857.33	(Laughter)
859.33	"-- says, ""I want to show you something."
861.33	"I want to show you my watch."""
863.33	And he brings the watch center, into the robot's field of vision,
868.33	points to it, gives it a motion cue,
870.33	and the robot looks at the watch quite successfully.
872.33	We don't know whether he understood or not that the robot --
876.33	Notice the turn-taking.
878.33	Ritchie: OK, I want to show you something. OK, this is a watch
881.33	that my girlfriend gave me.
884.33	Robot: Oh, cool.
886.33	Ritchie: Yeah, look, it's got a little blue light in it too. I almost lost it this week.
891.33	(Laughter)
895.33	RB: So it's making eye contact with him, following his eyes.
898.33	Ritchie: Can you do the same thing? Robot: Yeah, sure.
900.33	RB: And they successfully have that sort of communication.
902.33	And here's another aspect of the sorts of things that Chris and I were doing.
906.33	This is another robot, Cog.
908.33	They first make eye contact, and then, when Christie looks over at this toy,
914.33	the robot estimates her gaze direction
916.33	and looks at the same thing that she's looking at.
918.33	(Laughter)
919.33	So we're going to see more and more of this sort of robot
922.33	over the next few years in labs.
924.33	But then the big questions, two big questions that people ask me are:
929.33	if we make these robots more and more human-like,
931.33	will we accept them, will we -- will they need rights eventually?
936.33	And the other question people ask me is, will they want to take over?
939.33	(Laughter)
940.33	And on the first -- you know, this has been a very Hollywood theme
943.33	with lots of movies. You probably recognize these characters here --
946.33	where in each of these cases, the robots want more respect.
950.33	Well, do you ever need to give robots respect?
954.33	They're just machines, after all.
956.33	But I think, you know, we have to accept that we are just machines.
960.33	After all, that's certainly what modern molecular biology says about us.
965.33	You don't see a description of how, you know,
968.33	Molecule A, you know, comes up and docks with this other molecule.
972.33	And it's moving forward, you know, propelled by various charges,
975.33	and then the soul steps in and tweaks those molecules so that they connect.
979.33	It's all mechanistic. We are mechanism.
982.33	If we are machines, then in principle at least,
985.33	we should be able to build machines out of other stuff,
989.33	which are just as alive as we are.
993.33	But I think for us to admit that,
995.33	we have to give up on our special-ness, in a certain way.
998.33	And we've had the retreat from special-ness
1000.33	under the barrage of science and technology many times
1003.33	over the last few hundred years, at least.
1007.33	that we are the center of the universe
1010.33	when the earth started to go around the sun;
1017.33	And to imagine -- you know, it's always hard for us.
1020.33	Recently we've been battered with the idea that maybe
1023.33	we didn't even have our own creation event, here on earth,
1025.33	which people didn't like much. And then the human genome said,
1028.33	maybe we only have 35,000 genes. And that was really --
1031.33	people didn't like that, we've got more genes than that.
1034.33	We don't like to give up our special-ness, so, you know,
1037.33	having the idea that robots could really have emotions,
1039.33	or that robots could be living creatures --
1041.33	I think is going to be hard for us to accept.
1043.33	But we're going to come to accept it over the next 50 years or so.
1047.33	And the second question is, will the machines want to take over?
1050.33	And here the standard scenario is that we create these things,
1055.33	they grow, we nurture them, they learn a lot from us,
1058.33	and then they start to decide that we're pretty boring, slow.
1062.33	They want to take over from us.
1064.33	And for those of you that have teenagers, you know what that's like.
1067.33	(Laughter)
1068.33	But Hollywood extends it to the robots.
1071.33	And the question is, you know,
1074.33	will someone accidentally build a robot that takes over from us?
1078.33	And that's sort of like this lone guy in the backyard,
1081.33	"you know -- ""I accidentally built a 747."""
1084.33	I don't think that's going to happen.
1086.33	And I don't think --
1088.33	(Laughter)
1089.33	-- I don't think we're going to deliberately build robots
1092.33	that we're uncomfortable with.
1094.33	We'll -- you know, they're not going to have a super bad robot.
1096.33	Before that has to come to be a mildly bad robot,
1099.33	and before that a not so bad robot.
1101.33	(Laughter)
1102.33	And we're just not going to let it go that way.
1104.33	(Laughter)
1105.33	So, I think I'm going to leave it at that: the robots are coming,
1111.33	we don't have too much to worry about, it's going to be a lot of fun,
1114.33	and I hope you all enjoy the journey over the next 50 years.
1118.33	(Applause)
