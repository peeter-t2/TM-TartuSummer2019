startsecond	text
15.651	We are today talking
15.651	about moral persuasion:
18.261	What is moral and immoral
18.261	in trying to change people's behaviors
22.267	by using technology and using design?
24.744	And I don't know what you expect,
26.6	but when I was thinking about that issue,
28.577	I early on realized what I'm not able
28.577	to give you are answers.
33.203	I'm not able to tell you
33.203	what is moral or immoral,
35.998	because we're living
35.998	in a pluralist society.
38.569	My values can be radically
38.569	different from your values,
42.835	which means that what I consider
42.835	moral or immoral based on that
46.036	might not necessarily be
46.036	what you consider moral or immoral.
50.029	But I also realized
50.029	there is one thing that I could give you,
53.267	and that is what this guy
53.267	behind me gave the world --
55.824	Socrates.
56.998	It is questions.
58.417	What I can do and what
58.417	I would like to do with you
61.074	is give you, like that initial question,
63.043	a set of questions
63.043	to figure out for yourselves,
66.477	layer by layer, like peeling an onion,
70.142	getting at the core of what you believe
70.142	is moral or immoral persuasion.
75.559	And I'd like to do that
75.559	with a couple of examples of technologies
79.624	where people have used game elements
79.624	to get people to do things.
85.343	So it's at first a very simple,
85.343	very obvious question
88.407	I would like to give you:
89.627	What are your intentions
89.627	if you are designing something?
92.668	And obviously, intentions
92.668	are not the only thing,
96.065	so here is another example
96.065	for one of these applications.
99.267	There are a couple of these kinds
99.267	of Eco dashboards right now --
102.378	dashboards built into cars --
103.862	which try to motivate you
103.862	to drive more fuel-efficiently.
106.718	This here is Nissan's MyLeaf,
108.515	where your driving behavior
108.515	is compared with the driving behavior
111.603	of other people,
112.778	so you can compete for who drives a route
112.778	the most fuel-efficiently.
116.079	And these things are
116.079	very effective, it turns out --
118.58	so effective that they motivate people
118.58	to engage in unsafe driving behaviors,
122.543	like not stopping at a red light,
124.329	because that way you have
124.329	to stop and restart the engine,
127.068	and that would use quite
127.068	some fuel, wouldn't it?
130.338	So despite this being
130.338	a very well-intended application,
134.771	obviously there was a side effect of that.
137.17	Here's another example
137.17	for one of these side effects.
139.742	Commendable: a site that allows parents
139.742	to give their kids little badges
144.55	for doing the things
144.55	that parents want their kids to do,
147.232	like tying their shoes.
148.572	And at first that sounds very nice,
150.84	very benign, well-intended.
153.014	But it turns out, if you look into
153.014	research on people's mindset,
156.808	caring about outcomes,
158.319	caring about public recognition,
160.116	caring about these kinds
160.116	of public tokens of recognition
164.001	is not necessarily very helpful
166.019	for your long-term
166.019	psychological well-being.
168.35	It's better if you care
168.35	about learning something.
171.05	It's better when you care about yourself
172.979	than how you appear
172.979	in front of other people.
176.021	So that kind of motivational tool
176.021	that is used actually, in and of itself,
181.086	has a long-term side effect,
183.018	in that every time we use a technology
184.852	that uses something
184.852	like public recognition or status,
188.05	we're actually positively endorsing this
190.45	as a good and normal thing
190.45	to care about --
193.884	that way, possibly having
193.884	a detrimental effect
196.772	on the long-term psychological
196.772	well-being of ourselves as a culture.
200.651	So that's a second, very obvious question:
203.319	What are the effects
203.319	of what you're doing --
205.654	the effects you're having
205.654	with the device, like less fuel,
209.802	as well as the effects
209.802	of the actual tools you're using
212.531	to get people to do things --
214.229	public recognition?
215.824	Now is that all -- intention, effect?
218.769	Well, there are some technologies
218.769	which obviously combine both.
221.927	Both good long-term and short-term effects
224.738	and a positive intention
224.738	"like Fred Stutzman's ""Freedom,"""
227.571	where the whole point
227.571	of that application is --
229.802	well, we're usually so bombarded
229.802	with constant requests by other people,
233.551	with this device,
234.731	you can shut off the Internet
234.731	connectivity of your PC of choice
238.235	for a pre-set amount of time,
239.707	to actually get some work done.
241.702	And I think most of us will agree
241.702	that's something well-intended,
244.877	and also has good consequences.
247.121	In the words of Michel Foucault,
248.791	"it is a ""technology of the self."""
250.755	It is a technology
250.755	that empowers the individual
253.616	to determine its own life course,
255.455	to shape itself.
257.41	But the problem is,
257.41	as Foucault points out,
260.418	that every technology of the self
262.227	has a technology of domination
262.227	as its flip side.
265.696	As you see in today's modern
265.696	liberal democracies,
270.323	the society, the state,
270.323	not only allows us to determine our self,
275.03	to shape our self,
276.205	it also demands it of us.
278.22	It demands that we optimize ourselves,
280.205	that we control ourselves,
282.069	that we self-manage continuously,
284.804	because that's the only way
284.804	in which such a liberal society works.
288.721	These technologies want us
288.721	to stay in the game
293.013	that society has devised for us.
295.81	They want us to fit in even better.
298.121	They want us to optimize
298.121	ourselves to fit in.
301.628	Now, I don't say that
301.628	is necessarily a bad thing;
305.293	I just think that this example
305.293	points us to a general realization,
309.645	and that is: no matter what technology
309.645	or design you look at,
313.472	even something we consider
313.472	as well-intended
316.517	and as good in its effects
316.517	as Stutzman's Freedom,
319.507	comes with certain values embedded in it.
322.238	And we can question these values.
324.198	We can question: Is it a good thing
326.166	that all of us continuously
326.166	self-optimize ourselves
329.674	to fit better into that society?
331.709	Or to give you another example:
333.225	What about a piece
333.225	of persuasive technology
335.725	that convinces Muslim women
335.725	to wear their headscarves?
338.94	Is that a good or a bad technology
341.016	in its intentions or in its effects?
343.603	Well, that basically depends on
343.603	the kind of values you bring to bear
347.881	to make these kinds of judgments.
350.142	So that's a third question:
351.694	What values do you use to judge?
353.848	And speaking of values:
355.213	I've noticed that in the discussion
355.213	about moral persuasion online
358.593	and when I'm talking with people,
360.254	more often than not,
360.254	there is a weird bias.
363.463	And that bias is that we're asking:
366.383	"Is this or that ""still"" ethical?"
369.22	"Is it ""still"" permissible?"
371.894	We're asking things like:
373.116	Is this Oxfam donation form,
375.329	where the regular monthly
375.329	donation is the preset default,
378.401	and people, maybe without intending it,
380.504	are encouraged or nudged
380.504	into giving a regular donation
384.34	instead of a one-time donation,
385.853	"is that ""still' permissible?"
387.22	"Is it ""still"" ethical?"
388.607	We're fishing at the low end.
390.879	But in fact, that question,
390.879	"""Is it 'still' ethical?"""
393.377	is just one way of looking at ethics.
395.182	Because if you look at the beginning
395.182	of ethics in Western culture,
400.098	you see a very different idea
400.098	of what ethics also could be.
403.97	For Aristotle, ethics
403.97	was not about the question,
407.991	"""Is that still good, or is it bad?"""
410.287	Ethics was about the question
410.287	of how to live life well.
414.216	"And he put that in the word ""arÃªte,"""
416.421	which we, from [Ancient Greek],
416.421	"translate as ""virtue."""
419.2	"But really, it means ""excellence."""
420.864	It means living up to your own
420.864	full potential as a human being.
426.937	And that is an idea that, I think,
428.617	Paul Richard Buchanan
428.617	put nicely in a recent essay,
431.338	where he said,
431.338	"""Products are vivid arguments"
433.505	"about how we should live our lives."""
436.086	Our designs are not ethical or unethical
438.687	in that they're using ethical
438.687	or unethical means of persuading us.
443.661	They have a moral component
445.255	just in the kind of vision
445.255	and the aspiration of the good life
449.506	that they present to us.
451.441	And if you look into the designed
451.441	environment around us
454.968	with that kind of lens,
456.164	"asking, ""What is the vision"
456.164	of the good life
458.641	that our products, our design,
458.641	"present to us?"","
461.403	then you often get the shivers,
463.703	because of how little
463.703	we expect of each other,
466.055	of how little we actually
466.055	seem to expect of our life,
469.969	and what the good life looks like.
473.11	So that's a fourth question
473.11	I'd like to leave you with:
476.157	What vision of the good life
476.157	do your designs convey?
481.249	And speaking of design,
482.645	you'll notice that I already
482.645	broadened the discussion,
486.859	because it's not just persuasive
486.859	technology that we're talking about here,
491.327	it's any piece of design
491.327	that we put out here in the world.
495.428	I don't know whether you know
496.852	the great communication researcher
496.852	Paul Watzlawick who, back in the '60s,
500.431	made the argument
500.431	that we cannot not communicate.
502.966	Even if we choose to be silent,
502.966	we chose to be silent,
505.591	and we're communicating something
505.591	by choosing to be silent.
508.571	And in the same way
508.571	that we cannot not communicate,
511.33	we cannot not persuade:
512.885	whatever we do or refrain from doing,
514.92	whatever we put out there
514.92	as a piece of design, into the world,
519.309	has a persuasive component.
521.38	It tries to affect people.
523.277	It puts a certain vision of the good life
523.277	out there in front of us,
527.048	which is what Peter-Paul Verbeek,
528.697	the Dutch philosopher of technology, says.
531.437	No matter whether we as designers
531.437	intend it or not,
535.409	we materialize morality.
537.575	We make certain things
537.575	harder and easier to do.
540.402	We organize the existence of people.
542.637	We put a certain vision
543.812	of what good or bad or normal or usual is
547.24	in front of people,
548.415	by everything we put
548.415	out there in the world.
551.247	Even something as innocuous
551.247	as a set of school chairs
554.357	is a persuasive technology,
556.428	because it presents and materializes
556.428	a certain vision of the good life --
561.142	a good life in which teaching
561.142	and learning and listening
564.023	is about one person teaching,
564.023	the others listening;
567.146	in which it is about
567.146	learning-is-done-while-sitting;
571.223	in which you learn for yourself;
572.842	in which you're not supposed
572.842	to change these rules,
575.286	because the chairs
575.286	are fixed to the ground.
578.888	And even something as innocuous
578.888	as a single-design chair,
581.823	like this one by Arne Jacobsen,
583.419	is a persuasive technology,
585.219	because, again, it communicates
585.219	an idea of the good life:
588.735	a good life -- a life that you,
588.735	as a designer, consent to by saying,
593.684	"""In a good life, goods are produced"
593.684	as sustainably or unsustainably
597.215	as this chair.
598.85	Workers are treated as well or as badly
600.851	as the workers were treated
600.851	"that built that chair."""
603.762	The good life is a life
603.762	where design is important
606.087	because somebody obviously took
606.087	the time and spent the money
609.032	for that kind of well-designed chair;
610.84	where tradition is important,
612.268	because this is a traditional classic
612.268	and someone cared about this;
615.458	and where there is something
615.458	as conspicuous consumption,
618.172	where it is OK and normal to spend
618.172	a humongous amount of money
621.152	on such a chair,
622.327	to signal to other people
622.327	what your social status is.
624.924	So these are the kinds of layers,
624.924	the kinds of questions
628.265	I wanted to lead you through today;
630.259	the question of: What are the intentions
630.259	that you bring to bear
633.317	when you're designing something?
634.901	What are the effects, intended
634.901	and unintended, that you're having?
638.177	What are the values
638.177	you're using to judge those?
641.002	What are the virtues, the aspirations
642.999	that you're actually expressing in that?
645.4	And how does that apply,
647.281	not just to persuasive technology,
649.291	but to everything you design?
651.912	Do we stop there?
653.815	I don't think so.
655.291	I think that all of these things
655.291	are eventually informed
659.753	by the core of all of this,
661.2	and this is nothing but life itself.
664.594	Why, when the question
664.594	of what the good life is
667.335	informs everything that we design,
669.698	should we stop at design
669.698	and not ask ourselves:
672.516	How does it apply to our own life?
674.881	"""Why should the lamp"
674.881	or the house be an art object,
677.617	"but not our life?"""
678.817	as Michel Foucault puts it.
680.696	Just to give you a practical
680.696	example of Buster Benson.
684.331	This is Buster setting up
684.331	a pull-up machine
686.613	at the office of his new
686.613	start-up, Habit Labs,
689.249	where they're trying to build
689.249	"other applications like ""Health Month"""
692.488	for people.
693.67	And why is he building a thing like this?
695.656	Well, here is the set of axioms
697.713	that Habit Labs, Buster's start-up,
697.713	put up for themselves
701.135	on how they wanted to work
701.135	together as a team
703.864	when they're building
703.864	these applications --
705.917	a set of moral principles
705.917	they set themselves
708.13	for working together --
709.515	one of them being,
710.777	"""We take care of our own health"
710.777	"and manage our own burnout."""
714.221	Because ultimately,
714.221	how can you ask yourselves
717.745	and how can you find an answer
717.745	on what vision of the good life
721.699	you want to convey and create
721.699	with your designs
724.892	without asking the question:
726.646	What vision of the good life
726.646	do you yourself want to live?
731.018	And with that,
732.945	I thank you.
734.381	(Applause)
