startsecond	text
12.708	Chris Anderson: Hello.
12.708	Welcome to this TED Dialogues.
16.486	It's the first of a series
16.486	that's going to be done
20.097	in response to the current
20.097	political upheaval.
24.085	I don't know about you;
25.278	I've become quite concerned about
25.278	the growing divisiveness in this country
28.913	and in the world.
30.433	No one's listening to each other. Right?
33.384	They aren't.
34.571	I mean, it feels like we need
34.571	a different kind of conversation,
38.331	one that's based on -- I don't know,
38.331	on reason, listening, on understanding,
44.283	on a broader context.
46.66	That's at least what we're going to try
46.66	in these TED Dialogues,
49.711	starting today.
50.927	And we couldn't have anyone with us
53.577	who I'd be more excited to kick this off.
56.41	This is a mind right here that thinks
56.41	pretty much like no one else
60.284	on the planet, I would hasten to say.
62.079	I'm serious.
63.262	(Yuval Noah Harari laughs)
64.548	I'm serious.
65.736	He synthesizes history
65.736	with underlying ideas
70.698	in a way that kind of takes
70.698	your breath away.
72.892	So, some of you will know
72.892	"this book, ""Sapiens."""
76.325	"Has anyone here read ""Sapiens""?"
78.092	(Applause)
79.328	I mean, I could not put it down.
82.497	The way that he tells the story of mankind
86.395	through big ideas that really make you
86.395	think differently --
90.221	it's kind of amazing.
91.98	And here's the follow-up,
93.228	which I think is being published
93.228	in the US next week.
96.328	YNH: Yeah, next week.
97.503	"CA: ""Homo Deus."""
98.701	Now, this is the history
98.701	of the next hundred years.
102.341	I've had a chance to read it.
104.215	It's extremely dramatic,
106.629	and I daresay, for some people,
106.629	quite alarming.
111.425	It's a must-read.
112.692	And honestly, we couldn't have
112.692	someone better to help
118.294	make sense of what on Earth
118.294	is happening in the world right now.
122.294	So a warm welcome, please,
122.294	to Yuval Noah Harari.
126.475	(Applause)
134.72	It's great to be joined by our friends
134.72	on Facebook and around the Web.
138.489	Hello, Facebook.
140.09	And all of you, as I start
140.09	asking questions of Yuval,
144.04	come up with your own questions,
145.716	and not necessarily about
145.716	the political scandal du jour,
148.387	but about the broader understanding
148.387	of: Where are we heading?
154.337	You ready? OK, we're going to go.
156.127	So here we are, Yuval:
157.426	New York City, 2017,
157.426	there's a new president in power,
161.17	and shock waves rippling around the world.
164.315	What on Earth is happening?
166.935	YNH: I think the basic thing that happened
169.205	is that we have lost our story.
171.964	Humans think in stories,
174.455	and we try to make sense of the world
174.455	by telling stories.
178.141	And for the last few decades,
179.582	we had a very simple
179.582	and very attractive story
182.476	about what's happening in the world.
184.249	And the story said that,
184.249	oh, what's happening is
187.437	that the economy is being globalized,
190.077	politics is being liberalized,
192.244	and the combination of the two
192.244	will create paradise on Earth,
196.267	and we just need to keep on
196.267	globalizing the economy
199.39	and liberalizing the political system,
201.225	and everything will be wonderful.
203.154	And 2016 is the moment
205.91	when a very large segment,
205.91	even of the Western world,
209.894	stopped believing in this story.
212.324	For good or bad reasons --
212.324	it doesn't matter.
214.48	People stopped believing in the story,
216.725	and when you don't have a story,
216.725	you don't understand what's happening.
221.032	CA: Part of you believes that that story
221.032	was actually a very effective story.
225.023	It worked.
226.241	YNH: To some extent, yes.
227.742	According to some measurements,
229.828	we are now in the best time ever
232.437	for humankind.
233.888	Today, for the first time in history,
236.352	more people die from eating too much
236.352	than from eating too little,
240.789	which is an amazing achievement.
242.585	(Laughter)
245.292	Also for the first time in history,
247.017	more people die from old age
247.017	than from infectious diseases,
251.176	and violence is also down.
253.994	For the first time in history,
255.448	more people commit suicide
255.448	than are killed by crime and terrorism
260.803	and war put together.
262.667	Statistically, you are
262.667	your own worst enemy.
266.851	At least, of all the people in the world,
268.881	you are most likely
268.881	to be killed by yourself --
272.027	(Laughter)
273.318	which is, again,
273.318	very good news, compared --
276.386	(Laughter)
278.034	compared to the level of violence
278.034	that we saw in previous eras.
282.359	CA: But this process
282.359	of connecting the world
284.619	ended up with a large group of people
284.619	kind of feeling left out,
288.542	and they've reacted.
290.197	And so we have this bombshell
292.207	that's sort of ripping
292.207	through the whole system.
294.542	I mean, what do you make
294.542	of what's happened?
297.958	It feels like the old way
297.958	that people thought of politics,
301.26	the left-right divide,
301.26	has been blown up and replaced.
304.14	How should we think of this?
305.761	YNH: Yeah, the old 20th-century
305.761	political model of left versus right
310.169	is now largely irrelevant,
311.9	and the real divide today
311.9	is between global and national,
316.426	global or local.
318.239	And you see it again all over the world
321.12	that this is now the main struggle.
323.289	We probably need completely
323.289	new political models
326.749	and completely new ways
326.749	of thinking about politics.
332.319	In essence, what you can say
332.319	is that we now have global ecology,
337.873	we have a global economy
337.873	but we have national politics,
341.838	and this doesn't work together.
343.599	This makes the political
343.599	system ineffective,
345.849	because it has no control
345.849	over the forces that shape our life.
349.397	And you have basically two solutions
349.397	to this imbalance:
352.7	either de-globalize the economy
352.7	and turn it back into a national economy,
357.298	or globalize the political system.
360.768	CA: So some, I guess
360.768	many liberals out there
365.457	view Trump and his government
365.457	as kind of irredeemably bad,
371.917	just awful in every way.
374.6	Do you see any underlying narrative
374.6	or political philosophy in there
381.047	that is at least worth understanding?
382.875	How would you articulate that philosophy?
384.944	Is it just the philosophy of nationalism?
388.074	YNH: I think the underlying
388.074	feeling or idea
393.498	is that the political system --
393.498	something is broken there.
398.014	It doesn't empower
398.014	the ordinary person anymore.
401.808	It doesn't care so much
401.808	about the ordinary person anymore,
405.332	and I think this diagnosis
405.332	of the political disease is correct.
410.175	With regard to the answers,
410.175	I am far less certain.
413.558	I think what we are seeing
413.558	is the immediate human reaction:
417.065	if something doesn't work, let's go back.
419.647	And you see it all over the world,
421.292	that people, almost nobody
421.292	in the political system today,
425.742	has any future-oriented vision
425.742	of where humankind is going.
429.959	Almost everywhere,
429.959	you see retrograde vision:
433.009	"""Let's make America great again,"""
435.079	like it was great -- I don't know --
435.079	in the '50s, in the '80s, sometime,
438.532	let's go back there.
439.726	And you go to Russia
439.726	a hundred years after Lenin,
444.471	Putin's vision for the future
446.366	is basically, ah, let's go back
446.366	to the Tsarist empire.
449.587	And in Israel, where I come from,
452.003	the hottest political vision
452.003	of the present is:
455.279	"""Let's build the temple again."""
457.154	So let's go back 2,000 years backwards.
460.156	So people are thinking
460.156	sometime in the past we've lost it,
465.006	and sometimes in the past, it's like
465.006	you've lost your way in the city,
468.768	and you say OK, let's go back
468.768	to the point where I felt secure
471.942	and start again.
473.328	I don't think this can work,
474.925	but a lot of people,
474.925	this is their gut instinct.
477.851	CA: But why couldn't it work?
479.527	"""America First"" is a very"
479.527	appealing slogan in many ways.
483.19	Patriotism is, in many ways,
483.19	a very noble thing.
487.091	It's played a role
487.091	in promoting cooperation
489.856	among large numbers of people.
491.47	Why couldn't you have a world
491.47	organized in countries,
495.376	all of which put themselves first?
499.193	YNH: For many centuries,
499.193	even thousands of years,
502.536	patriotism worked quite well.
505.322	Of course, it led to wars an so forth,
507.225	but we shouldn't focus
507.225	too much on the bad.
510.204	There are also many,
510.204	many positive things about patriotism,
513.77	and the ability to have
513.77	a large number of people
517.568	care about each other,
519.006	sympathize with one another,
520.636	and come together for collective action.
523.874	If you go back to the first nations,
526.593	so, thousands of years ago,
528.442	the people who lived along
528.442	the Yellow River in China --
531.872	it was many, many different tribes
534.339	and they all depended on the river
534.339	for survival and for prosperity,
538.733	but all of them also suffered
538.733	from periodical floods
543.066	and periodical droughts.
544.69	And no tribe could really do
544.69	anything about it,
547.749	because each of them controlled
547.749	just a tiny section of the river.
551.933	And then in a long
551.933	and complicated process,
554.721	the tribes coalesced together
554.721	to form the Chinese nation,
558.669	which controlled the entire Yellow River
561.327	and had the ability to bring
561.327	hundreds of thousands of people together
566.798	to build dams and canals
566.798	and regulate the river
571.073	and prevent the worst floods and droughts
574.284	and raise the level
574.284	of prosperity for everybody.
577.408	And this worked in many places
577.408	around the world.
580.049	But in the 21st century,
583.199	technology is changing all that
583.199	in a fundamental way.
586.658	We are now living -- all people
586.658	in the world --
589.396	are living alongside the same cyber river,
593.237	and no single nation can regulate
593.237	this river by itself.
598.867	We are all living together
598.867	on a single planet,
602.934	which is threatened by our own actions.
605.719	And if you don't have some kind
605.719	of global cooperation,
609.759	nationalism is just not on the right level
609.759	to tackle the problems,
614.926	whether it's climate change
614.926	or whether it's technological disruption.
619.581	CA: So it was a beautiful idea
621.796	in a world where most of the action,
621.796	most of the issues,
625.768	took place on national scale,
628.148	but your argument is that the issues
628.148	that matter most today
630.97	no longer take place on a national scale
630.97	but on a global scale.
634.138	YNH: Exactly. All the major problems
634.138	of the world today
637.971	are global in essence,
640.384	and they cannot be solved
641.899	unless through some kind
641.899	of global cooperation.
645.82	It's not just climate change,
647.473	which is, like, the most obvious
647.473	example people give.
650.901	I think more in terms
650.901	of technological disruption.
654.003	If you think about, for example,
654.003	artificial intelligence,
657.077	over the next 20, 30 years
660.094	pushing hundreds of millions of people
660.094	out of the job market --
664.002	this is a problem on a global level.
666.277	It will disrupt the economy
666.277	of all the countries.
669.804	And similarly, if you think
669.804	about, say, bioengineering
673.491	and people being afraid of conducting,
676.47	I don't know, genetic engineering
676.47	research in humans,
679.155	it won't help if just
679.155	a single country, let's say the US,
684.468	outlaws all genetic experiments in humans,
687.816	but China or North Korea
687.816	continues to do it.
691.47	So the US cannot solve it by itself,
694.234	and very quickly, the pressure on the US
694.234	to do the same will be immense
699.141	because we are talking about
699.141	high-risk, high-gain technologies.
704.055	If somebody else is doing it,
704.055	I can't allow myself to remain behind.
708.787	The only way to have regulations,
708.787	effective regulations,
714.499	on things like genetic engineering,
716.616	is to have global regulations.
718.652	If you just have national regulations,
718.652	nobody would like to stay behind.
723.714	CA: So this is really interesting.
725.746	It seems to me that this may be one key
727.701	to provoking at least
727.701	a constructive conversation
731.197	between the different sides here,
732.894	because I think everyone can agree
732.894	that the start point
736.06	of a lot of the anger
736.06	that's propelled us to where we are
738.781	is because of the legitimate
738.781	concerns about job loss.
741.553	Work is gone, a traditional
741.553	way of life has gone,
745.218	and it's no wonder
745.218	that people are furious about that.
748.617	And in general, they have blamed
748.617	globalism, global elites,
753.193	for doing this to them
753.193	without asking their permission,
755.964	and that seems like
755.964	a legitimate complaint.
758.083	But what I hear you saying
758.083	is that -- so a key question is:
761.416	What is the real cause of job loss,
761.416	both now and going forward?
766.901	To the extent that it's about globalism,
769.701	then the right response,
769.701	yes, is to shut down borders
773.847	and keep people out
773.847	and change trade agreements and so forth.
777.851	But you're saying, I think,
779.231	that actually the bigger cause of job loss
779.231	is not going to be that at all.
784.046	It's going to originate
784.046	in technological questions,
787.784	and we have no chance of solving that
789.82	unless we operate as a connected world.
791.939	YNH: Yeah, I think that,
793.482	I don't know about the present,
793.482	but looking to the future,
796.747	it's not the Mexicans or Chinese
796.747	who will take the jobs
799.848	from the people in Pennsylvania,
801.439	it's the robots and algorithms.
803.206	So unless you plan to build a big wall
803.206	on the border of California --
807.414	(Laughter)
808.572	the wall on the border with Mexico
808.572	is going to be very ineffective.
812.287	And I was struck when I watched
812.287	the debates before the election,
818.659	I was struck that certainly Trump
818.659	did not even attempt to frighten people
824.42	by saying the robots will take your jobs.
827.02	Now even if it's not true,
827.02	it doesn't matter.
829.343	It could have been an extremely
829.343	effective way of frightening people --
832.885	(Laughter)
833.91	and galvanizing people:
835.095	"""The robots will take your jobs!"""
836.728	And nobody used that line.
838.107	And it made me afraid,
840.823	because it meant
840.823	that no matter what happens
844.895	in universities and laboratories,
847.065	and there, there is already
847.065	an intense debate about it,
849.854	but in the mainstream political system
849.854	and among the general public,
853.972	people are just unaware
856.106	that there could be an immense
856.106	technological disruption --
860.64	not in 200 years,
860.64	but in 10, 20, 30 years --
864.786	and we have to do something about it now,
867.38	partly because most of what we teach
867.38	children today in school or in college
873.68	is going to be completely irrelevant
873.68	to the job market of 2040, 2050.
879.705	So it's not something we'll need
879.705	to think about in 2040.
883.087	We need to think today
883.087	what to teach the young people.
886.704	CA: Yeah, no, absolutely.
890.415	You've often written about
890.415	moments in history
894.356	where humankind has ...
894.356	entered a new era, unintentionally.
901.626	Decisions have been made,
901.626	technologies have been developed,
904.518	and suddenly the world has changed,
906.913	possibly in a way
906.913	that's worse for everyone.
909.404	So one of the examples
909.404	"you give in ""Sapiens"""
911.503	is just the whole agricultural revolution,
913.618	which, for an actual person
913.618	tilling the fields,
917.196	they just picked up a 12-hour
917.196	backbreaking workday
920.4	instead of six hours in the jungle
920.4	and a much more interesting lifestyle.
926.672	(Laughter)
927.738	So are we at another possible
927.738	phase change here,
930.951	where we kind of sleepwalk into a future
930.951	that none of us actually wants?
935.878	YNH: Yes, very much so.
938.635	During the agricultural revolution,
940.496	what happened is that immense
940.496	technological and economic revolution
944.94	empowered the human collective,
947.829	but when you look at actual
947.829	individual lives,
950.806	the life of a tiny elite
950.806	became much better,
954.324	and the lives of the majority of people
954.324	became considerably worse.
958.586	And this can happen again
958.586	in the 21st century.
961.315	No doubt the new technologies
961.315	will empower the human collective.
966.205	But we may end up again
968.949	with a tiny elite reaping
968.949	all the benefits, taking all the fruits,
973.43	and the masses of the population
973.43	finding themselves worse
977.64	than they were before,
978.965	certainly much worse than this tiny elite.
982.477	CA: And those elites
982.477	might not even be human elites.
985.156	They might be cyborgs or --
986.937	YNH: Yeah, they could be
986.937	enhanced super humans.
989.168	They could be cyborgs.
990.447	They could be completely
990.447	nonorganic elites.
992.828	They could even be
992.828	non-conscious algorithms.
995.38	What we see now in the world
995.38	is authority shifting away
1000.315	from humans to algorithms.
1002.608	More and more decisions --
1002.608	about personal lives,
1006.156	about economic matters,
1006.156	about political matters --
1008.852	are actually being taken by algorithms.
1011.355	If you ask the bank for a loan,
1014.013	chances are your fate is decided
1014.013	by an algorithm, not by a human being.
1018.734	And the general impression
1018.734	is that maybe Homo sapiens just lost it.
1024.945	The world is so complicated,
1024.945	there is so much data,
1029.529	things are changing so fast,
1032.107	that this thing that evolved
1032.107	on the African savanna
1035.732	tens of thousands of years ago --
1037.463	to cope with a particular environment,
1040.984	a particular volume
1040.984	of information and data --
1044.492	it just can't handle the realities
1044.492	of the 21st century,
1048.852	and the only thing
1048.852	that may be able to handle it
1051.773	is big-data algorithms.
1053.869	So no wonder more and more authority
1053.869	is shifting from us to the algorithms.
1060.677	CA: So we're in New York City
1060.677	for the first of a series of TED Dialogues
1064.55	with Yuval Harari,
1066.871	and there's a Facebook Live
1066.871	audience out there.
1070.739	We're excited to have you with us.
1072.414	We'll start coming
1072.414	to some of your questions
1074.54	and questions of people in the room
1076.278	in just a few minutes,
1077.467	so have those coming.
1079.455	Yuval, if you're going
1079.455	to make the argument
1083.376	that we need to get past nationalism
1083.376	because of the coming technological ...
1091.038	danger, in a way,
1092.903	presented by so much of what's happening
1094.872	we've got to have
1094.872	a global conversation about this.
1097.339	Trouble is, it's hard to get people
1097.339	really believing that, I don't know,
1100.791	AI really is an imminent
1100.791	threat, and so forth.
1102.976	The things that people,
1102.976	some people at least,
1105.726	care about much more immediately, perhaps,
1107.785	is climate change,
1109.393	perhaps other issues like refugees,
1109.393	nuclear weapons, and so forth.
1114.31	Would you argue that where
1114.31	we are right now
1119.38	that somehow those issues
1119.38	need to be dialed up?
1122.953	You've talked about climate change,
1125.137	but Trump has said
1125.137	he doesn't believe in that.
1128.817	So in a way, your most powerful argument,
1131.28	you can't actually use to make this case.
1134.05	YNH: Yeah, I think with climate change,
1136.26	at first sight, it's quite surprising
1139.991	that there is a very close correlation
1142.519	between nationalism and climate change.
1145.865	I mean, almost always, the people
1145.865	who deny climate change are nationalists.
1150.476	And at first sight, you think: Why?
1152.581	What's the connection?
1153.758	Why don't you have socialists
1153.758	denying climate change?
1156.568	But then, when you think
1156.568	about it, it's obvious --
1158.943	because nationalism has no solution
1158.943	to climate change.
1162.711	If you want to be a nationalist
1162.711	in the 21st century,
1165.931	you have to deny the problem.
1167.827	If you accept the reality of the problem,
1167.827	then you must accept that, yes,
1172.338	there is still room in the world
1172.338	for patriotism,
1175.138	there is still room in the world
1175.138	for having special loyalties
1179.313	and obligations towards your own people,
1179.313	towards your own country.
1183.971	I don't think anybody is really
1183.971	thinking of abolishing that.
1187.815	But in order to confront climate change,
1190.84	we need additional loyalties
1190.84	and commitments
1195.075	to a level beyond the nation.
1197.104	And that should not be impossible,
1199.571	because people can have
1199.571	several layers of loyalty.
1203.287	You can be loyal to your family
1205.715	and to your community
1207.252	and to your nation,
1208.605	so why can't you also be loyal
1208.605	to humankind as a whole?
1212.257	Of course, there are occasions
1212.257	when it becomes difficult,
1215.68	what to put first,
1217.487	but, you know, life is difficult.
1219.334	Handle it.
1220.509	(Laughter)
1223.177	CA: OK, so I would love to get
1223.177	some questions from the audience here.
1227.699	We've got a microphone here.
1229.641	Speak into it, and Facebook,
1229.641	get them coming, too.
1232.882	Howard Morgan: One of the things that has
1232.882	clearly made a huge difference
1236.34	in this country and other countries
1238.15	is the income distribution inequality,
1240.388	the dramatic change
1240.388	in income distribution in the US
1244.626	from what it was 50 years ago,
1246.352	and around the world.
1247.527	Is there anything we can do
1247.527	to affect that?
1250.694	Because that gets at a lot
1250.694	of the underlying causes.
1256.103	YNH: So far I haven't heard a very
1256.103	good idea about what to do about it,
1261.441	again, partly because most ideas
1261.441	remain on the national level,
1265.193	and the problem is global.
1266.985	I mean, one idea that we hear
1266.985	quite a lot about now
1269.987	is universal basic income.
1271.843	But this is a problem.
1273.018	I mean, I think it's a good start,
1274.694	but it's a problematic idea because
1274.694	"it's not clear what ""universal"" is"
1278.44	"and it's not clear what ""basic"" is."
1280.305	Most people when they speak
1280.305	about universal basic income,
1283.71	they actually mean national basic income.
1286.519	But the problem is global.
1288.287	Let's say that you have AI and 3D printers
1288.287	taking away millions of jobs
1293.961	in Bangladesh,
1295.141	from all the people who make
1295.141	my shirts and my shoes.
1298.413	So what's going to happen?
1299.743	The US government will levy taxes
1299.743	on Google and Apple in California,
1306.306	and use that to pay basic income
1306.306	to unemployed Bangladeshis?
1310.911	If you believe that,
1310.911	you can just as well believe
1313.571	that Santa Claus will come
1313.571	and solve the problem.
1317.258	So unless we have really universal
1317.258	and not national basic income,
1322.408	the deep problems
1322.408	are not going to go away.
1325.567	And also it's not clear what basic is,
1328.323	because what are basic human needs?
1330.98	A thousand years ago,
1330.98	just food and shelter was enough.
1333.814	But today, people will say
1333.814	education is a basic human need,
1337.449	it should be part of the package.
1339.046	But how much? Six years?
1339.046	Twelve years? PhD?
1342.849	Similarly, with health care,
1344.706	let's say that in 20, 30, 40 years,
1347.415	you'll have expensive treatments
1347.415	that can extend human life
1351.212	to 120, I don't know.
1353.151	Will this be part of the basket
1353.151	of basic income or not?
1358.366	It's a very difficult problem,
1359.819	because in a world where people
1359.819	lose their ability to be employed,
1366.101	the only thing they are going to get
1366.101	is this basic income.
1369.706	So what's part of it is a very,
1369.706	very difficult ethical question.
1374.857	CA: There's a bunch of questions
1374.857	on how the world affords it as well,
1378.185	who pays.
1379.369	There's a question here
1379.369	from Facebook from Lisa Larson:
1382.205	"""How does nationalism in the US now"
1384.804	compare to that between
1384.804	World War I and World War II
1388.243	"in the last century?"""
1389.688	YNH: Well the good news, with regard
1389.688	to the dangers of nationalism,
1394.16	we are in a much better position
1394.16	than a century ago.
1398.107	A century ago, 1917,
1400.803	Europeans were killing
1400.803	each other by the millions.
1403.96	In 2016, with Brexit,
1403.96	as far as I remember,
1408.335	a single person lost their life,
1408.335	an MP who was murdered by some extremist.
1413.596	Just a single person.
1415.153	I mean, if Brexit was about
1415.153	British independence,
1417.862	this is the most peaceful
1417.862	war of independence in human history.
1422.637	And let's say that Scotland
1422.637	will now choose to leave the UK
1428.45	after Brexit.
1430.65	So in the 18th century,
1432.658	if Scotland wanted -- and the Scots
1432.658	wanted several times --
1435.914	to break out of the control of London,
1439.471	the reaction of the government
1439.471	in London was to send an army up north
1443.793	to burn down Edinburgh
1443.793	and massacre the highland tribes.
1447.288	My guess is that if, in 2018,
1447.288	the Scots vote for independence,
1452.868	the London government
1452.868	will not send an army up north
1456.301	to burn down Edinburgh.
1457.928	Very few people are now willing
1457.928	to kill or be killed
1462.219	for Scottish or for British independence.
1464.965	So for all the talk
1464.965	of the rise of nationalism
1470.009	and going back to the 1930s,
1472.276	to the 19th century, in the West at least,
1476.075	the power of national sentiments
1476.075	today is far, far smaller
1482.683	than it was a century ago.
1484.247	CA: Although some people now,
1484.247	you hear publicly worrying
1488.108	about whether that might be shifting,
1490.888	that there could actually be
1490.888	outbreaks of violence in the US
1494.31	depending on how things turn out.
1496.681	Should we be worried about that,
1498.244	or do you really think
1498.244	things have shifted?
1500.334	YNH: No, we should be worried.
1501.849	We should be aware of two things.
1503.498	First of all, don't be hysterical.
1505.159	We are not back
1505.159	in the First World War yet.
1508.63	But on the other hand,
1508.63	don't be complacent.
1511.594	We reached from 1917 to 2017,
1516.992	not by some divine miracle,
1519.198	but simply by human decisions,
1521.246	and if we now start making
1521.246	the wrong decisions,
1523.933	we could be back
1523.933	in an analogous situation to 1917
1528.442	in a few years.
1529.972	One of the things I know as a historian
1532.317	is that you should never
1532.317	underestimate human stupidity.
1536.016	(Laughter)
1538.923	It's one of the most powerful
1538.923	forces in history,
1542.031	human stupidity and human violence.
1544.382	Humans do such crazy things
1544.382	for no obvious reason,
1548.511	but again, at the same time,
1550.245	another very powerful force
1550.245	in human history is human wisdom.
1553.873	We have both.
1555.063	CA: We have with us here
1555.063	moral psychologist Jonathan Haidt,
1557.989	who I think has a question.
1560.691	Jonathan Haidt: Thanks, Yuval.
1562.198	So you seem to be a fan
1562.198	of global governance,
1564.705	but when you look at the map of the world
1564.705	from Transparency International,
1568.249	which rates the level of corruption
1568.249	of political institutions,
1571.601	it's a vast sea of red with little bits
1571.601	of yellow here and there
1574.705	for those with good institutions.
1576.334	So if we were to have
1576.334	some kind of global governance,
1578.859	what makes you think it would end up
1578.859	being more like Denmark
1581.714	rather than more like Russia or Honduras,
1583.778	and aren't there alternatives,
1585.303	such as we did with CFCs?
1587.413	There are ways to solve global problems
1587.413	with national governments.
1590.544	What would world government
1590.544	actually look like,
1592.782	and why do you think it would work?
1594.527	YNH: Well, I don't know
1594.527	what it would look like.
1598.311	Nobody still has a model for that.
1601.387	The main reason we need it
1604.039	is because many of these issues
1604.039	are lose-lose situations.
1608.357	When you have
1608.357	a win-win situation like trade,
1611.273	both sides can benefit
1611.273	from a trade agreement,
1614.213	then this is something you can work out.
1616.501	Without some kind of global government,
1618.871	national governments each
1618.871	have an interest in doing it.
1621.749	But when you have a lose-lose situation
1621.749	like with climate change,
1625.744	it's much more difficult
1627.409	without some overarching
1627.409	authority, real authority.
1632.319	Now, how to get there
1632.319	and what would it look like,
1635.105	I don't know.
1636.489	And certainly there is no obvious reason
1640.25	to think that it would look like Denmark,
1642.554	or that it would be a democracy.
1644.166	Most likely it wouldn't.
1646.776	We don't have workable democratic models
1652.831	for a global government.
1654.951	So maybe it would look more
1654.951	like ancient China
1658.04	than like modern Denmark.
1659.763	But still, given the dangers
1659.763	that we are facing,
1665.01	I think the imperative of having
1665.01	some kind of real ability
1670.154	to force through difficult decisions
1670.154	on the global level
1674.306	is more important
1674.306	than almost anything else.
1679.411	CA: There's a question from Facebook here,
1681.533	and then we'll get the mic to Andrew.
1683.45	So, Kat Hebron on Facebook,
1685.67	calling in from Vail:
1687.362	"""How would developed nations manage"
1687.362	"the millions of climate migrants?"""
1692.638	YNH: I don't know.
1694.816	CA: That's your answer, Kat. (Laughter)
1696.732	YNH: And I don't think
1696.732	that they know either.
1698.902	They'll just deny the problem, maybe.
1700.72	CA: But immigration, generally,
1700.72	is another example of a problem
1703.769	that's very hard to solve
1703.769	on a nation-by-nation basis.
1706.366	One nation can shut its doors,
1707.86	but maybe that stores up
1707.86	problems for the future.
1710.418	YNH: Yes, I mean --
1710.418	it's another very good case,
1714.314	especially because it's so much easier
1716.567	to migrate today
1718.422	than it was in the Middle Ages
1718.422	or in ancient times.
1722.135	CA: Yuval, there's a belief
1722.135	among many technologists, certainly,
1726.622	that political concerns
1726.622	are kind of overblown,
1728.997	that actually, political leaders
1728.997	don't have that much influence
1732.718	in the world,
1733.908	that the real determination of humanity
1733.908	at this point is by science,
1737.901	by invention, by companies,
1739.371	by many things
1739.371	other than political leaders,
1743.787	and it's actually very hard
1743.787	for leaders to do much,
1746.222	so we're actually worrying
1746.222	about nothing here.
1749.825	YNH: Well, first, it should be emphasized
1752.085	that it's true that political leaders'
1752.085	ability to do good is very limited,
1757.106	but their ability to do harm is unlimited.
1760.173	There is a basic imbalance here.
1762.797	You can still press the button
1762.797	and blow everybody up.
1766.389	You have that kind of ability.
1767.999	But if you want, for example,
1767.999	to reduce inequality,
1771.592	that's very, very difficult.
1773.493	But to start a war,
1774.913	you can still do so very easily.
1776.788	So there is a built-in imbalance
1776.788	in the political system today
1780.404	which is very frustrating,
1782.039	where you cannot do a lot of good
1782.039	but you can still do a lot of harm.
1786.964	And this makes the political system
1786.964	still a very big concern.
1791.632	CA: So as you look at
1791.632	what's happening today,
1793.807	and putting your historian's hat on,
1795.585	do you look back in history at moments
1795.585	when things were going just fine
1799.135	and an individual leader really took
1799.135	the world or their country backwards?
1805.127	YNH: There are quite a few examples,
1807.78	but I should emphasize,
1807.78	it's never an individual leader.
1810.623	I mean, somebody put him there,
1812.281	and somebody allowed him
1812.281	to continue to be there.
1815.588	So it's never really just the fault
1815.588	of a single individual.
1819.695	There are a lot of people
1819.695	behind every such individual.
1824.332	CA: Can we have the microphone
1824.332	here, please, to Andrew?
1830.952	Andrew Solomon: You've talked a lot
1830.952	about the global versus the national,
1834.54	but increasingly, it seems to me,
1836.19	the world situation
1836.19	is in the hands of identity groups.
1838.857	We look at people within the United States
1841.191	who have been recruited by ISIS.
1842.842	We look at these other groups
1842.842	which have formed
1845.057	which go outside of national bounds
1847.043	but still represent
1847.043	significant authorities.
1849.228	How are they to be integrated
1849.228	into the system,
1851.68	and how is a diverse set of identities
1851.68	to be made coherent
1855.417	under either national
1855.417	or global leadership?
1859.2	YNH: Well, the problem
1859.2	of such diverse identities
1862.445	is a problem from nationalism as well.
1865.049	Nationalism believes
1865.049	in a single, monolithic identity,
1869.428	and exclusive or at least
1869.428	more extreme versions of nationalism
1873.568	believe in an exclusive loyalty
1873.568	to a single identity.
1877.161	And therefore, nationalism has had
1877.161	a lot of problems
1880.101	with people wanting to divide
1880.101	their identities
1883.001	between various groups.
1885.088	So it's not just a problem, say,
1885.088	for a global vision.
1890.36	And I think, again, history shows
1894.236	that you shouldn't necessarily
1894.236	think in such exclusive terms.
1900.387	If you think that there is just
1900.387	a single identity for a person,
1903.819	"""I am just X, that's it, I can't be"
1903.819	"several things, I can be just that,"""
1908.883	that's the start of the problem.
1911.003	You have religions, you have nations
1913.815	that sometimes demand exclusive loyalty,
1917.021	but it's not the only option.
1918.776	There are many religions and many nations
1921.182	that enable you to have
1921.182	diverse identities at the same time.
1925.084	CA: But is one explanation
1925.084	of what's happened in the last year
1929.465	that a group of people have got
1929.465	fed up with, if you like,
1934.669	the liberal elites,
1934.669	for want of a better term,
1937.86	obsessing over many, many different
1937.86	identities and them feeling,
1942.257	"""But what about my identity?"
1942.257	I am being completely ignored here.
1946.14	And by the way, I thought
1946.14	"I was the majority""?"
1949.138	And that that's actually
1949.138	sparked a lot of the anger.
1952.738	YNH: Yeah. Identity is always problematic,
1955.907	because identity is always based
1955.907	on fictional stories
1960.241	that sooner or later collide with reality.
1963.71	Almost all identities,
1965.252	I mean, beyond the level
1965.252	of the basic community
1968.687	of a few dozen people,
1970.18	are based on a fictional story.
1972.133	They are not the truth.
1973.798	They are not the reality.
1975.137	It's just a story that people invent
1975.137	and tell one another
1978.255	and start believing.
1979.77	And therefore all identities
1979.77	are extremely unstable.
1985.114	They are not a biological reality.
1987.665	Sometimes nationalists, for example,
1989.695	think that the nation
1989.695	is a biological entity.
1992.646	It's made of the combination
1992.646	of soil and blood,
1996.283	creates the nation.
1998.009	But this is just a fictional story.
2001.125	CA: Soil and blood
2001.125	kind of makes a gooey mess.
2003.712	(Laughter)
2005.558	YNH: It does, and also
2005.558	it messes with your mind
2008.606	when you think too much
2008.606	that I am a combination of soil and blood.
2013.414	If you look from a biological perspective,
2016.305	obviously none of the nations
2016.305	that exist today
2019.807	existed 5,000 years ago.
2022.074	Homo sapiens is a social animal,
2022.074	that's for sure.
2025.956	But for millions of years,
2028.407	Homo sapiens and our hominid ancestors
2028.407	lived in small communities
2033.07	of a few dozen individuals.
2035.423	Everybody knew everybody else.
2037.574	Whereas modern nations
2037.574	are imagined communities,
2041.619	in the sense that I don't even know
2041.619	all these people.
2044.194	I come from a relatively
2044.194	small nation, Israel,
2047.066	and of eight million Israelis,
2049.233	I never met most of them.
2051.247	I will never meet most of them.
2053.579	They basically exist here.
2056.165	CA: But in terms of this identity,
2058.938	this group who feel left out
2058.938	and perhaps have work taken away,
2064.399	"I mean, in ""Homo Deus,"""
2066.717	you actually speak of this group
2066.717	in one sense expanding,
2069.852	that so many people
2069.852	may have their jobs taken away
2073.498	by technology in some way
2073.498	that we could end up with
2077.902	a really large -- I think you call it
2077.902	"a ""useless class"" --"
2081.097	a class where traditionally,
2083.224	as viewed by the economy,
2083.224	these people have no use.
2085.979	YNH: Yes.
2087.201	CA: How likely a possibility is that?
2090.156	Is that something
2090.156	we should be terrified about?
2092.924	And can we address it in any way?
2095.607	YNH: We should think about it
2095.607	very carefully.
2097.878	I mean, nobody really knows
2097.878	what the job market will look like
2100.873	in 2040, 2050.
2102.587	There is a chance
2102.587	many new jobs will appear,
2105.319	but it's not certain.
2107.097	And even if new jobs do appear,
2109.332	it won't necessarily be easy
2111.34	for a 50-year old unemployed truck driver
2114.363	made unemployed by self-driving vehicles,
2117.42	it won't be easy
2117.42	for an unemployed truck driver
2121.097	to reinvent himself or herself
2121.097	as a designer of virtual worlds.
2125.907	Previously, if you look at the trajectory
2125.907	of the industrial revolution,
2130.113	when machines replaced humans
2130.113	in one type of work,
2134.294	the solution usually came
2134.294	from low-skill work
2138.599	in new lines of business.
2141.211	So you didn't need any more
2141.211	agricultural workers,
2144.637	so people moved to working
2144.637	in low-skill industrial jobs,
2150.075	and when this was taken away
2150.075	by more and more machines,
2153.568	people moved to low-skill service jobs.
2156.562	Now, when people say there will
2156.562	be new jobs in the future,
2159.946	that humans can do better than AI,
2162.399	that humans can do better than robots,
2164.253	they usually think about high-skill jobs,
2166.917	like software engineers
2166.917	designing virtual worlds.
2170.812	Now, I don't see how
2170.812	an unemployed cashier from Wal-Mart
2176.23	reinvents herself or himself at 50
2176.23	as a designer of virtual worlds,
2180.877	and certainly I don't see
2182.372	how the millions of unemployed
2182.372	Bangladeshi textile workers
2185.863	will be able to do that.
2187.498	I mean, if they are going to do it,
2189.242	we need to start teaching
2189.242	the Bangladeshis today
2192.622	how to be software designers,
2194.4	and we are not doing it.
2195.667	So what will they do in 20 years?
2198.182	CA: So it feels like you're really
2198.182	highlighting a question
2202.12	that's really been bugging me
2202.12	the last few months more and more.
2206.327	It's almost a hard question
2206.327	to ask in public,
2209.206	but if any mind has some wisdom
2209.206	to offer in it, maybe it's yours,
2212.621	so I'm going to ask you:
2214.19	What are humans for?
2217.052	YNH: As far as we know, for nothing.
2219.01	(Laughter)
2220.746	I mean, there is no great cosmic drama,
2220.746	some great cosmic plan,
2226.296	that we have a role to play in.
2229.161	And we just need to discover
2229.161	what our role is
2232.209	and then play it to the best
2232.209	of our ability.
2235.225	This has been the story of all religions
2235.225	and ideologies and so forth,
2240.227	but as a scientist, the best I can say
2240.227	is this is not true.
2243.729	There is no universal drama
2243.729	with a role in it for Homo sapiens.
2249.111	So --
2250.816	CA: I'm going to push back on you
2250.816	just for a minute,
2253.333	just from your own book,
2254.551	"because in ""Homo Deus,"""
2255.899	you give really one of the most coherent
2255.899	and understandable accounts
2260.982	about sentience, about consciousness,
2263.238	and that unique sort of human skill.
2266.22	You point out that it's different
2266.22	from intelligence,
2268.737	the intelligence
2268.737	that we're building in machines,
2271.095	and that there's actually a lot
2271.095	of mystery around it.
2274.777	How can you be sure there's no purpose
2278.178	when we don't even understand
2278.178	what this sentience thing is?
2282.253	I mean, in your own thinking,
2282.253	isn't there a chance
2284.853	that what humans are for
2284.853	is to be the universe's sentient things,
2289.189	to be the centers of joy and love
2289.189	and happiness and hope?
2292.636	And maybe we can build machines
2292.636	that actually help amplify that,
2295.695	even if they're not going to become
2295.695	sentient themselves?
2298.383	Is that crazy?
2299.558	I kind of found myself hoping that,
2299.558	reading your book.
2303.065	YNH: Well, I certainly think that the most
2303.065	interesting question today in science
2306.946	is the question
2306.946	of consciousness and the mind.
2309.393	We are getting better and better
2309.393	in understanding the brain
2312.915	and intelligence,
2314.199	but we are not getting much better
2316.76	in understanding the mind
2316.76	and consciousness.
2319.127	People often confuse intelligence
2319.127	and consciousness,
2322.513	especially in places like Silicon Valley,
2324.836	which is understandable,
2324.836	because in humans, they go together.
2328.617	I mean, intelligence basically
2328.617	is the ability to solve problems.
2332.22	Consciousness is the ability
2332.22	to feel things,
2334.786	to feel joy and sadness
2334.786	and boredom and pain and so forth.
2340.022	In Homo sapiens and all other mammals
2340.022	as well -- it's not unique to humans --
2344.085	in all mammals and birds
2344.085	and some other animals,
2346.756	intelligence and consciousness
2346.756	go together.
2349.43	We often solve problems by feeling things.
2353.032	So we tend to confuse them.
2354.549	But they are different things.
2356.038	What's happening today
2356.038	in places like Silicon Valley
2359.15	is that we are creating
2359.15	artificial intelligence
2362.8	but not artificial consciousness.
2364.646	There has been an amazing development
2364.646	in computer intelligence
2368.05	over the last 50 years,
2369.636	and exactly zero development
2369.636	in computer consciousness,
2373.861	and there is no indication that computers
2373.861	are going to become conscious
2377.571	anytime soon.
2380.126	So first of all, if there is
2380.126	some cosmic role for consciousness,
2385.8	it's not unique to Homo sapiens.
2387.954	Cows are conscious, pigs are conscious,
2390.297	chimpanzees are conscious,
2390.297	chickens are conscious,
2393.154	so if we go that way, first of all,
2393.154	we need to broaden our horizons
2397.031	and remember very clearly we are not
2397.031	the only sentient beings on Earth,
2401.78	and when it comes to sentience --
2403.599	when it comes to intelligence,
2403.599	there is good reason to think
2406.935	we are the most intelligent
2406.935	of the whole bunch.
2410.255	But when it comes to sentience,
2412.853	to say that humans are more
2412.853	sentient than whales,
2416.035	or more sentient than baboons
2416.035	or more sentient than cats,
2420.206	I see no evidence for that.
2422.524	So first step is, you go
2422.524	in that direction, expand.
2426.155	And then the second question
2426.155	of what is it for,
2430.161	I would reverse it
2431.967	and I would say that I don't think
2431.967	sentience is for anything.
2436.227	I think we don't need
2436.227	to find our role in the universe.
2440.423	The really important thing
2440.423	is to liberate ourselves from suffering.
2446.26	What characterizes sentient beings
2449.277	in contrast to robots, to stones,
2452.021	to whatever,
2453.228	is that sentient beings
2453.228	suffer, can suffer,
2457.043	and what they should focus on
2459.407	is not finding their place
2459.407	in some mysterious cosmic drama.
2463.551	They should focus on understanding
2463.551	what suffering is,
2467.394	what causes it and how
2467.394	to be liberated from it.
2471.392	CA: I know this is a big issue for you,
2471.392	and that was very eloquent.
2474.893	We're going to have a blizzard
2474.893	of questions from the audience here,
2478.331	and maybe from Facebook as well,
2480.275	and maybe some comments as well.
2481.972	So let's go quick.
2483.792	There's one right here.
2486.872	Keep your hands held up
2486.872	at the back if you want the mic,
2489.705	and we'll get it back to you.
2491.148	Question: In your work, you talk a lot
2491.148	about the fictional stories
2494.291	that we accept as truth,
2495.659	and we live our lives by it.
2497.4	As an individual, knowing that,
2499.923	how does it impact the stories
2499.923	that you choose to live your life,
2503.693	and do you confuse them
2503.693	with the truth, like all of us?
2508.066	YNH: I try not to.
2509.301	I mean, for me, maybe the most
2509.301	important question,
2512.093	both as a scientist and as a person,
2514.595	is how to tell the difference
2514.595	between fiction and reality,
2518.494	because reality is there.
2521.114	I'm not saying that everything is fiction.
2523.22	It's just very difficult for human beings
2523.22	to tell the difference
2526.296	between fiction and reality,
2527.937	and it has become more and more difficult
2527.937	as history progressed,
2532.906	because the fictions
2532.906	that we have created --
2535.381	nations and gods and money
2535.381	and corporations --
2538.573	they now control the world.
2540.107	So just to even think,
2541.308	"""Oh, this is just all fictional entities"
2541.308	"that we've created,"""
2544.477	is very difficult.
2545.948	But reality is there.
2548.863	For me the best ...
2550.892	There are several tests
2553.039	to tell the difference
2553.039	between fiction and reality.
2555.833	The simplest one, the best one
2555.833	that I can say in short,
2559.283	is the test of suffering.
2560.888	If it can suffer, it's real.
2563.012	If it can't suffer, it's not real.
2564.73	A nation cannot suffer.
2566.219	That's very, very clear.
2567.813	Even if a nation loses a war,
2569.775	"we say, ""Germany suffered a defeat"
2569.775	"in the First World War,"""
2573.864	it's a metaphor.
2575.053	Germany cannot suffer.
2575.053	Germany has no mind.
2577.634	Germany has no consciousness.
2579.311	Germans can suffer, yes,
2579.311	but Germany cannot.
2582.993	Similarly, when a bank goes bust,
2585.986	the bank cannot suffer.
2587.781	When the dollar loses its value,
2587.781	the dollar doesn't suffer.
2591.196	People can suffer. Animals can suffer.
2593.47	This is real.
2594.65	So I would start, if you
2594.65	really want to see reality,
2599.203	I would go through the door of suffering.
2601.291	If you can really understand
2601.291	what suffering is,
2604.269	this will give you also the key
2606.516	to understand what reality is.
2608.557	CA: There's a Facebook question
2608.557	here that connects to this,
2611.364	from someone around the world
2611.364	in a language that I cannot read.
2614.365	YNH: Oh, it's Hebrew.
2614.365	CA: Hebrew. There you go.
2616.606	(Laughter)
2617.692	Can you read the name?
2618.88	YNH: Or Lauterbach Goren.
2620.779	CA: Well, thank you for writing in.
2622.647	"The question is: ""Is the post-truth era"
2622.647	really a brand-new era,
2627.226	or just another climax or moment
2627.226	in a never-ending trend?
2632.521	YNH: Personally, I don't connect
2632.521	with this idea of post-truth.
2635.874	My basic reaction as a historian is:
2638.606	If this is the era of post-truth,
2638.606	when the hell was the era of truth?
2642.525	CA: Right.
2643.8	(Laughter)
2645.144	YNH: Was it the 1980s, the 1950s,
2645.144	the Middle Ages?
2649.851	I mean, we have always lived
2649.851	in an era, in a way, of post-truth.
2654.703	CA: But I'd push back on that,
2657.038	because I think what people
2657.038	are talking about
2659.732	is that there was a world
2659.732	where you had fewer journalistic outlets,
2666.716	where there were traditions,
2666.716	that things were fact-checked.
2670.388	It was incorporated into the charter
2670.388	of those organizations
2674.357	that the truth mattered.
2676.548	So if you believe in a reality,
2678.321	then what you write is information.
2680.568	There was a belief that that information
2680.568	should connect to reality in a real way,
2684.413	and if you wrote a headline,
2684.413	it was a serious, earnest attempt
2687.398	to reflect something
2687.398	that had actually happened.
2689.725	And people didn't always get it right.
2691.6	But I think the concern now is you've got
2693.633	a technological system
2693.633	that's incredibly powerful
2695.975	that, for a while at least,
2695.975	massively amplified anything
2700.169	with no attention paid to whether
2700.169	it connected to reality,
2702.973	only to whether it connected
2702.973	to clicks and attention,
2706.151	and that that was arguably toxic.
2707.791	That's a reasonable concern, isn't it?
2710.251	YNH: Yeah, it is. I mean,
2710.251	the technology changes,
2712.561	and it's now easier to disseminate
2712.561	both truth and fiction and falsehood.
2717.813	It goes both ways.
2719.84	It's also much easier, though, to spread
2719.84	the truth than it was ever before.
2724.443	But I don't think there
2724.443	is anything essentially new
2728.152	about this disseminating
2728.152	fictions and errors.
2732.896	There is nothing that -- I don't know --
2732.896	Joseph Goebbels, didn't know
2736.954	about all this idea of fake
2736.954	news and post-truth.
2742.417	He famously said that if you repeat
2742.417	a lie often enough,
2746.159	people will think it's the truth,
2748.004	and the bigger the lie, the better,
2750.384	because people won't even think
2750.384	that something so big can be a lie.
2756.431	I think that fake news
2756.431	has been with us for thousands of years.
2762.113	Just think of the Bible.
2764.038	(Laughter)
2765.449	CA: But there is a concern
2766.76	that the fake news is associated
2766.76	with tyrannical regimes,
2770.801	and when you see an uprise in fake news
2773.402	that is a canary in the coal mine
2773.402	that there may be dark times coming.
2779.944	YNH: Yeah. I mean, the intentional use
2779.944	of fake news is a disturbing sign.
2787.632	But I'm not saying that it's not bad,
2787.632	I'm just saying that it's not new.
2792.64	CA: There's a lot of interest
2792.64	on Facebook on this question
2795.418	about global governance
2795.418	versus nationalism.
2801.112	Question here from Phil Dennis:
2802.644	"""How do we get people, governments,"
2802.644	to relinquish power?
2806.164	Is that -- is that --
2806.164	actually, the text is so big
2810.103	I can't read the full question.
2811.667	But is that a necessity?
2813.23	Is it going to take war to get there?
2815.866	Sorry Phil -- I mangled your question,
2815.866	but I blame the text right here.
2819.58	YNH: One option
2819.58	that some people talk about
2821.704	is that only a catastrophe
2821.704	can shake humankind
2826.467	and open the path to a real system
2826.467	of global governance,
2831.755	and they say that we can't do it
2831.755	before the catastrophe,
2835.927	but we need to start
2835.927	laying the foundations
2838.752	so that when the disaster strikes,
2841.276	we can react quickly.
2843.482	But people will just not have
2843.482	the motivation to do such a thing
2847.506	before the disaster strikes.
2849.542	Another thing that I would emphasize
2851.831	is that anybody who is really
2851.831	interested in global governance
2856.909	should always make it very, very clear
2859.834	that it doesn't replace or abolish
2859.834	local identities and communities,
2866.442	that it should come both as --
2869.422	It should be part of a single package.
2872.753	CA: I want to hear more on this,
2876.155	"because the very words ""global governance"""
2879.232	are almost the epitome of evil
2879.232	in the mindset of a lot of people
2883.845	on the alt-right right now.
2885.195	It just seems scary, remote, distant,
2885.195	and it has let them down,
2888.173	and so globalists,
2888.173	global governance -- no, go away!
2892.313	And many view the election
2892.313	as the ultimate poke in the eye
2896.019	to anyone who believes in that.
2897.521	So how do we change the narrative
2901.096	so that it doesn't seem
2901.096	so scary and remote?
2904.095	Build more on this idea
2904.095	of it being compatible
2906.863	with local identity, local communities.
2909.508	YNH: Well, I think again we should start
2912.132	really with the biological realities
2915.288	of Homo sapiens.
2917.323	And biology tells us two things
2917.323	about Homo sapiens
2921.465	which are very relevant to this issue:
2923.746	first of all, that we are
2923.746	completely dependent
2926.799	on the ecological system around us,
2929.418	and that today we are talking
2929.418	about a global system.
2932.901	You cannot escape that.
2934.282	And at the same time, biology tells us
2934.282	about Homo sapiens
2937.928	that we are social animals,
2940.199	but that we are social
2940.199	on a very, very local level.
2944.86	It's just a simple fact of humanity
2948.429	that we cannot have intimate familiarity
2953.25	with more than about 150 individuals.
2957.149	The size of the natural group,
2961.47	the natural community of Homo sapiens,
2964.596	is not more than 150 individuals,
2967.964	and everything beyond that is really
2967.964	based on all kinds of imaginary stories
2974.387	and large-scale institutions,
2976.458	and I think that we can find a way,
2980.858	again, based on a biological
2980.858	understanding of our species,
2985.452	to weave the two together
2987.558	and to understand that today
2987.558	in the 21st century,
2990.658	we need both the global level
2990.658	and the local community.
2996.218	And I would go even further than that
2998.259	and say that it starts
2998.259	with the body itself.
3002.32	The feelings that people today have
3002.32	of alienation and loneliness
3006.686	and not finding their place in the world,
3009.926	I would think that the chief problem
3009.926	is not global capitalism.
3016.105	The chief problem is that over
3016.105	the last hundred years,
3019.155	people have been becoming disembodied,
3022.883	have been distancing themselves
3022.883	from their body.
3026.066	As a hunter-gatherer or even as a peasant,
3028.986	to survive, you need to be
3028.986	constantly in touch
3033.208	with your body and with your senses,
3035.415	every moment.
3036.62	If you go to the forest
3036.62	to look for mushrooms
3038.791	and you don't pay attention
3038.791	to what you hear,
3041.192	to what you smell, to what you taste,
3043.092	you're dead.
3044.267	So you must be very connected.
3046.442	In the last hundred years,
3046.442	people are losing their ability
3051.062	to be in touch with their body
3051.062	and their senses,
3053.958	to hear, to smell, to feel.
3056.168	More and more attention goes to screens,
3059.318	to what is happening elsewhere,
3060.862	some other time.
3062.107	This, I think, is the deep reason
3064.562	for the feelings of alienation
3064.562	and loneliness and so forth,
3068.48	and therefore part of the solution
3071.006	is not to bring back
3071.006	some mass nationalism,
3075.294	but also reconnect with our own bodies,
3079.442	and if you are back
3079.442	in touch with your body,
3082.729	you will feel much more at home
3082.729	in the world also.
3085.923	CA: Well, depending on how things go,
3085.923	we may all be back in the forest soon.
3089.632	We're going to have
3089.632	one more question in the room
3092.005	and one more on Facebook.
3093.532	Ama Adi-Dako: Hello. I'm from Ghana,
3093.532	West Africa, and my question is:
3096.937	I'm wondering how do you present
3096.937	and justify the idea of global governance
3101.563	to countries that have been
3101.563	historically disenfranchised
3104.598	by the effects of globalization,
3106.667	and also, if we're talking about
3106.667	global governance,
3109.437	it sounds to me like it will definitely
3109.437	come from a very Westernized idea
3113.085	"of what the ""global"""
3113.085	is supposed to look like.
3115.283	So how do we present and justify
3115.283	that idea of global
3118.597	versus wholly nationalist
3121.614	to people in countries like Ghana
3121.614	and Nigeria and Togo
3124.973	and other countries like that?
3127.951	YNH: I would start by saying
3127.951	that history is extremely unfair,
3134.389	and that we should realize that.
3138.824	Many of the countries that suffered most
3141.897	from the last 200 years of globalization
3146.06	and imperialism and industrialization
3148.044	are exactly the countries
3148.044	which are also most likely to suffer most
3153.778	from the next wave.
3156.591	And we should be very,
3156.591	very clear about that.
3161.297	If we don't have a global governance,
3164.372	and if we suffer from climate change,
3167.599	from technological disruptions,
3169.88	the worst suffering will not be in the US.
3173.505	The worst suffering will be in Ghana,
3173.505	will be in Sudan, will be in Syria,
3178.625	will be in Bangladesh,
3178.625	will be in those places.
3181.386	So I think those countries
3181.386	have an even greater incentive
3187.446	to do something about
3187.446	the next wave of disruption,
3192.197	whether it's ecological
3192.197	or whether it's technological.
3194.746	Again, if you think about
3194.746	technological disruption,
3197.616	so if AI and 3D printers and robots
3197.616	will take the jobs
3202.256	from billions of people,
3204.649	I worry far less about the Swedes
3207.798	than about the people in Ghana
3207.798	or in Bangladesh.
3211.427	And therefore,
3211.427	because history is so unfair
3216.679	and the results of a calamity
3221.049	will not be shared equally
3221.049	between everybody,
3223.441	as usual, the rich
3223.441	will be able to get away
3227.898	from the worst consequences
3227.898	of climate change
3231.394	in a way that the poor
3231.394	will not be able to.
3235.167	CA: And here's a great question
3235.167	from Cameron Taylor on Facebook:
3238.599	"""At the end of 'Sapiens,'"""
3240.744	you said we should be asking the question,
3242.831	'What do we want to want?'
3245.211	Well, what do you think
3245.211	"we should want to want?"""
3248.222	YNH: I think we should want
3248.222	to want to know the truth,
3251.777	to understand reality.
3255.027	Mostly what we want is to change reality,
3260.165	to fit it to our own desires,
3260.165	to our own wishes,
3263.907	and I think we should first
3263.907	want to understand it.
3267.651	If you look at the long-term
3267.651	trajectory of history,
3271.439	what you see is that
3271.439	for thousands of years
3274.199	we humans have been gaining
3274.199	control of the world outside us
3277.559	and trying to shape it
3277.559	to fit our own desires.
3281.077	And we've gained control
3281.077	of the other animals,
3284.289	of the rivers, of the forests,
3285.844	and reshaped them completely,
3289.361	causing an ecological destruction
3292.746	without making ourselves satisfied.
3295.948	So the next step
3295.948	is we turn our gaze inwards,
3299.774	and we say OK, getting control
3299.774	of the world outside us
3304.346	did not really make us satisfied.
3306.234	Let's now try to gain control
3306.234	of the world inside us.
3308.957	This is the really big project
3311.144	of science and technology
3311.144	and industry in the 21st century --
3315.464	to try and gain control
3315.464	of the world inside us,
3319.01	to learn how to engineer and produce
3319.01	bodies and brains and minds.
3323.957	These are likely to be the main
3323.957	products of the 21st century economy.
3328.623	When people think about the future,
3328.623	very often they think in terms,
3332.468	"""Oh, I want to gain control"
3332.468	"of my body and of my brain."""
3336.439	And I think that's very dangerous.
3339.273	If we've learned anything
3339.273	from our previous history,
3342.563	it's that yes, we gain
3342.563	the power to manipulate,
3346.5	but because we didn't really
3346.5	understand the complexity
3349.314	of the ecological system,
3351.143	we are now facing an ecological meltdown.
3354.857	And if we now try to reengineer
3354.857	the world inside us
3360.287	without really understanding it,
3362.443	especially without understanding
3362.443	the complexity of our mental system,
3366.783	we might cause a kind of internal
3366.783	ecological disaster,
3371.467	and we'll face a kind of mental
3371.467	meltdown inside us.
3376.09	CA: Putting all the pieces
3376.09	together here --
3378.556	the current politics,
3378.556	the coming technology,
3381.26	concerns like the one
3381.26	you've just outlined --
3383.434	I mean, it seems like you yourself
3383.434	are in quite a bleak place
3386.553	when you think about the future.
3388.198	You're pretty worried about it.
3389.804	Is that right?
3391.02	And if there was one cause for hope,
3391.02	how would you state that?
3397.732	YNH: I focus on the most
3397.732	dangerous possibilities
3401.919	partly because this is like
3401.919	my job or responsibility
3404.964	as a historian or social critic.
3406.769	I mean, the industry focuses mainly
3406.769	on the positive sides,
3411.555	so it's the job of historians
3411.555	and philosophers and sociologists
3414.94	to highlight the more dangerous potential
3414.94	of all these new technologies.
3419.405	I don't think any of that is inevitable.
3421.912	Technology is never deterministic.
3424.975	You can use the same technology
3426.716	to create very different
3426.716	kinds of societies.
3429.731	If you look at the 20th century,
3431.793	so, the technologies
3431.793	of the Industrial Revolution,
3434.598	the trains and electricity and all that
3437.679	could be used to create
3437.679	a communist dictatorship
3440.755	or a fascist regime
3440.755	or a liberal democracy.
3443.584	The trains did not tell you
3443.584	what to do with them.
3446.136	Similarly, now, artificial intelligence
3446.136	and bioengineering and all of that --
3450.612	they don't predetermine a single outcome.
3454.706	Humanity can rise up to the challenge,
3457.907	and the best example we have
3459.622	of humanity rising up
3459.622	to the challenge of a new technology
3463.386	is nuclear weapons.
3465.133	In the late 1940s, '50s,
3468.166	many people were convinced
3470.329	that sooner or later the Cold War
3470.329	will end in a nuclear catastrophe,
3474.659	destroying human civilization.
3476.458	And this did not happen.
3477.962	In fact, nuclear weapons prompted
3477.962	humans all over the world
3484.406	to change the way that they manage
3484.406	international politics
3489.171	to reduce violence.
3491.564	And many countries basically took out war
3494.827	from their political toolkit.
3496.725	They no longer tried to pursue
3496.725	their interests with warfare.
3501.4	Not all countries have done so,
3501.4	but many countries have.
3504.694	And this is maybe
3504.694	the most important reason
3508.652	why international violence
3508.652	declined dramatically since 1945,
3514.778	and today, as I said,
3514.778	more people commit suicide
3518.14	than are killed in war.
3520.371	So this, I think, gives us a good example
3525.224	that even the most frightening technology,
3529.09	humans can rise up to the challenge
3531.649	and actually some good can come out of it.
3534.696	The problem is, we have very little
3534.696	margin for error.
3539.007	If we don't get it right,
3541.24	we might not have
3541.24	a second option to try again.
3546.157	CA: That's a very powerful note,
3547.748	on which I think we should draw
3547.748	this to a conclusion.
3550.577	Before I wrap up, I just want to say
3550.577	one thing to people here
3553.712	and to the global TED community
3553.712	watching online, anyone watching online:
3559.282	help us with these dialogues.
3562.199	If you believe, like we do,
3564.773	that we need to find
3564.773	a different kind of conversation,
3567.777	now more than ever, help us do it.
3570.034	Reach out to other people,
3573.089	try and have conversations
3573.089	with people you disagree with,
3575.853	understand them,
3577.06	pull the pieces together,
3578.614	and help us figure out how to take
3578.614	these conversations forward
3582.53	so we can make a real contribution
3584.808	to what's happening
3584.808	in the world right now.
3587.577	I think everyone feels more alive,
3590.92	more concerned, more engaged
3593.254	with the politics of the moment.
3595.807	The stakes do seem quite high,
3598.285	so help us respond to it
3598.285	in a wise, wise way.
3602.821	Yuval Harari, thank you.
3604.44	(Applause)
