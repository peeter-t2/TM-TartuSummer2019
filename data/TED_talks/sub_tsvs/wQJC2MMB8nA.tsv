startsecond	text
16.01	So, security is two different things:
18.31	it's a feeling, and it's a reality.
20.86	And they're different.
22.309	You could feel secure even if you're not.
25.76	And you can be secure
27.76	even if you don't feel it.
29.634	Really, we have two separate concepts
31.775	mapped onto the same word.
33.96	And what I want to do in this talk
33.96	is to split them apart --
37.61	figuring out when they diverge
37.61	and how they converge.
41.711	And language is actually a problem here.
44.01	There aren't a lot of good words
46.11	for the concepts
46.11	we're going to talk about.
49.295	So if you look at security
49.295	from economic terms,
53.439	it's a trade-off.
55.11	Every time you get some security,
55.11	you're always trading off something.
59.266	Whether this is a personal decision --
61.135	whether you're going to install
61.135	a burglar alarm in your home --
64.171	or a national decision,
65.352	where you're going to invade
65.352	a foreign country --
67.686	you're going to trade off something:
67.686	money or time, convenience, capabilities,
71.492	maybe fundamental liberties.
73.518	And the question to ask
73.518	when you look at a security anything
76.816	is not whether this makes us safer,
80.222	but whether it's worth the trade-off.
82.461	You've heard in the past
82.461	several years, the world is safer
85.714	because Saddam Hussein is not in power.
87.628	That might be true,
87.628	but it's not terribly relevant.
90.255	The question is: Was it worth it?
93.11	And you can make your own decision,
95.593	and then you'll decide
95.593	whether the invasion was worth it.
98.35	That's how you think about security:
98.35	in terms of the trade-off.
101.935	Now, there's often no right or wrong here.
105.208	Some of us have a burglar alarm
105.208	system at home and some of us don't.
108.54	And it'll depend on where we live,
111.295	whether we live alone or have a family,
113.245	how much cool stuff we have,
114.937	how much we're willing
114.937	to accept the risk of theft.
118.943	In politics also,
118.943	there are different opinions.
122.459	A lot of times, these trade-offs
122.459	are about more than just security,
126.918	and I think that's really important.
128.807	Now, people have a natural intuition
128.807	about these trade-offs.
132.588	We make them every day.
134.807	Last night in my hotel room,
134.807	when I decided to double-lock the door,
138.364	or you in your car when you drove here;
141.191	when we go eat lunch
142.693	and decide the food's not
142.693	poison and we'll eat it.
145.325	We make these trade-offs again and again,
148.51	multiple times a day.
150.11	We often won't even notice them.
151.723	They're just part
151.723	of being alive; we all do it.
154.373	Every species does it.
156.474	Imagine a rabbit in a field, eating grass.
159.36	And the rabbit sees a fox.
161.856	That rabbit will make
161.856	a security trade-off:
163.929	"""Should I stay, or should I flee?"""
166.38	And if you think about it,
168.023	the rabbits that are good
168.023	at making that trade-off
170.602	will tend to live and reproduce,
172.604	and the rabbits that are bad at it
174.935	will get eaten or starve.
176.958	So you'd think
179.573	that us, as a successful species
179.573	on the planet -- you, me, everybody --
183.906	would be really good
183.906	at making these trade-offs.
187.126	Yet it seems, again and again,
187.126	that we're hopelessly bad at it.
191.768	And I think that's a fundamentally
191.768	interesting question.
194.594	I'll give you the short answer.
196.491	The answer is, we respond
196.491	to the feeling of security
199.166	and not the reality.
201.864	Now, most of the time, that works.
205.538	Most of the time,
207.065	feeling and reality are the same.
210.776	Certainly that's true
210.776	for most of human prehistory.
215.633	We've developed this ability
218.365	because it makes evolutionary sense.
221.985	One way to think of it
221.985	is that we're highly optimized
225.283	for risk decisions
227.11	that are endemic to living
227.11	in small family groups
229.677	in the East African Highlands
229.677	in 100,000 BC.
236.879	Now, there are several biases
236.879	in risk perception.
240.109	A lot of good experiments in this.
241.874	And you can see certain biases
241.874	that come up again and again.
245.501	I'll give you four.
246.878	We tend to exaggerate
246.878	spectacular and rare risks
250.11	and downplay common risks --
252.11	so, flying versus driving.
254.451	The unknown is perceived
254.451	to be riskier than the familiar.
261.47	One example would be:
262.933	people fear kidnapping by strangers,
265.57	when the data supports that kidnapping
265.57	by relatives is much more common.
269.23	This is for children.
270.828	Third, personified risks
270.828	are perceived to be greater
274.892	than anonymous risks.
276.419	So, Bin Laden is scarier
276.419	because he has a name.
280.182	And the fourth is:
281.569	people underestimate risks
281.569	in situations they do control
286.348	and overestimate them
286.348	in situations they don't control.
289.335	So once you take up skydiving or smoking,
292.743	you downplay the risks.
295.037	If a risk is thrust upon you --
295.037	terrorism is a good example --
298.114	you'll overplay it,
299.295	because you don't feel
299.295	like it's in your control.
302.157	There are a bunch
302.157	of other of these cognitive biases,
305.674	that affect our risk decisions.
308.832	There's the availability heuristic,
311.11	which basically means we estimate
311.11	the probability of something
315.314	by how easy it is to bring
315.314	instances of it to mind.
319.831	So you can imagine how that works.
321.632	If you hear a lot about tiger attacks,
321.632	there must be a lot of tigers around.
325.284	You don't hear about lion attacks,
325.284	there aren't a lot of lions around.
328.652	This works, until you invent newspapers,
330.973	because what newspapers do
330.973	is repeat again and again
335.403	rare risks.
336.833	I tell people: if it's in the news,
336.833	don't worry about it,
339.722	because by definition, news is something
339.722	that almost never happens.
344.021	(Laughter)
345.814	When something is so common,
345.814	it's no longer news.
348.761	Car crashes, domestic violence --
350.983	those are the risks you worry about.
353.713	We're also a species of storytellers.
355.885	We respond to stories more than data.
358.514	And there's some basic
358.514	innumeracy going on.
360.944	"I mean, the joke ""One, two,"
360.944	"three, many"" is kind of right."
364.11	We're really good at small numbers.
366.456	One mango, two mangoes, three mangoes,
370.817	it's still more mangoes
370.817	you can eat before they rot.
373.818	So one half, one quarter,
373.818	one fifth -- we're good at that.
377.11	One in a million, one in a billion --
379.11	they're both almost never.
381.546	So we have trouble with the risks
381.546	that aren't very common.
385.76	And what these cognitive biases do
387.761	is they act as filters
387.761	between us and reality.
391.284	And the result is that feeling
391.284	and reality get out of whack,
395.181	they get different.
397.37	Now, you either have a feeling --
397.37	you feel more secure than you are,
401.325	there's a false sense of security.
403.034	Or the other way, and that's a false
403.034	sense of insecurity.
407.015	"I write a lot about ""security theater,"""
409.919	which are products
409.919	that make people feel secure,
412.623	but don't actually do anything.
414.624	There's no real word for stuff
414.624	that makes us secure,
417.205	but doesn't make us feel secure.
419.11	Maybe it's what the CIA
419.11	is supposed to do for us.
423.539	So back to economics.
425.731	If economics, if the market,
425.731	drives security,
429.411	and if people make trade-offs
429.411	based on the feeling of security,
434.282	then the smart thing for companies to do
434.282	for the economic incentives
438.986	is to make people feel secure.
441.942	And there are two ways to do this.
444.296	One, you can make people actually secure
447.11	and hope they notice.
448.597	Or two, you can make people
448.597	just feel secure
451.465	and hope they don't notice.
454.401	Right?
455.8	So what makes people notice?
459.5	Well, a couple of things:
460.906	understanding of the security,
463.196	of the risks, the threats,
465.11	the countermeasures, how they work.
467.008	But if you know stuff, you're more likely
470.155	to have your feelings match reality.
473.11	Enough real-world examples helps.
476.279	We all know the crime rate
476.279	in our neighborhood,
478.862	because we live there,
478.862	and we get a feeling about it
481.687	that basically matches reality.
485.038	Security theater is exposed
487.269	when it's obvious
487.269	that it's not working properly.
491.209	OK. So what makes people not notice?
494.443	Well, a poor understanding.
496.642	If you don't understand the risks,
496.642	you don't understand the costs,
499.81	you're likely to get the trade-off wrong,
501.991	and your feeling doesn't match reality.
504.503	Not enough examples.
506.879	There's an inherent problem
506.879	with low-probability events.
510.919	If, for example, terrorism
510.919	almost never happens,
514.756	it's really hard to judge the efficacy
514.756	of counter-terrorist measures.
520.523	This is why you keep sacrificing virgins,
524.11	and why your unicorn defenses
524.11	are working just great.
526.809	There aren't enough examples of failures.
531.109	Also, feelings that cloud the issues --
533.92	the cognitive biases I talked
533.92	about earlier: fears, folk beliefs --
538.727	basically, an inadequate model of reality.
543.403	So let me complicate things.
545.598	I have feeling and reality.
547.599	I want to add a third element.
547.599	"I want to add ""model."""
550.839	Feeling and model are in our head,
553.213	reality is the outside world;
553.213	it doesn't change, it's real.
557.8	Feeling is based on our intuition,
560.038	model is based on reason.
562.383	That's basically the difference.
564.446	In a primitive and simple world,
566.447	there's really no reason for a model,
570.253	because feeling is close to reality.
572.572	You don't need a model.
574.596	But in a modern and complex world,
577.556	you need models to understand
577.556	a lot of the risks we face.
582.362	There's no feeling about germs.
585.11	You need a model to understand them.
588.157	This model is an intelligent
588.157	representation of reality.
592.411	It's, of course, limited
592.411	by science, by technology.
598.249	We couldn't have a germ theory of disease
600.599	before we invented
600.599	the microscope to see them.
604.316	It's limited by our cognitive biases.
608.11	But it has the ability
608.11	to override our feelings.
611.507	Where do we get these models?
611.507	We get them from others.
614.635	We get them from religion,
614.635	from culture, teachers, elders.
620.298	A couple years ago,
620.298	I was in South Africa on safari.
623.748	The tracker I was with grew up
623.748	in Kruger National Park.
626.534	He had some very complex
626.534	models of how to survive.
629.8	And it depended on if you were attacked
629.8	by a lion, leopard, rhino, or elephant --
633.737	and when you had to run away,
633.737	when you couldn't run away,
636.495	when you had to climb a tree,
636.495	when you could never climb a tree.
639.602	I would have died in a day.
642.16	But he was born there,
642.16	and he understood how to survive.
646.49	I was born in New York City.
648.11	I could have taken him to New York,
648.11	and he would have died in a day.
651.385	(Laughter)
652.41	Because we had different models
652.41	based on our different experiences.
658.291	Models can come from the media,
660.784	from our elected officials ...
663.234	Think of models of terrorism,
666.339	child kidnapping,
668.56	airline safety, car safety.
671.539	Models can come from industry.
674.348	The two I'm following
674.348	are surveillance cameras,
677.59	ID cards,
679.11	quite a lot of our computer
679.11	security models come from there.
682.264	A lot of models come from science.
684.515	Health models are a great example.
686.376	Think of cancer, bird flu,
686.376	swine flu, SARS.
689.942	All of our feelings of security
689.942	about those diseases
694.836	come from models given to us, really,
694.836	by science filtered through the media.
701.038	So models can change.
703.482	Models are not static.
705.609	As we become more comfortable
705.609	in our environments,
708.873	our model can move closer to our feelings.
713.965	So an example might be,
716.329	if you go back 100 years ago,
717.949	when electricity was first
717.949	becoming common,
721.401	there were a lot of fears about it.
723.128	There were people who were afraid
723.128	to push doorbells,
725.63	because there was electricity
725.63	in there, and that was dangerous.
728.659	For us, we're very facile
728.659	around electricity.
731.552	We change light bulbs
731.552	without even thinking about it.
734.948	Our model of security around electricity
734.948	is something we were born into.
741.735	It hasn't changed as we were growing up.
744.273	And we're good at it.
747.38	Or think of the risks on the Internet
747.38	across generations --
751.903	how your parents approach
751.903	Internet security,
754.024	versus how you do,
755.664	versus how our kids will.
758.3	Models eventually fade
758.3	into the background.
762.427	"""Intuitive"" is just"
762.427	another word for familiar.
765.887	So as your model is close to reality
765.887	and it converges with feelings,
769.761	you often don't even know it's there.
773.239	A nice example of this came
773.239	from last year and swine flu.
778.281	When swine flu first appeared,
780.305	the initial news caused
780.305	a lot of overreaction.
783.562	Now, it had a name,
785.564	which made it scarier
785.564	than the regular flu,
787.638	even though it was more deadly.
789.784	And people thought doctors
789.784	should be able to deal with it.
793.459	So there was that feeling
793.459	of lack of control.
796.007	And those two things
796.007	made the risk more than it was.
799.14	As the novelty wore off
799.14	and the months went by,
802.721	there was some amount of tolerance;
802.721	people got used to it.
806.355	There was no new data,
806.355	but there was less fear.
809.681	By autumn,
811.879	people thought the doctors
811.879	should have solved this already.
815.722	And there's kind of a bifurcation:
817.706	people had to choose
817.706	between fear and acceptance --
824.512	actually, fear and indifference --
826.18	and they kind of chose suspicion.
829.11	And when the vaccine appeared last winter,
832.245	there were a lot of people --
832.245	a surprising number --
834.78	who refused to get it.
838.777	And it's a nice example of how
838.777	people's feelings of security change,
842.457	how their model changes,
844.084	sort of wildly,
845.776	with no new information,
845.776	with no new input.
850.327	This kind of thing happens a lot.
853.199	I'm going to give one more complication.
855.194	We have feeling, model, reality.
858.64	I have a very relativistic
858.64	view of security.
861.174	I think it depends on the observer.
863.695	And most security decisions
863.695	have a variety of people involved.
869.792	And stakeholders with specific trade-offs
869.792	will try to influence the decision.
876.355	And I call that their agenda.
879.512	And you see agenda --
879.512	this is marketing, this is politics --
883.481	trying to convince you to have
883.481	one model versus another,
886.544	trying to convince you to ignore a model
888.552	and trust your feelings,
891.248	marginalizing people
891.248	with models you don't like.
894.744	This is not uncommon.
897.61	An example, a great example,
897.61	is the risk of smoking.
902.196	In the history of the past 50 years,
904.003	the smoking risk shows
904.003	how a model changes,
906.64	and it also shows how an industry fights
906.64	against a model it doesn't like.
911.983	Compare that to the secondhand
911.983	smoke debate --
915.11	probably about 20 years behind.
917.982	Think about seat belts.
919.621	When I was a kid, no one wore a seat belt.
921.669	Nowadays, no kid will let you drive
921.669	if you're not wearing a seat belt.
926.633	Compare that to the airbag debate,
929.11	probably about 30 years behind.
932.006	All examples of models changing.
936.855	What we learn is that changing
936.855	models is hard.
940.334	Models are hard to dislodge.
942.411	If they equal your feelings,
944.11	you don't even know you have a model.
947.11	And there's another cognitive bias
949.02	I'll call confirmation bias,
951.11	where we tend to accept data
951.11	that confirms our beliefs
955.495	and reject data
955.495	that contradicts our beliefs.
959.49	So evidence against our model,
959.49	we're likely to ignore,
963.449	even if it's compelling.
964.721	It has to get very compelling
964.721	before we'll pay attention.
968.99	New models that extend
968.99	long periods of time are hard.
971.611	Global warming is a great example.
973.389	We're terrible at models
973.389	that span 80 years.
976.855	"We can do ""to the next harvest."""
978.942	"We can often do ""until our kids grow up."""
981.76	"But ""80 years,"" we're just not good at."
984.975	So it's a very hard model to accept.
987.999	We can have both models
987.999	in our head simultaneously --
991.912	that kind of problem where
991.912	we're holding both beliefs together,
998.884	the cognitive dissonance.
1000.278	Eventually, the new model
1000.278	will replace the old model.
1004.164	Strong feelings can create a model.
1007.411	September 11 created a security model
1007.411	in a lot of people's heads.
1012.798	Also, personal experiences
1012.798	with crime can do it,
1016.11	personal health scare,
1017.513	a health scare in the news.
1020.198	You'll see these called
1020.198	"""flashbulb events"" by psychiatrists."
1024.183	They can create a model instantaneously,
1026.668	because they're very emotive.
1029.908	So in the technological world,
1031.52	we don't have experience to judge models.
1035.124	And we rely on others. We rely on proxies.
1038.081	And this works, as long as
1038.081	it's the correct others.
1041.183	We rely on government agencies
1043.889	to tell us what pharmaceuticals are safe.
1048.317	I flew here yesterday.
1050.254	I didn't check the airplane.
1052.699	I relied on some other group
1055.318	to determine whether
1055.318	my plane was safe to fly.
1057.779	We're here, none of us fear the roof
1057.779	is going to collapse on us,
1061.101	not because we checked,
1063.33	but because we're pretty sure
1063.33	the building codes here are good.
1068.442	It's a model we just accept
1071.455	pretty much by faith.
1073.331	And that's OK.
1077.966	Now, what we want is people
1077.966	to get familiar enough with better models,
1083.863	have it reflected in their feelings,
1086.007	to allow them to make security trade-offs.
1090.11	When these go out of whack,
1090.11	you have two options.
1093.853	One, you can fix people's feelings,
1093.853	directly appeal to feelings.
1098.11	It's manipulation, but it can work.
1101.173	The second, more honest way
1103.388	is to actually fix the model.
1106.72	Change happens slowly.
1108.845	The smoking debate took 40 years --
1108.845	and that was an easy one.
1115.195	Some of this stuff is hard.
1117.496	Really, though, information
1117.496	seems like our best hope.
1121.276	And I lied.
1122.572	Remember I said feeling, model, reality;
1122.572	reality doesn't change?
1126.616	It actually does.
1128.015	We live in a technological world;
1129.753	reality changes all the time.
1132.887	So we might have,
1132.887	for the first time in our species:
1135.888	feeling chases model, model chases
1135.888	reality, reality's moving --
1139.095	they might never catch up.
1142.18	We don't know.
1145.614	But in the long term,
1147.241	both feeling and reality are important.
1149.469	And I want to close with two quick
1149.469	stories to illustrate this.
	will remember this --
1155.229	there was a short epidemic
1155.229	of Tylenol poisonings
1158.623	in the United States.
1159.843	It's a horrific story.
1161.228	Someone took a bottle of Tylenol,
1163.331	put poison in it, closed it up,
1163.331	put it back on the shelf,
1166.357	someone else bought it and died.
1167.939	This terrified people.
1169.636	There were a couple of copycat attacks.
1171.887	There wasn't any real risk,
1171.887	but people were scared.
1174.756	And this is how the tamper-proof
1174.756	drug industry was invented.
1178.656	Those tamper-proof caps?
1178.656	That came from this.
1180.909	It's complete security theater.
1182.504	As a homework assignment,
1182.504	think of 10 ways to get around it.
1185.419	I'll give you one: a syringe.
1187.334	But it made people feel better.
1190.744	It made their feeling of security
1190.744	more match the reality.
1195.39	Last story: a few years ago,
1195.39	a friend of mine gave birth.
1198.348	I visit her in the hospital.
1199.769	It turns out, when a baby's born now,
1201.716	they put an RFID bracelet on the baby,
1201.716	a corresponding one on the mother,
1205.303	so if anyone other than the mother takes
1205.303	the baby out of the maternity ward,
1208.947	an alarm goes off.
1210.129	"I said, ""Well, that's kind of neat."
1211.882	I wonder how rampant
1211.882	"baby snatching is out of hospitals."""
1215.876	I go home, I look it up.
1217.136	It basically never happens.
1218.685	(Laughter)
1220.553	But if you think about it,
1220.553	if you are a hospital,
1223.42	and you need to take a baby
1223.42	away from its mother,
1225.824	out of the room to run some tests,
1227.629	you better have some good
1227.629	security theater,
1229.703	or she's going to rip your arm off.
1231.672	(Laughter)
1234.161	So it's important for us,
1235.902	those of us who design security,
1238.061	who look at security policy --
1240.946	or even look at public policy
1240.946	in ways that affect security.
1245.006	It's not just reality;
1245.006	it's feeling and reality.
1248.446	What's important
1250.335	is that they be about the same.
1251.904	It's important that,
1251.904	if our feelings match reality,
1254.459	we make better security trade-offs.
1256.711	Thank you.
1257.888	(Applause)
