startsecond	text
12.82	Roy Price is a man that most of you
12.82	have probably never heard about,
17.12	even though he may have been responsible
19.64	for 22 somewhat mediocre 
19.64	minutes of your life on April 19, 2013.
26.56	He may have also been responsible
26.56	for 22 very entertaining minutes,
29.76	but not very many of you.
32.04	And all of that goes back to a decision
33.96	that Roy had to make
33.96	about three years ago.
35.984	So you see, Roy Price
35.984	is a senior executive with Amazon Studios.
40.84	That's the TV production
40.84	company of Amazon.
43.88	He's 47 years old, slim, spiky hair,
47.16	describes himself on Twitter
47.16	"as ""movies, TV, technology, tacos."""
52	And Roy Price has a very responsible job,
52	because it's his responsibility
57.2	to pick the shows, the original content
57.2	that Amazon is going to make.
61.28	And of course that's
61.28	a highly competitive space.
63.64	I mean, there are so many
63.64	TV shows already out there,
66.4	that Roy can't just choose any show.
68.6	He has to find shows
68.6	that are really, really great.
72.72	So in other words, he has to find shows
75.56	that are on the very right end
75.56	of this curve here.
77.96	So this curve here
77.96	is the rating distribution
80.64	of about 2,500 TV shows
80.64	on the website IMDB,
85.04	and the rating goes from one to 10,
87.96	and the height here shows you
87.96	how many shows get that rating.
90.96	So if your show gets a rating
90.96	of nine points or higher, that's a winner.
95.68	Then you have a top two percent show.
97.52	"That's shows like ""Breaking Bad,"""
97.52	"""Game of Thrones,"" ""The Wire,"""
101.44	so all of these shows that are addictive,
103.76	whereafter you've watched a season,
103.76	your brain is basically like,
106.84	"""Where can I get more of these episodes?"""
109.04	That kind of show.
110.92	On the left side, just for clarity,
110.92	here on that end,
113.44	you have a show called
113.44	"""Toddlers and Tiaras"" --"
116.64	(Laughter)
119.32	-- which should tell you enough
120.88	about what's going on
120.88	on that end of the curve.
123.095	Now, Roy Price is not worried about
123.095	getting on the left end of the curve,
127.28	because I think you would have to have
127.28	some serious brainpower
130.24	"to undercut ""Toddlers and Tiaras."""
131.96	So what he's worried about
131.96	is this middle bulge here,
135.92	the bulge of average TV,
137.76	you know, those shows
137.76	that aren't really good or really bad,
140.639	they don't really get you excited.
142.32	So he needs to make sure
142.32	that he's really on the right end of this.
147.2	So the pressure is on,
148.8	and of course it's also the first time
151	that Amazon is even
151	doing something like this,
153.2	so Roy Price does not want
153.2	to take any chances.
156.56	He wants to engineer success.
159.04	He needs a guaranteed success,
160.84	and so what he does is,
160.84	he holds a competition.
163.44	So he takes a bunch of ideas for TV shows,
166.6	and from those ideas,
166.6	through an evaluation,
168.92	they select eight candidates for TV shows,
173.04	and then he just makes the first episode
173.04	of each one of these shows
176.28	and puts them online for free
176.28	for everyone to watch.
179.44	And so when Amazon
179.44	is giving out free stuff,
181.72	you're going to take it, right?
183.28	So millions of viewers
183.28	are watching those episodes.
188.44	What they don't realize is that,
188.44	while they're watching their shows,
191.68	actually, they are being watched.
194	They are being watched
194	by Roy Price and his team,
196.36	who record everything.
197.76	They record when somebody presses play,
197.76	when somebody presses pause,
201.16	what parts they skip,
201.16	what parts they watch again.
203.72	So they collect millions of data points,
206	because they want
206	to have those data points
208.12	to then decide
208.12	which show they should make.
210.84	And sure enough,
210.84	so they collect all the data,
213.04	they do all the data crunching,
213.04	and an answer emerges,
215.64	and the answer is,
216.88	"""Amazon should do a sitcom"
216.88	"about four Republican US Senators."""
222.44	They did that show.
223.68	So does anyone know the name of the show?
226.72	"(Audience: ""Alpha House."")"
228.04	"Yes, ""Alpha House,"""
229.52	but it seems like not too many of you here
229.52	remember that show, actually,
233.64	because it didn't turn out that great.
235.52	It's actually just an average show,
237.4	actually -- literally, in fact, because
237.4	the average of this curve here is at 7.4,
242	"and ""Alpha House"" lands at 7.5,"
244.44	so a slightly above average show,
246.48	but certainly not what Roy Price
246.48	and his team were aiming for.
250.32	Meanwhile, however,
250.32	at about the same time,
253.2	at another company,
254.8	another executive did manage
254.8	to land a top show using data analysis,
259.04	and his name is Ted,
260.64	Ted Sarandos, who is
260.64	the Chief Content Officer of Netflix,
264.08	and just like Roy,
264.08	he's on a constant mission
266.24	to find that great TV show,
267.76	and he uses data as well to do that,
269.8	except he does it
269.8	a little bit differently.
271.839	So instead of holding a competition,
271.839	what he did -- and his team of course --
275.6	was they looked at all the data
275.6	they already had about Netflix viewers,
279.16	you know, the ratings
279.16	they give their shows,
281.28	the viewing histories,
281.28	what shows people like, and so on.
284	And then they use that data to discover
285.92	all of these little bits and pieces
285.92	about the audience:
288.56	what kinds of shows they like,
290.04	what kind of producers,
290.04	what kind of actors.
292.16	And once they had
292.16	all of these pieces together,
294.76	they took a leap of faith,
296.44	and they decided to license
298.56	not a sitcom about four Senators
301.04	but a drama series about a single Senator.
304.76	You guys know the show?
306.44	(Laughter)
307.76	"Yes, ""House of Cards,"" and Netflix"
307.76	of course, nailed it with that show,
311.52	at least for the first two seasons.
313.68	(Laughter) (Applause)
317.68	"""House of Cards"" gets"
317.68	a 9.1 rating on this curve,
320.88	so it's exactly
320.88	where they wanted it to be.
324.08	Now, the question of course is,
324.08	what happened here?
326.52	So you have two very competitive,
326.52	data-savvy companies.
329.2	They connect all of these
329.2	millions of data points,
332.08	and then it works
332.08	beautifully for one of them,
334.48	and it doesn't work for the other one.
336.36	So why?
337.6	Because logic kind of tells you
337.6	that this should be working all the time.
341.08	I mean, if you're collecting
341.08	millions of data points
343.56	on a decision you're going to make,
345.32	then you should be able
345.32	to make a pretty good decision.
347.96	You have 200 years
347.96	of statistics to rely on.
350.2	You're amplifying it
350.2	with very powerful computers.
353.24	The least you could expect
353.24	is good TV, right?
357.88	And if data analysis
357.88	does not work that way,
361.52	then it actually gets a little scary,
363.6	because we live in a time
363.6	where we're turning to data more and more
367.44	to make very serious decisions
367.44	that go far beyond TV.
372.76	Does anyone here know the company
372.76	Multi-Health Systems?
377.08	No one. OK, that's good actually.
378.76	OK, so Multi-Health Systems
378.76	is a software company,
382	and I hope that nobody here in this room
384.84	ever comes into contact
384.84	with that software,
388.04	because if you do,
388.04	it means you're in prison.
390.16	(Laughter)
391.36	If someone here in the US is in prison,
391.36	and they apply for parole,
394.92	then it's very likely that
394.92	data analysis software from that company
399.24	will be used in determining
399.24	whether to grant that parole.
402.88	So it's the same principle
402.88	as Amazon and Netflix,
405.48	but now instead of deciding whether
405.48	a TV show is going to be good or bad,
410.12	you're deciding whether a person
410.12	is going to be good or bad.
413.04	And mediocre TV, 22 minutes,
413.04	that can be pretty bad,
418.56	but more years in prison,
418.56	I guess, even worse.
422.36	And unfortunately, there is actually
422.36	some evidence that this data analysis,
426.52	despite having lots of data,
426.52	does not always produce optimum results.
430.76	And that's not because a company
430.76	like Multi-Health Systems
433.506	doesn't know what to do with data.
435.158	Even the most data-savvy
435.158	companies get it wrong.
437.48	Yes, even Google gets it wrong sometimes.
440.68	In 2009, Google announced
440.68	that they were able, with data analysis,
445.2	to predict outbreaks of influenza,
445.2	the nasty kind of flu,
449.36	by doing data analysis
449.36	on their Google searches.
453.16	And it worked beautifully,
453.16	and it made a big splash in the news,
457.04	including the pinnacle
457.04	of scientific success:
459.2	"a publication in the journal ""Nature."""
461.68	It worked beautifully
461.68	for year after year after year,
465.32	until one year it failed.
467	And nobody could even tell exactly why.
469.28	It just didn't work that year,
471	and of course that again made big news,
472.96	including now a retraction
474.6	of a publication
474.6	"from the journal ""Nature."""
478.48	So even the most data-savvy companies,
478.48	Amazon and Google,
481.84	they sometimes get it wrong.
484	And despite all those failures,
486.96	data is moving rapidly
486.96	into real-life decision-making --
490.84	into the workplace,
492.68	law enforcement,
494.52	medicine.
496.4	So we should better make sure
496.4	that data is helping.
499.76	Now, personally I've seen
499.76	a lot of this struggle with data myself,
502.92	because I work in computational genetics,
504.92	which is also a field
504.92	where lots of very smart people
507.44	are using unimaginable amounts of data
507.44	to make pretty serious decisions
511.12	like deciding on a cancer therapy
511.12	or developing a drug.
515.52	And over the years,
515.52	I've noticed a sort of pattern
517.92	or kind of rule, if you will,
517.92	about the difference
520.4	between successful
520.4	decision-making with data
523.12	and unsuccessful decision-making,
524.76	and I find this a pattern worth sharing,
524.76	and it goes something like this.
530.52	So whenever you're
530.52	solving a complex problem,
532.679	you're doing essentially two things.
534.44	The first one is, you take that problem
534.44	apart into its bits and pieces
537.76	so that you can deeply analyze
537.76	those bits and pieces,
540.28	and then of course
540.28	you do the second part.
542.32	You put all of these bits and pieces
542.32	back together again
545	to come to your conclusion.
546.36	And sometimes you
546.36	have to do it over again,
548.72	but it's always those two things:
550.4	taking apart and putting
550.4	back together again.
554.28	And now the crucial thing is
555.92	that data and data analysis
558.84	is only good for the first part.
561.36	Data and data analysis,
561.36	no matter how powerful,
563.6	can only help you taking a problem apart
563.6	and understanding its pieces.
568.08	It's not suited to put those pieces
568.08	back together again
571.6	and then to come to a conclusion.
573.52	There's another tool that can do that,
573.52	and we all have it,
576.28	and that tool is the brain.
577.6	If there's one thing a brain is good at,
579.56	it's taking bits and pieces
579.56	back together again,
581.84	even when you have incomplete information,
583.88	and coming to a good conclusion,
585.48	especially if it's the brain of an expert.
588.44	And that's why I believe
588.44	that Netflix was so successful,
591.12	because they used data and brains
591.12	where they belong in the process.
594.72	They use data to first understand
594.72	lots of pieces about their audience
598.28	that they otherwise wouldn't have
598.28	been able to understand at that depth,
601.72	but then the decision
601.72	to take all these bits and pieces
604.36	and put them back together again
604.36	"and make a show like ""House of Cards,"""
607.72	that was nowhere in the data.
609.16	Ted Sarandos and his team
609.16	made that decision to license that show,
613.16	which also meant, by the way,
613.16	that they were taking
615.565	a pretty big personal risk
615.565	with that decision.
618.44	And Amazon, on the other hand,
618.44	they did it the wrong way around.
621.48	They used data all the way
621.48	to drive their decision-making,
624.24	first when they held
624.24	their competition of TV ideas,
626.68	"then when they selected ""Alpha House"""
626.68	to make as a show.
630.4	Which of course was
630.4	a very safe decision for them,
632.92	because they could always
632.92	point at the data, saying,
635.4	"""This is what the data tells us."""
637.12	But it didn't lead to the exceptional
637.12	results that they were hoping for.
642.12	So data is of course a massively
642.12	useful tool to make better decisions,
647.12	but I believe that things go wrong
649.52	when data is starting
649.52	to drive those decisions.
652.12	No matter how powerful,
652.12	data is just a tool,
655.92	and to keep that in mind,
655.92	I find this device here quite useful.
659.28	Many of you will ...
660.52	(Laughter)
661.76	Before there was data,
663	this was the decision-making
663	device to use.
665.88	(Laughter)
667.16	Many of you will know this.
668.52	This toy here is called the Magic 8 Ball,
670.497	and it's really amazing,
671.72	because if you have a decision to make,
671.72	a yes or no question,
674.64	all you have to do is you shake the ball,
674.64	and then you get an answer --
678.4	"""Most Likely"" -- right here"
678.4	in this window in real time.
681.24	I'll have it out later for tech demos.
683.36	(Laughter)
684.6	Now, the thing is, of course --
684.6	so I've made some decisions in my life
688.2	where, in hindsight,
688.2	I should have just listened to the ball.
691.12	But, you know, of course,
691.12	if you have the data available,
694.48	you want to replace this with something
694.48	much more sophisticated,
697.56	like data analysis
697.56	to come to a better decision.
701.2	But that does not change the basic setup.
703.84	So the ball may get smarter
703.84	and smarter and smarter,
707.04	but I believe it's still on us
707.04	to make the decisions
709.88	if we want to achieve
709.88	something extraordinary,
712.92	on the right end of the curve.
714.88	And I find that a very encouraging
714.88	message, in fact,
719.4	that even in the face
719.4	of huge amounts of data,
723.4	it still pays off to make decisions,
727.52	to be an expert in what you're doing
730.2	and take risks.
732.32	Because in the end, it's not data,
735.12	it's risks that will land you
735.12	on the right end of the curve.
739.84	Thank you.
741.08	(Applause)
