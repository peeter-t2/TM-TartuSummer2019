startsecond	text
12.843	In 2007, I became the attorney general
15.434	of the state of New Jersey.
17.159	Before that, I'd been a criminal prosecutor,
19.439	first in the Manhattan district attorney's office,
22.12	and then at the United States Department of Justice.
24.77	But when I became the attorney general,
26.971	two things happened that changed 
26.971	the way I see criminal justice.
30.866	The first is that I asked what I thought
32.896	were really basic questions.
35.082	I wanted to understand who we were arresting,
37.938	who we were charging,
39.602	and who we were putting in our nation's jails
41.73	and prisons.
43.146	I also wanted to understand
44.794	if we were making decisions
46.123	in a way that made us safer.
48.641	And I couldn't get this information out.
51.893	It turned out that most big criminal justice agencies
55.25	like my own
56.552	didn't track the things that matter.
58.934	So after about a month of being incredibly frustrated,
62.252	I walked down into a conference room
64.223	that was filled with detectives
66.113	and stacks and stacks of case files,
68.895	and the detectives were sitting there
70.071	with yellow legal pads taking notes.
72.305	They were trying to get the information
73.891	I was looking for
75.109	by going through case by case
77.154	for the past five years.
79.052	And as you can imagine,
80.705	when we finally got the results, they weren't good.
83.348	It turned out that we were doing
85.003	a lot of low-level drug cases
87.023	on the streets just around the corner
88.498	from our office in Trenton.
90.766	The second thing that happened
92.233	is that I spent the day in the Camden,
92.233	New Jersey police department.
95.907	Now, at that time, Camden, New Jersey,
97.794	was the most dangerous city in America.
100.446	I ran the Camden Police
100.446	Department because of that.
104.273	I spent the day in the police department,
106.385	and I was taken into a room
106.385	with senior police officials,
109.111	all of whom were working hard
110.786	and trying very hard to reduce crime in Camden.
114.043	And what I saw in that room,
115.869	as we talked about how to reduce crime,
118.114	were a series of officers with a
118.114	lot of little yellow sticky notes.
121.973	And they would take a yellow sticky
121.973	and they would write something on it
124.823	and they would put it up on a board.
126.622	And one of them said, 
126.622	"""We had a robbery two weeks ago."
128.793	"We have no suspects."""
130.504	"And another said, ""We had a shooting in this neighborhood last week. We have no suspects."""
135.531	We weren't using data-driven policing.
138.114	We were essentially trying to fight crime
140.156	with yellow Post-it notes.
142.683	Now, both of these things made me realize
144.818	fundamentally that we were failing.
148.069	We didn't even know who was
148.069	in our criminal justice system,
151.192	we didn't have any data about
151.192	the things that mattered,
154.427	and we didn't share data or use analytics
156.995	or tools to help us make better decisions
159.146	and to reduce crime.
161.149	And for the first time, I started to think
163.373	about how we made decisions.
165.283	When I was an assistant D.A.,
166.68	and when I was a federal prosecutor,
168.55	I looked at the cases in front of me,
170.296	and I generally made decisions based on my instinct
172.922	and my experience.
174.614	When I became attorney general,
176.273	I could look at the system as a whole,
177.912	and what surprised me is that I found
179.73	that that was exactly how we were doing it
181.635	across the entire system --
183.938	in police departments, in prosecutors's offices,
186.339	in courts and in jails.
189.139	And what I learned very quickly
191.336	is that we weren't doing a good job.
194.969	So I wanted to do things differently.
196.985	I wanted to introduce data and analytics
199.182	and rigorous statistical analysis
201.231	into our work.
202.631	In short, I wanted to moneyball criminal justice.
205.601	Now, moneyball, as many of you know,
207.628	is what the Oakland A's did,
209.197	where they used smart data and statistics
211.17	to figure out how to pick players
212.792	that would help them win games,
214.313	and they went from a system that 
214.313	was based on baseball scouts
217.293	who used to go out and watch players
219.153	and use their instinct and experience,
220.79	the scouts' instincts and experience,
222.533	to pick players, from one to use
224.246	smart data and rigorous statistical analysis
227.068	to figure out how to pick players
227.068	that would help them win games.
230.439	It worked for the Oakland A's,
232.237	and it worked in the state of New Jersey.
234.456	We took Camden off the top of the list
236.529	as the most dangerous city in America.
238.7	We reduced murders there by 41 percent,
241.855	which actually means 37 lives were saved.
244.837	And we reduced all crime in the city by 26 percent.
248.577	We also changed the way
248.577	we did criminal prosecutions.
251.816	So we went from doing low-level drug crimes
253.821	that were outside our building
255.463	to doing cases of statewide importance,
257.805	on things like reducing violence
257.805	with the most violent offenders,
260.963	prosecuting street gangs,
262.821	gun and drug trafficking, and political corruption.
266.229	And all of this matters greatly,
268.731	because public safety to me
270.676	is the most important function of government.
273.212	If we're not safe, we can't be educated,
275.51	we can't be healthy,
276.858	we can't do any of the other things
276.858	we want to do in our lives.
279.803	And we live in a country today
281.504	where we face serious criminal justice problems.
284.638	We have 12 million arrests every single year.
288.299	The vast majority of those arrests
290.342	are for low-level crimes, like misdemeanors,
295.088	Less than five percent of all arrests
297.079	are for violent crime.
298.974	Yet we spend 75 billion,
301.029	that's b for billion,
302.447	dollars a year on state and local corrections costs.
306.574	Right now, today, we have 2.3 million people
309.415	in our jails and prisons.
311.315	And we face unbelievable public safety challenges
314.111	because we have a situation
316.05	in which two thirds of the people in our jails
318.948	are there waiting for trial.
320.702	They haven't yet been convicted of a crime.
322.837	They're just waiting for their day in court.
324.956	And 67 percent of people come back.
328.504	Our recidivism rate is amongst 
328.504	the highest in the world.
331.532	Almost seven in 10 people who are released
333.635	from prison will be rearrested
335.286	in a constant cycle of crime and incarceration.
339.241	So when I started my job at the Arnold Foundation,
341.823	I came back to looking at a lot of these questions,
344.559	and I came back to thinking about how
346.213	we had used data and analytics to transform
348.596	the way we did criminal justice in New Jersey.
351.18	And when I look at the criminal justice system
353.324	in the United States today,
354.98	I feel the exact same way that I did
356.619	about the state of New Jersey when I started there,
359.085	which is that we absolutely have to do better,
362.313	and I know that we can do better.
364.236	So I decided to focus
365.941	on using data and analytics
368.158	to help make the most critical decision
370.519	in public safety,
372.125	and that decision is the determination
374.146	of whether, when someone has been arrested,
376.681	whether they pose a risk to public safety
378.596	and should be detained,
380.122	or whether they don't pose a risk to public safety
382.478	and should be released.
384.115	Everything that happens in criminal cases
386.034	comes out of this one decision.
387.806	It impacts everything.
389.302	It impacts sentencing.
390.652	It impacts whether someone gets drug treatment.
392.553	It impacts crime and violence.
394.876	And when I talk to judges around the United States,
396.813	which I do all the time now,
398.741	they all say the same thing,
400.578	which is that we put dangerous people in jail,
403.685	and we let non-dangerous, nonviolent people out.
407.21	They mean it and they believe it.
409.443	But when you start to look at the data,
411.176	which, by the way, the judges don't have,
413.64	when we start to look at the data,
415.252	what we find time and time again,
417.67	is that this isn't the case.
419.652	We find low-risk offenders,
421.333	which makes up 50 percent of our
421.333	entire criminal justice population,
425.047	we find that they're in jail.
427.446	Take Leslie Chew, who was a Texas man
429.932	who stole four blankets on a cold winter night.
432.816	He was arrested, and he was kept in jail
435.411	on 3,500 dollars bail,
437.464	an amount that he could not afford to pay.
440.24	And he stayed in jail for eight months
442.828	until his case came up for trial,
444.893	at a cost to taxpayers of more than 9,000 dollars.
448.798	And at the other end of the spectrum,
450.795	we're doing an equally terrible job.
453.077	The people who we find
454.649	are the highest-risk offenders,
456.668	the people who we think have the highest likelihood
459.165	of committing a new crime if they're released,
461.117	we see nationally that 50 percent of those people
464.067	are being released.
466.041	The reason for this is the way we make decisions.
469.215	Judges have the best intentions
470.924	when they make these decisions about risk,
472.876	but they're making them subjectively.
475.36	They're like the baseball scouts 20 years ago
477.506	who were using their instinct and their experience
479.637	to try to decide what risk someone poses.
482.316	They're being subjective,
483.846	and we know what happens
483.846	with subjective decision making,
486.906	which is that we are often wrong.
489.649	What we need in this space
491.032	are strong data and analytics.
493.584	What I decided to look for
495.331	was a strong data and analytic risk assessment tool,
498.167	something that would let judges actually understand
500.931	with a scientific and objective way
503.19	what the risk was that was posed
504.837	by someone in front of them.
506.447	I looked all over the country,
508.096	and I found that between five and 10 percent
510.038	of all U.S. jurisdictions
511.367	actually use any type of risk assessment tool,
514.345	and when I looked at these tools,
515.97	I quickly realized why.
517.83	They were unbelievably expensive to administer,
520.52	they were time-consuming,
522.048	they were limited to the local jurisdiction
524.155	in which they'd been created.
525.585	So basically, they couldn't be scaled
527.378	or transferred to other places.
529.587	So I went out and built a phenomenal team
531.824	of data scientists and researchers
533.868	and statisticians
535.494	to build a universal risk assessment tool,
538.339	so that every single judge in
538.339	the United States of America
540.732	can have an objective, scientific measure of risk.
545.056	In the tool that we've built,
546.714	what we did was we collected 1.5 million cases
549.582	from all around the United States,
551.28	from cities, from counties,
552.924	from every single state in the country,
554.435	the federal districts.
556.181	And with those 1.5 million cases,
558.37	which is the largest data set on pretrial
560.31	in the United States today,
562.115	we were able to basically find that there were
567.302	to try to figure out what mattered most.
570.168	And we found that there were nine specific things
572.249	that mattered all across the country
574.484	and that were the most highly predictive of risk.
577.461	And so we built a universal risk assessment tool.
581.166	And it looks like this.
582.611	As you'll see, we put some information in,
585.223	but most of it is incredibly simple,
587.236	it's easy to use,
588.668	it focuses on things like the
588.668	defendant's prior convictions,
591.637	whether they've been sentenced to incarceration,
593.616	whether they've engaged in violence before,
595.88	whether they've even failed to come back to court.
598.273	And with this tool, we can predict three things.
600.773	First, whether or not someone will commit
602.626	a new crime if they're released.
604.191	Second, for the first time,
605.855	and I think this is incredibly important,
607.716	we can predict whether someone will commit
609.639	an act of violence if they're released.
611.473	And that's the single most important thing
613.36	that judges say when you talk to them.
615.167	And third, we can predict whether someone
616.995	will come back to court.
618.985	And every single judge in the
618.985	United States of America can use it,
622.018	because it's been created on a universal data set.
625.83	What judges see if they run the risk assessment tool
628.439	is this -- it's a dashboard.
630.559	At the top, you see the New Criminal Activity Score,
633.407	six of course being the highest,
635.336	and then in the middle you
635.336	"see, ""Elevated risk of violence."""
637.739	What that says is that this person
639.485	is someone who has an elevated risk of violence
641.545	that the judge should look twice at.
643.43	And then, towards the bottom,
644.766	you see the Failure to Appear Score,
646.734	which again is the likelihood
648.126	that someone will come back to court.
651.139	Now I want to say something really important.
653.352	It's not that I think we should be eliminating
656.079	the judge's instinct and experience
658.323	from this process.
659.927	I don't.
660.985	I actually believe the problem that we see
662.992	and the reason that we have
662.992	these incredible system errors,
665.846	where we're incarcerating
665.846	low-level, nonviolent people
668.933	and we're releasing high-risk, dangerous people,
672.105	is that we don't have an objective measure of risk.
674.828	But what I believe should happen
676.128	is that we should take that
676.128	data-driven risk assessment
678.928	and combine that with the
678.928	judge's instinct and experience
681.969	to lead us to better decision making.
684.927	The tool went statewide in Kentucky on July 1,
688.23	and we're about to go up in a
688.23	number of other U.S. jurisdictions.
691.581	Our goal, quite simply, is that every single judge
694.172	in the United States will use a data-driven risk tool
696.364	within the next five years.
698.455	We're now working on risk tools
699.807	for prosecutors and for police officers as well,
703.091	to try to take a system that runs today
705.791	in America the same way it did 50 years ago,
708.587	based on instinct and experience,
710.684	and make it into one that runs
712.539	on data and analytics.
715.008	Now, the great news about all this,
716.929	and we have a ton of work left to do,
718.546	and we have a lot of culture to change,
720.403	but the great news about all of it
722.149	is that we know it works.
724.017	It's why Google is Google,
726.17	and it's why all these baseball teams use moneyball
728.632	to win games.
730.413	The great news for us as well
732.15	is that it's the way that we can transform
734.046	the American criminal justice system.
736.367	It's how we can make our streets safer,
738.724	we can reduce our prison costs,
741.023	and we can make our system much fairer
743.09	and more just.
744.815	Some people call it data science.
746.977	I call it moneyballing criminal justice.
749.278	Thank you.
751.082	(Applause)
