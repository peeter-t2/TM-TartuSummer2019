startsecond	text
12.988	Let me tell you a story.
15.304	It goes back 200 million years.
17.103	It's a story of the neocortex,
19.087	"which means ""new rind."""
21.061	So in these early mammals,
23.492	because only mammals have a neocortex,
25.547	rodent-like creatures.
27.211	It was the size of a postage stamp and just as thin,
30.79	and was a thin covering around
32.229	their walnut-sized brain,
34.493	but it was capable of a new type of thinking.
38.194	Rather than the fixed behaviors
39.761	that non-mammalian animals have,
41.753	it could invent new behaviors.
44.445	So a mouse is escaping a predator,
46.998	its path is blocked,
48.538	it'll try to invent a new solution.
50.667	That may work, it may not,
51.933	but if it does, it will remember that
53.843	and have a new behavior,
55.135	and that can actually spread virally
56.592	through the rest of the community.
58.787	Another mouse watching this could say,
60.396	"""Hey, that was pretty clever, going around that rock,"""
63.1	and it could adopt a new behavior as well.
66.825	Non-mammalian animals
68.542	couldn't do any of those things.
70.255	They had fixed behaviors.
71.47	Now they could learn a new behavior
72.801	but not in the course of one lifetime.
75.377	In the course of maybe a thousand lifetimes,
77.144	it could evolve a new fixed behavior.
80.474	That was perfectly okay 200 million years ago.
83.851	The environment changed very slowly.
85.832	It could take 10,000 years for there to be
87.386	a significant environmental change,
89.478	and during that period of time
90.86	it would evolve a new behavior.
93.789	Now that went along fine,
95.31	but then something happened.
97.014	Sixty-five million years ago,
99.26	there was a sudden, violent
99.26	change to the environment.
101.875	We call it the Cretaceous extinction event.
105.38	That's when the dinosaurs went extinct,
107.673	that's when 75 percent of the
111.122	animal and plant species went extinct,
113.868	and that's when mammals
115.613	overtook their ecological niche,
117.765	and to anthropomorphize, biological evolution said,
121.419	"""Hmm, this neocortex is pretty good stuff,"""
123.444	and it began to grow it.
125.237	And mammals got bigger,
126.579	their brains got bigger at an even faster pace,
129.494	and the neocortex got bigger even faster than that
133.301	and developed these distinctive ridges and folds
136.23	basically to increase its surface area.
139.111	If you took the human neocortex
140.93	and stretched it out,
142.231	it's about the size of a table napkin,
143.944	and it's still a thin structure.
145.25	It's about the thickness of a table napkin.
147.23	But it has so many convolutions and ridges
149.727	it's now 80 percent of our brain,
152.802	and that's where we do our thinking,
155.263	and it's the great sublimator.
157.024	We still have that old brain
158.138	that provides our basic drives and motivations,
160.902	but I may have a drive for conquest,
163.618	and that'll be sublimated by the neocortex
166.333	into writing a poem or inventing an app
169.242	or giving a TED Talk,
170.751	and it's really the neocortex that's where
174.373	the action is.
176.341	Fifty years ago, I wrote a paper
178.058	describing how I thought the brain worked,
179.976	and I described it as a series of modules.
183.175	Each module could do things with a pattern.
185.303	It could learn a pattern. It could remember a pattern.
188.049	It could implement a pattern.
189.456	And these modules were organized in hierarchies,
192.135	and we created that hierarchy with our own thinking.
195.089	And there was actually very little to go on
199.984	It led me to meet President Johnson.
202.099	I've been thinking about this for 50 years,
204.272	and a year and a half ago I came out with the book
207.1	"""How To Create A Mind,"""
208.365	which has the same thesis,
209.978	but now there's a plethora of evidence.
212.79	The amount of data we're getting about the brain
214.604	from neuroscience is doubling every year.
216.807	Spatial resolution of brainscanning of all types
219.461	is doubling every year.
221.746	We can now see inside a living brain
223.463	and see individual interneural connections
226.333	connecting in real time, firing in real time.
229.036	We can see your brain create your thoughts.
231.455	We can see your thoughts create your brain,
233.03	which is really key to how it works.
235.029	So let me describe briefly how it works.
237.248	I've actually counted these modules.
239.523	We have about 300 million of them,
241.569	and we create them in these hierarchies.
243.798	I'll give you a simple example.
245.88	I've got a bunch of modules
248.685	that can recognize the crossbar to a capital A,
252.088	and that's all they care about.
254.002	A beautiful song can play,
255.58	a pretty girl could walk by,
257.014	they don't care, but they see
257.014	a crossbar to a capital A,
259.86	"they get very excited and they say ""crossbar,"""
262.881	and they put out a high probability
264.993	on their output axon.
266.627	That goes to the next level,
267.96	and these layers are organized in conceptual levels.
270.71	Each is more abstract than the next one,
272.566	"so the next one might say ""capital A."""
274.984	That goes up to a higher
274.984	"level that might say ""Apple."""
277.875	Information flows down also.
280.042	If the apple recognizer has seen A-P-P-L,
282.978	"it'll think to itself, ""Hmm, I"
282.978	"think an E is probably likely,"""
286.197	and it'll send a signal down to all the E recognizers
288.761	"saying, ""Be on the lookout for an E,"
290.38	"I think one might be coming."""
291.936	The E recognizers will lower their threshold
294.779	and they see some sloppy
294.779	thing, could be an E.
296.724	Ordinarily you wouldn't think so,
298.214	but we're expecting an E, it's good enough,
300.223	and yeah, I've seen an E, and then apple says,
302.04	"""Yeah, I've seen an Apple."""
303.768	Go up another five levels,
305.514	and you're now at a pretty high level
306.867	of this hierarchy,
308.436	and stretch down into the different senses,
310.789	and you may have a module
310.789	that sees a certain fabric,
313.444	hears a certain voice quality,
313.444	smells a certain perfume,
316.288	"and will say, ""My wife has entered the room."""
318.801	Go up another 10 levels, and now you're at
320.696	a very high level.
321.856	You're probably in the frontal cortex,
323.793	"and you'll have modules that say, ""That was ironic."
327.56	"That's funny. She's pretty."""
329.93	You might think that those are more sophisticated,
332.035	but actually what's more complicated
333.541	is the hierarchy beneath them.
336.21	There was a 16-year-old girl, she had brain surgery,
338.83	and she was conscious because the surgeons
340.881	wanted to talk to her.
342.418	You can do that because there's no pain receptors
344.24	in the brain.
345.278	And whenever they stimulated particular,
347.078	very small points on her neocortex,
349.541	shown here in red, she would laugh.
352.206	So at first they thought they were triggering
353.646	some kind of laugh reflex,
355.366	but no, they quickly realized they had found
357.885	the points in her neocortex that detect humor,
360.929	and she just found everything hilarious
362.898	whenever they stimulated these points.
365.335	"""You guys are so funny just standing around,"""
367.26	was the typical comment,
368.998	and they weren't funny,
371.3	not while doing surgery.
374.547	So how are we doing today?
379.377	Well, computers are actually beginning to master
382.431	human language with techniques
384.432	that are similar to the neocortex.
387.299	I actually described the algorithm,
388.813	which is similar to something called
390.867	a hierarchical hidden Markov model,
393.1	something I've worked on since the '90s.
396.341	"""Jeopardy"" is a very broad natural language game,"
399.579	and Watson got a higher score
401.471	than the best two players combined.
403.471	It got this query correct:
405.97	"""A long, tiresome speech"
408.055	"delivered by a frothy pie topping,"""
410.207	and it quickly responded,
410.207	"""What is a meringue harangue?"""
413.003	And Jennings and the other guy didn't get that.
415.638	It's a pretty sophisticated example of
417.564	computers actually understanding human language,
419.478	and it actually got its knowledge by reading
421.13	Wikipedia and several other encyclopedias.
424.915	Five to 10 years from now,
427.048	search engines will actually be based on
429.232	not just looking for combinations of words and links
432.026	but actually understanding,
433.94	reading for understanding the billions of pages
436.351	on the web and in books.
439.084	So you'll be walking along, and Google will pop up
441.7	"and say, ""You know, Mary, you expressed concern"
444.781	to me a month ago that your glutathione supplement
447.8	wasn't getting past the blood-brain barrier.
450.031	Well, new research just came out 13 seconds ago
452.624	that shows a whole new approach to that
454.335	and a new way to take glutathione.
456.328	"Let me summarize it for you."""
458.89	Twenty years from now, we'll have nanobots,
462.574	because another exponential trend
464.201	is the shrinking of technology.
465.816	They'll go into our brain
468.186	through the capillaries
469.889	and basically connect our neocortex
472.366	to a synthetic neocortex in the cloud
475.551	providing an extension of our neocortex.
479.142	Now today, I mean,
480.72	you have a computer in your phone,
482.25	but if you need 10,000 computers for a few seconds
485.004	to do a complex search,
486.499	you can access that for a second or two in the cloud.
489.895	In the 2030s, if you need some extra neocortex,
492.99	you'll be able to connect to that in the cloud
495.263	directly from your brain.
496.911	So I'm walking along and I say,
498.454	"""Oh, there's Chris Anderson."
499.817	He's coming my way.
501.342	I'd better think of something clever to say.
503.677	I've got three seconds.
505.201	My 300 million modules in my neocortex
508.298	isn't going to cut it.
509.538	"I need a billion more."""
510.784	I'll be able to access that in the cloud.
514.107	And our thinking, then, will be a hybrid
516.919	of biological and non-biological thinking,
520.441	but the non-biological portion
522.339	is subject to my law of accelerating returns.
525.021	It will grow exponentially.
527.26	And remember what happens
529.276	the last time we expanded our neocortex?
531.921	That was two million years ago
533.347	when we became humanoids
534.583	and developed these large foreheads.
536.177	Other primates have a slanted brow.
538.76	They don't have the frontal cortex.
540.505	But the frontal cortex is not
540.505	really qualitatively different.
544.19	It's a quantitative expansion of neocortex,
546.933	but that additional quantity of thinking
549.636	was the enabling factor for us to take
551.415	a qualitative leap and invent language
554.761	and art and science and technology
556.728	and TED conferences.
558.182	No other species has done that.
560.313	And so, over the next few decades,
562.388	we're going to do it again.
564.148	We're going to again expand our neocortex,
566.422	only this time we won't be limited
568.178	by a fixed architecture of enclosure.
572.458	It'll be expanded without limit.
575.762	That additional quantity will again
578.005	be the enabling factor for another qualitative leap
581.01	in culture and technology.
582.645	Thank you very much.
584.699	(Applause)
