startsecond	text
12.485	Ten years ago, I wrote a book which I entitled
14.707	"""Our Final Century?"" Question mark."
17.8	My publishers cut out the question mark. (Laughter)
21.377	The American publishers changed our title
23.259	"to ""Our Final Hour."""
27.168	Americans like instant gratification and the reverse.
30.66	(Laughter)
32.368	And my theme was this:
34.118	Our Earth has existed for 45 million centuries,
38.284	but this one is special —
40.297	it's the first where one species, ours,
43.313	has the planet's future in its hands.
46.115	Over nearly all of Earth's history,
48.105	threats have come from nature —
50.041	disease, earthquakes, asteroids and so forth —
53.537	but from now on, the worst dangers come from us.
59.209	And it's now not just the nuclear threat;
62.48	in our interconnected world,
64.231	network breakdowns can cascade globally;
67.394	air travel can spread pandemics
67.394	worldwide within days;
71.35	and social media can spread panic and rumor
74.677	literally at the speed of light.
77.894	We fret too much about minor hazards —
81.119	improbable air crashes, carcinogens in food,
85.15	low radiation doses, and so forth —
87.376	but we and our political masters
90.201	are in denial about catastrophic scenarios.
94.404	The worst have thankfully not yet happened.
97.442	Indeed, they probably won't.
99.638	But if an event is potentially devastating,
102.823	it's worth paying a substantial premium
105.691	to safeguard against it, even if it's unlikely,
109.527	just as we take out fire insurance on our house.
114.04	And as science offers greater power and promise,
119.037	the downside gets scarier too.
122.903	We get ever more vulnerable.
125.142	Within a few decades,
126.98	millions will have the capability
129.21	to misuse rapidly advancing biotech,
132.331	just as they misuse cybertech today.
135.884	Freeman Dyson, in a TED Talk,
139.083	foresaw that children will design
139.083	and create new organisms
142.679	just as routinely as his generation
142.679	played with chemistry sets.
147.19	Well, this may be on the science fiction fringe,
149.718	but were even part of his scenario to come about,
152.901	our ecology and even our species
155.638	would surely not survive long unscathed.
159.627	For instance, there are some eco-extremists
163.49	who think that it would be better for the planet,
165.999	for Gaia, if there were far fewer humans.
169.402	What happens when such people have mastered
172.119	synthetic biology techniques
174.256	that will be widespread by 2050?
177.108	And by then, other science fiction nightmares
180.15	may transition to reality:
181.86	dumb robots going rogue,
183.93	or a network that develops a mind of its own
186.347	threatens us all.
188.936	Well, can we guard against such risks by regulation?
192.206	We must surely try, but these enterprises
194.613	are so competitive, so globalized,
198.142	and so driven by commercial pressure,
200.122	that anything that can be done
200.122	will be done somewhere,
203.407	whatever the regulations say.
205.443	It's like the drug laws — we try to regulate, but can't.
208.93	And the global village will have its village idiots,
211.974	and they'll have a global range.
215.47	So as I said in my book,
217.761	we'll have a bumpy ride through this century.
220.65	There may be setbacks to our society —
224.14	indeed, a 50 percent chance of a severe setback.
228.255	But are there conceivable events
231.169	that could be even worse,
233.33	events that could snuff out all life?
236.76	When a new particle accelerator came online,
239.686	some people anxiously asked,
241.475	could it destroy the Earth or, even worse,
243.725	rip apart the fabric of space?
246.384	Well luckily, reassurance could be offered.
249.927	I and others pointed out that nature
251.971	has done the same experiments
253.904	zillions of times already,
256.09	via cosmic ray collisions.
257.855	But scientists should surely be precautionary
260.909	about experiments that generate conditions
263.489	without precedent in the natural world.
265.972	Biologists should avoid release
265.972	of potentially devastating
269.395	genetically modified pathogens.
272.11	And by the way, our special aversion
275.627	to the risk of truly existential disasters
279.088	depends on a philosophical and ethical question,
282.363	and it's this:
284.033	Consider two scenarios.
286.341	Scenario A wipes out 90 percent of humanity.
291.577	Scenario B wipes out 100 percent.
295.473	How much worse is B than A?
298.391	Some would say 10 percent worse.
301.414	The body count is 10 percent higher.
304.564	But I claim that B is incomparably worse.
307.47	As an astronomer, I can't believe
310.099	that humans are the end of the story.
312.566	It is five billion years before the sun flares up,
315.889	and the universe may go on forever,
318.6	so post-human evolution,
320.892	here on Earth and far beyond,
323.082	could be as prolonged as the Darwinian process
325.796	that's led to us, and even more wonderful.
329.077	And indeed, future evolution
329.077	will happen much faster,
331.741	on a technological timescale,
333.94	not a natural selection timescale.
336.239	So we surely, in view of those immense stakes,
340.434	shouldn't accept even a one in a billion risk
343.82	that human extinction would foreclose
346.049	this immense potential.
348.359	Some scenarios that have been envisaged
350.131	may indeed be science fiction,
351.95	but others may be disquietingly real.
355.336	It's an important maxim that the unfamiliar
358.21	is not the same as the improbable,
360.907	and in fact, that's why we at Cambridge University
363.305	are setting up a center to study how to mitigate
366.68	these existential risks.
368.712	It seems it's worthwhile just for a few people
371.775	to think about these potential disasters.
374.091	And we need all the help we can get from others,
377.104	because we are stewards of a precious
379.583	pale blue dot in a vast cosmos,
383.066	a planet with 50 million centuries ahead of it.
386.444	And so let's not jeopardize that future.
389	And I'd like to finish with a quote
390.795	from a great scientist called Peter Medawar.
394.296	"I quote, ""The bells that toll for mankind"
397.569	are like the bells of Alpine cattle.
400.213	They are attached to our own necks,
402.499	and it must be our fault if they do not make
405.174	"a tuneful and melodious sound."""
407.305	Thank you very much.
409.572	(Applause)
