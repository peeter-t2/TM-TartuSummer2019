startsecond	text
13.072	Today's computers are so amazing
16.81	that we fail to notice
16.81	how terrible they really are.
22.172	I'd like to talk to you today
22.172	about this problem,
24.594	and how we can fix it with neuroscience.
28.056	First, I'd like to take you back
28.056	to a frosty night in Harlem in 2011
32.097	that had a profound impact on me.
34.437	I was sitting in a dive bar
34.437	outside of Columbia University,
37.635	where I studied computer science
37.635	and neuroscience,
40.567	and I was having this great conversation
40.567	with a fellow student
43.659	about the power of holograms
43.659	to one day replace computers.
47.39	And just as we were getting
47.39	to the best part of the conversation,
50.503	of course, his phone lights up.
52.621	And he pulls it towards himself,
52.621	and he looks down and he starts typing.
57.07	And then he forces his eyeballs
57.07	back up to mine and he goes,
60.277	"""Keep going. I'm with you."""
62.404	But of course his eyes were glazed over,
64.785	and the moment was dead.
66.964	Meanwhile across the bar,
68.208	I noticed another student
68.208	holding his phone,
70.516	this time towards a group.
71.985	He was swiping through
71.985	pictures on Instagram,
74.769	and these kids were laughing hysterically.
77.327	And that dichotomy
77.327	between how crappy I was feeling
80.87	and how happy they were feeling
80.87	about the same technology,
83.672	really got me thinking.
85.074	And the more I thought of it,
85.074	the more I realized
87.431	it was clearly not the digital information
87.431	that was the bad guy here,
91.227	it was simply the display position
91.227	that was separating me from my friend
94.958	and that was binding those kids together.
97.608	See, they were connected around something,
99.831	just like our ancestors
99.831	who evolved their social cognitions
103.253	telling stories around the campfire.
105.857	And that's exactly what tools
105.857	should do, I think.
108.225	They should extend our bodies.
109.728	And I think computers today
109.728	are doing quite the opposite.
112.939	Whether you're sending
112.939	an email to your wife
115.191	or you're composing a symphony
117.237	or just consoling a friend,
118.865	you're doing it in pretty
118.865	much the same way.
121.235	You're hunched over these rectangles,
123.492	fumbling with buttons and menus
123.492	and more rectangles.
126.759	And I think this is the wrong way,
128.78	I think we can start using
128.78	a much more natural machine.
132.232	We should use machines that bring
132.232	our work back into the world.
135.774	We should use machines that use
135.774	the principles of neuroscience
138.817	to extend our senses
138.817	versus going against them.
143.305	Now it just so happens
143.305	that I have such a machine here.
146.116	It's called the Meta 2.
147.297	Let's try it out.
157.617	Now in front of me right now,
157.617	I can see the audience,
160.454	and I can see my very hands.
163.026	And in three, two, one,
165.227	we're going to see an immersive
165.227	hologram appear,
168.003	a very realistic hologram
168.003	appear in front of me,
170.307	of our very glasses I'm wearing
170.307	on my head right now.
172.895	And of course this could be
172.895	anything that we're shopping for
175.76	or learning from,
176.935	and I can use my hands
178.302	to very nicely kind of move
178.302	it around with fine control.
182.434	And I think Iron Man would be proud.
186.643	We're going to come back
186.643	to this in just a bit.
189.783	(Applause)
191.971	Now if you're anything like me,
191.971	your mind is already reeling
194.906	with the possibilities of what we can do
194.906	with this kind of technology,
198.231	so let's look at a few.
199.413	My mom is an architect,
200.587	so naturally the first thing I imagined
202.516	was laying out a building in 3D space
205.021	instead of having to use
205.021	these 2D floor plans.
207.437	She's actually touching graphics right now
209.926	and selecting an interior decor.
211.727	This was all shot through a GoPro
211.727	through our very glasses.
215.115	And this next use case
215.115	is very personal to me,
217.754	it's Professor Adam Gazzaley's
217.754	glass brain project,
221.192	courtesy of UCSF.
223.107	As a neuroscience student,
224.826	I would always fantasize
226.247	about the ability to learn and memorize
226.247	these complex brain structures
231.71	with an actual machine,
232.901	where I could touch and play
232.901	with the various brain structures.
236.535	Now what you're seeing
236.535	is called augmented reality,
240.085	but to me, it's part
240.085	of a much more important story --
243.512	a story of how we can begin
243.512	to extend our bodies with digital devices,
250.227	instead of the other way around.
253.734	Now ...
255.227	in the next few years, humanity's
255.227	going to go through a shift, I think.
258.613	We're going to start putting
258.613	an entire layer of digital information
261.85	on the real world.
264.05	Just imagine for a moment
265.342	what this could mean for storytellers,
267.626	for painters,
268.965	for brain surgeons,
271.147	for interior decorators
272.988	and maybe for all of us here today.
275.544	And what I think we need
275.544	to do as a community,
277.735	is really try and make an effort
279.751	to imagine how we can
279.751	create this new reality
282.666	in a way that extends
282.666	the human experience,
285.388	instead of gamifying our reality
287.38	or cluttering it with digital information.
289.467	And that's what I'm very passionate about.
292.318	Now, I want to tell you a little secret.
294.503	In about five years --
295.694	this is not the smallest device --
297.344	in about five years,
298.536	these are all going to look like
298.536	strips of glass on our eyes
301.488	that project holograms.
303.426	And just like we don't care so much
303.426	about which phone we buy
306.76	in terms of the hardware -- we buy it
306.76	for the operating system --
310.205	as a neuroscientist,
311.388	I always dreamt of building
311.388	the iOS of the mind, if you will.
316.537	And it's very, very important
316.537	that we get this right,
319.441	because we might be living
319.441	inside of these things
321.759	for at least as long as we've lived
323.471	with the Windows graphical user interface.
326.136	And I don't know about you,
327.477	but living inside of Windows scares me.
330.009	(Laughter)
331.353	To isolate the single most intuitive
331.353	interface out of infinity,
335.267	we use neuroscience to drive
335.267	our design guidelines,
337.971	instead of letting a bunch of designers
337.971	fight it out in the boardroom.
341.585	And the principle we all revolve around
344.258	"is what's called the ""Neural Path"
344.258	"of Least Resistance."""
347.29	At every turn, we're connecting
347.29	the iOS of the brain with our brain
351.445	on, for the first time, our brain's terms.
353.855	In other words, we're trying to create
353.855	a zero learning-curve computer.
358.738	We're building a system
358.738	that you've always known how to use.
362.097	Here are the first three
362.097	design guidelines that we employ
365.014	in this brand-new form of user experience.
367.369	First and foremost,
367.369	you are the operating system.
370.787	Traditional file systems
370.787	are complex and abstract,
373.518	and they take your brain
373.518	extra steps to decode them.
376.133	We're going against the Neural Path
376.133	of Least Resistance.
378.962	Meanwhile, in augmented reality,
381.184	you can of course place
381.184	your holographic TED panel over here,
386.183	and your holographic email
386.183	on the other side of the desk,
389.758	and your spatial memory evolved just fine
389.758	to go ahead and retrieve them.
395.605	You could put your holographic Tesla
395.605	that you're shopping for --
398.657	or whatever model my legal team
398.657	told me to put in right before the show.
402.186	(Laughter)
403.212	Perfect. And your brain knows
403.212	exactly how to get it back.
405.968	The second interface guideline
405.968	"we call ""touch to see."""
409.97	What do babies do when they see
409.97	something that grabs their interest?
414.712	They try and reach out and touch it.
416.452	And that's exactly how the natural
416.452	machine should work as well.
420.439	Turns out the visual system
420.439	gets a fundamental boost
422.951	from a sense we call proprioception --
425.384	that's the sense
425.384	of our body parts in space.
427.653	So by touching our work directly,
427.653	we're not only going to control it better,
431.487	we're also going to understand
431.487	it much more deeply.
434.637	Hence, touch to see.
436.323	But it's not enough
436.323	to experience things ourselves.
438.742	We're inherently these social primates.
440.993	And this leads me to our third guideline,
443.129	the holographic campfire
443.129	from our first story.
446.537	Our mirror-neuron subsystem suggests
448.475	that we can connect with each other
448.475	and with our work much better
452.047	if we can see each other's
452.047	faces and hands in 3D.
455.056	So if you look at the video behind me,
456.917	you can see two Meta users
456.917	playing around with the same hologram,
461.25	making eye contact,
461.25	connected around this thing,
463.989	instead of being distracted
463.989	by external devices.
468.711	Let's go ahead and try this again
468.711	with neuroscience in mind.
476.127	So again, our favorite interface,
476.127	the iOS of the mind.
480.315	I'm going to now take a step further
482.25	and go ahead and grab this pair of glasses
485.024	and leave it right here by the desk.
486.768	I'm now with you, I'm in the moment,
488.514	we're connecting.
489.69	My spatial memory kicks in,
489.69	and I can go ahead and grab it
492.632	and bring it right back here, reminding me
494.757	that I am the operating system.
496.667	And now my proprioception is working,
499.071	and I can go ahead and explode
499.071	these glasses into a thousand parts
502.891	and touch the very sensor
502.891	that is currently scanning my hand.
507.305	But it's not enough to see things alone,
509.29	so in a second, my co-founder Ray
509.29	is going to make a 3D call --
512.286	Ray?
513.468	(Ringing)
515.387	Hey Ray, how's it going?
516.907	Guys, I can see this guy
516.907	in front me in full 3D.
520.359	And he is photo-realistic.
522.68	(Applause)
524	Thank you.
525.176	My mirror-neuron subsystem suggests
525.176	that this is going to replace phones
529.181	in not too long.
530.601	Ray, how's it going?
532.443	Ray: Great. We're live today.
534.832	(Applause)
536.405	MG: Ray, give the crowd a gift
538.541	of the holographic brain
538.541	we saw from the video earlier.
541.2	Guys, this is not only
541.2	going to change phones,
543.382	it's also going to change
543.382	the way we collaborate.
546.7	Thank you so much.
547.987	Thanks, Ray.
549.169	Ray: You're welcome.
550.344	(Applause)
551.375	MG: So folks, this is the message
551.375	that I discovered in that bar in 2011:
556.347	The future of computers is not
556.347	locked inside one of these screens.
560.944	It's right here, inside of us.
565.876	(Applause)
569.923	So if there's one idea that I could
569.923	leave you with here today,
572.86	it's that the natural machine
572.86	is not some figment of the future,
575.94	it's right here in 2016.
578.447	Which is why all hundred of us at Meta,
581.246	including the administrative staff,
582.945	the executives,
584.411	the designers, the engineers --
586.158	before TED2017,
588.084	we're all going to be throwing
588.084	away our external monitors
591.765	and replacing them with a truly
591.765	and profoundly more natural machine.
596.909	Thank you very much.
598.124	(Applause)
602.079	Thank you, appreciate it.
605.501	Thanks, guys.
609.928	Chris Anderson: So help
609.928	me out on one thing,
612.796	because there've been a few
612.796	augmented reality demos
615.448	shown over the last year or so out there.
618.178	And there's sometimes
618.178	a debate among technologists
620.611	about, are we really seeing
620.611	the real thing on-screen?
624.34	There's this issue of field of view,
626.104	that somehow the technology
626.104	is showing a broader view
629.594	than you would actually see
629.594	wearing the glasses.
633.086	Were we seeing the real deal there?
634.833	MG: Absolutely the real deal.
636.27	Not only that,
637.451	we took extra measures to shoot it
637.451	with a GoPro through the actual lens
640.812	in the various videos
640.812	that you've seen here.
642.889	We want to try to simulate
642.889	the experience for the world
645.489	that we're actually seeing
645.489	through the glasses,
647.706	and not cut any corners.
648.881	CA: Thank you so much for showing us that.
650.929	MG: Thanks so much, I appreciate that.
