startsecond	text
16.26	So since I was here last in '06,
19.26	we discovered that global climate change
21.26	is turning out to be a pretty serious issue,
23.26	so we covered that fairly extensively
25.26	in Skeptic magazine.
27.26	We investigate all kinds
29.26	of scientific and quasi-scientific controversies,
32.26	but it turns out we don't have to worry about any of this
34.26	because the world's going to end in 2012.
36.26	Another update:
38.26	You will recall I introduced you guys
40.26	to the Quadro Tracker.
42.26	It's like a water dowsing device.
44.26	It's just a hollow piece of plastic with an antenna that swivels around.
47.26	And you walk around, and it points to things.
49.26	Like if you're looking for marijuana in students' lockers,
52.26	it'll point right to somebody.
54.26	Oh, sorry. (Laughter)
56.26	This particular one that was given to me
58.26	finds golf balls,
60.26	especially if you're at a golf course
62.26	and you check under enough bushes.
65.26	"Well, under the category of ""What's the harm of silly stuff like this?"""
68.26	this device, the ADE 651,
71.26	was sold to the Iraqi government
74.26	for 40,000 dollars apiece.
76.26	It's just like this one, completely worthless,
78.26	"in which it allegedly worked by ""electrostatic"
80.26	"magnetic ion attraction,"""
84.26	which translates to
86.26	"""pseudoscientific baloney"" -- would be the nice word --"
89.26	in which you string together a bunch of words that sound good,
91.26	but it does absolutely nothing.
93.26	In this case, at trespass points,
96.26	allowing people to go through
98.26	because your little tracker device said they were okay,
101.26	actually cost lives.
104.26	So there is a danger to pseudoscience,
106.26	in believing in this sort of thing.
109.26	So what I want to talk about today is belief.
112.26	I want to believe,
114.26	and you do too.
116.26	And in fact, I think my thesis here is that
118.26	belief is the natural state of things.
120.26	It is the default option. We just believe.
122.26	We believe all sorts of things.
124.26	Belief is natural;
126.26	disbelief, skepticism, science, is not natural.
128.26	It's more difficult.
130.26	It's uncomfortable to not believe things.
132.26	"So like Fox Mulder on ""X-Files,"""
135.26	who wants to believe in UFOs? Well, we all do,
138.26	and the reason for that is because
140.26	we have a belief engine in our brains.
143.26	Essentially, we are pattern-seeking primates.
146.26	We connect the dots: A is connected to B; B is connected to C.
149.26	And sometimes A really is connected to B,
152.26	and that's called association learning.
154.26	We find patterns, we make those connections,
157.26	whether it's Pavlov's dog here
159.26	associating the sound of the bell with the food,
162.26	and then he salivates to the sound of the bell,
164.26	or whether it's a Skinnerian rat,
166.26	in which he's having an association
168.26	between his behavior and a reward for it,
170.26	and therefore he repeats the behavior.
172.26	In fact, what Skinner discovered
174.26	is that, if you put a pigeon in a box like this,
177.26	and he has to press one of these two keys,
179.26	and he tries to figure out what the pattern is,
181.26	and you give him a little reward in the hopper box there --
183.26	if you just randomly assign rewards
186.26	such that there is no pattern,
188.26	they will figure out any kind of pattern.
190.26	And whatever they were doing just before they got the reward,
192.26	they repeat that particular pattern.
194.26	Sometimes it was even spinning around twice counterclockwise,
197.26	once clockwise and peck the key twice.
200.26	And that's called superstition,
202.26	and that, I'm afraid,
204.26	we will always have with us.
206.26	"I call this process ""patternicity"" --"
208.26	that is, the tendency to find meaningful patterns
210.26	in both meaningful and meaningless noise.
213.26	When we do this process, we make two types of errors.
216.26	A Type I error, or false positive,
218.26	is believing a pattern is real
220.26	when it's not.
222.26	Our second type of error is a false negative.
224.26	A Type II error is not believing
226.26	a pattern is real when it is.
229.26	So let's do a thought experiment.
231.26	You are a hominid three million years ago
233.26	walking on the plains of Africa.
236.26	Your name is Lucy, okay?
238.26	And you hear a rustle in the grass.
240.26	Is it a dangerous predator,
242.26	or is it just the wind?
244.26	Your next decision could be the most important one of your life.
247.26	Well, if you think that the rustle in the grass is a dangerous predator
250.26	and it turns out it's just the wind,
252.26	you've made an error in cognition,
254.26	made a Type I error, false positive.
256.26	But no harm. You just move away.
258.26	You're more cautious. You're more vigilant.
260.26	On the other hand, if you believe that the rustle in the grass is just the wind,
262.26	and it turns out it's a dangerous predator,
265.26	you're lunch.
267.26	You've just won a Darwin award.
269.26	You've been taken out of the gene pool.
271.26	Now the problem here is that
273.26	patternicities will occur whenever the cost
275.26	of making a Type I error
277.26	is less than the cost of making a Type II error.
279.26	This is the only equation in the talk by the way.
281.26	We have a pattern detection problem
283.26	that is assessing the difference between a Type I and a Type II error
286.26	is highly problematic,
288.26	especially in split-second, life-and-death situations.
291.26	So the default position
293.26	is just: Believe all patterns are real --
295.26	All rustles in the grass are dangerous predators
298.26	and not just the wind.
300.26	And so I think that we evolved ...
302.26	there was a natural selection for the propensity for our belief engines,
305.26	our pattern-seeking brain processes,
307.26	to always find meaningful patterns
309.26	and infuse them with these sort of
311.26	predatory or intentional agencies that I'll come back to.
314.26	So for example, what do you see here?
316.26	It's a horse head, that's right.
318.26	It looks like a horse. It must be a horse.
320.26	That's a pattern.
322.26	And is it really a horse?
324.26	Or is it more like a frog?
327.26	See, our pattern detection device,
329.26	which appears to be located in the anterior cingulate cortex --
332.26	it's our little detection device there --
335.26	can be easily fooled, and this is the problem.
337.26	For example, what do you see here?
339.26	Yes, of course, it's a cow.
342.26	Once I prime the brain -- it's called cognitive priming --
345.26	once I prime the brain to see it,
347.26	it pops back out again even without the pattern that I've imposed on it.
350.26	And what do you see here?
352.26	Some people see a Dalmatian dog.
354.26	Yes, there it is. And there's the prime.
356.26	So when I go back without the prime,
358.26	your brain already has the model
360.26	so you can see it again.
362.26	What do you see here?
365.26	Planet Saturn. Yes, that's good.
367.26	How about here?
370.26	Just shout out anything you see.
374.26	That's a good audience, Chris.
376.26	Because there's nothing in this. Well, allegedly there's nothing.
379.26	This is an experiment done by Jennifer Whitson
382.26	at U.T. Austin
384.26	on corporate environments
386.26	and whether feelings of uncertainty and out of control
389.26	makes people see illusory patterns.
391.26	That is, almost everybody sees the planet Saturn.
394.26	People that are put in a condition of feeling out of control
397.26	are more likely to see something in this,
399.26	which is allegedly patternless.
402.26	In other words, the propensity to find these patterns
405.26	goes up when there's a lack of control.
408.26	For example, baseball players are notoriously superstitious
411.26	when they're batting,
413.26	but not so much when they're fielding.
415.26	Because fielders are successful
419.26	The best batters fail seven out of 10 times.
422.26	So their superstitions, their patternicities,
424.26	are all associated with feelings of lack of control
427.26	and so forth.
430.26	What do you see in this particular one here, in this field?
433.26	Anybody see an object there?
435.26	There actually is something here,
437.26	but it's degraded.
439.26	While you're thinking about that,
441.26	this was an experiment done by Susan Blackmore,
443.26	a psychologist in England,
445.26	who showed subjects this degraded image
447.26	and then ran a correlation between
449.26	their scores on an ESP test:
451.26	How much did they believe in the paranormal,
453.26	supernatural, angels and so forth.
456.26	And those who scored high on the ESP scale,
459.26	tended to not only see
461.26	more patterns in the degraded images
463.26	but incorrect patterns.
465.26	Here is what you show subjects.
467.26	The fish is degraded 20 percent, 50 percent
470.26	and then the one I showed you,
474.26	A similar experiment was done by another [Swiss] psychologist
476.26	named Peter Brugger,
478.26	who found significantly more meaningful patterns
481.26	were perceived on the right hemisphere,
483.26	via the left visual field, than the left hemisphere.
486.26	So if you present subjects the images such
488.26	that it's going to end up on the right hemisphere instead of the left,
491.26	then they're more likely to see patterns
493.26	than if you put it on the left hemisphere.
495.26	Our right hemisphere appears to be
497.26	where a lot of this patternicity occurs.
499.26	So what we're trying to do is bore into the brain
501.26	to see where all this happens.
503.26	Brugger and his colleague, Christine Mohr,
506.26	gave subjects L-DOPA.
508.26	L-DOPA's a drug, as you know, given for treating Parkinson's disease,
511.26	which is related to a decrease in dopamine.
514.26	L-DOPA increases dopamine.
516.26	An increase of dopamine caused
518.26	subjects to see more patterns
520.26	than those that did not receive the dopamine.
522.26	So dopamine appears to be the drug
524.26	associated with patternicity.
526.26	In fact, neuroleptic drugs
528.26	that are used to eliminate psychotic behavior,
530.26	things like paranoia, delusions
532.26	and hallucinations,
534.26	these are patternicities.
536.26	They're incorrect patterns. They're false positives. They're Type I errors.
539.26	And if you give them drugs
541.26	that are dopamine antagonists,
543.26	they go away.
545.26	That is, you decrease the amount of dopamine,
547.26	and their tendency to see
549.26	patterns like that decreases.
551.26	On the other hand, amphetamines like cocaine
554.26	are dopamine agonists.
556.26	They increase the amount of dopamine.
558.26	So you're more likely to feel in a euphoric state,
561.26	creativity, find more patterns.
563.26	In fact, I saw Robin Williams recently
565.26	talk about how he thought he was much funnier
567.26	when he was doing cocaine, when he had that issue, than now.
570.26	So perhaps more dopamine
572.26	is related to more creativity.
574.26	Dopamine, I think, changes
576.26	our signal-to-noise ratio.
578.26	That is, how accurate we are
580.26	in finding patterns.
582.26	If it's too low, you're more likely to make too many Type II errors.
585.26	You miss the real patterns. You don't want to be too skeptical.
587.26	If you're too skeptical, you'll miss the really interesting good ideas.
591.26	Just right, you're creative, and yet you don't fall for too much baloney.
594.26	Too high and maybe you see patterns everywhere.
597.26	Every time somebody looks at you, you think people are staring at you.
600.26	You think people are talking about you.
602.26	And if you go too far on that, that's just simply
604.26	labeled as madness.
606.26	It's a distinction perhaps we might make
608.26	between two Nobel laureates, Richard Feynman
610.26	and John Nash.
612.26	One sees maybe just the right number
614.26	of patterns to win a Nobel Prize.
616.26	The other one also, but maybe too many patterns.
618.26	And we then call that schizophrenia.
621.26	So the signal-to-noise ratio then presents us with a pattern-detection problem.
624.26	And of course you all know exactly
626.26	what this is, right?
628.26	And what pattern do you see here?
630.26	Again, I'm putting your anterior cingulate cortex to the test here,
633.26	causing you conflicting pattern detections.
636.26	You know, of course, this is Via Uno shoes.
638.26	These are sandals.
641.26	Pretty sexy feet, I must say.
644.26	Maybe a little Photoshopped.
646.26	And of course, the ambiguous figures
648.26	that seem to flip-flop back and forth.
650.26	It turns out what you're thinking about a lot
652.26	influences what you
654.26	tend to see.
656.26	And you see the lamp here, I know.
658.26	Because the lights on here.
661.26	Of course, thanks to the environmentalist movement
663.26	we're all sensitive to the plight of marine mammals.
666.26	So what you see in this particular ambiguous figure
669.26	is, of course, the dolphins, right?
671.26	You see a dolphin here,
673.26	and there's a dolphin,
675.26	and there's a dolphin.
677.26	That's a dolphin tail there, guys.
680.26	(Laughter)
685.26	If we can give you conflicting data, again,
688.26	your ACC is going to be going into hyperdrive.
691.26	If you look down here, it's fine. If you look up here, then you get conflicting data.
694.26	And then we have to flip the image
696.26	for you to see that it's a set up.
700.26	The impossible crate illusion.
702.26	It's easy to fool the brain in 2D.
704.26	"So you say, ""Aw, come on Shermer, anybody can do that"
706.26	"in a Psych 101 text with an illusion like that."""
708.26	Well here's the late, great Jerry Andrus'
710.26	"""impossible crate"" illusion in 3D,"
713.26	in which Jerry is standing inside
715.26	the impossible crate.
717.26	And he was kind enough to post this
719.26	and give us the reveal.
721.26	Of course, camera angle is everything. The photographer is over there,
724.26	and this board appears to overlap with this one, and this one with that one, and so on.
727.26	But even when I take it away,
729.26	the illusion is so powerful because of how are brains are wired
731.26	to find those certain kinds of patterns.
734.26	This is a fairly new one
736.26	that throws us off because of the conflicting patterns
738.26	of comparing this angle with that angle.
741.26	In fact, it's the exact same picture side by side.
744.26	So what you're doing is comparing that angle
746.26	instead of with this one, but with that one.
748.26	And so your brain is fooled.
750.26	Yet again, your pattern detection devices are fooled.
752.26	Faces are easy to see
754.26	because we have an additional evolved
756.26	facial recognition software
758.26	in our temporal lobes.
761.26	Here's some faces on the side of a rock.
764.26	I'm actually not even sure if this is -- this might be Photoshopped.
767.26	But anyway, the point is still made.
769.26	Now which one of these looks odd to you?
771.26	In a quick reaction, which one looks odd?
773.26	The one on the left. Okay. So I'll rotate it
775.26	so it'll be the one on the right.
777.26	And you are correct.
779.26	A fairly famous illusion -- it was first done with Margaret Thatcher.
782.26	Now, they trade up the politicians every time.
784.26	Well, why is this happening?
786.26	Well, we know exactly where it happens,
788.26	in the temporal lobe, right across, sort of above your ear there,
791.26	in a little structure called the fusiform gyrus.
794.26	And there's two types of cells that do this,
796.26	that record facial features either globally,
799.26	or specifically these large, rapid-firing cells,
801.26	first look at the general face.
803.26	So you recognize Obama immediately.
805.26	And then you notice something quite
807.26	a little bit odd about the eyes and the mouth.
809.26	Especially when they're upside down,
811.26	you're engaging that general facial recognition software there.
814.26	Now I said back in our little thought experiment,
817.26	you're a hominid walking on the plains of Africa.
819.26	Is it just the wind or a dangerous predator?
822.26	What's the difference between those?
824.26	Well, the wind is inanimate;
826.26	the dangerous predator is an intentional agent.
828.26	And I call this process agenticity.
830.26	That is the tendency to infuse patterns
832.26	with meaning, intention and agency,
834.26	often invisible beings from the top down.
837.26	This is an idea that we got
839.26	from a fellow TEDster here, Dan Dennett,
841.26	who talked about taking the intentional stance.
843.26	So it's a type of that expanded to explain, I think, a lot of different things:
846.26	souls, spirits, ghosts, gods, demons, angels,
849.26	aliens, intelligent designers,
851.26	government conspiracists
853.26	and all manner of invisible agents
855.26	with power and intention, are believed
857.26	to haunt our world and control our lives.
859.26	I think it's the basis of animism
861.26	and polytheism and monotheism.
864.26	It's the belief that aliens are somehow
866.26	more advanced than us, more moral than us,
868.26	and the narratives always are
870.26	that they're coming here to save us and rescue us from on high.
873.26	The intelligent designer's always portrayed
875.26	as this super intelligent, moral being
878.26	that comes down to design life.
880.26	Even the idea that government can rescue us --
882.26	that's no longer the wave of the future,
884.26	but that is, I think, a type of agenticity:
886.26	projecting somebody up there,
888.26	big and powerful, will come rescue us.
890.26	And this is also, I think, the basis of conspiracy theories.
892.26	There's somebody hiding behind there pulling the strings,
895.26	whether it's the Illuminati
897.26	or the Bilderbergers.
899.26	But this is a pattern detection problem, isn't it?
901.26	Some patterns are real and some are not.
903.26	Was JFK assassinated by a conspiracy or by a lone assassin?
906.26	Well, if you go there -- there's people there on any given day --
909.26	like when I went there, here -- showing me where the different shooters were.
912.26	My favorite one was he was in the manhole.
915.26	And he popped out at the last second, took that shot.
918.26	But of course, Lincoln was assassinated by a conspiracy.
920.26	So we can't just uniformly dismiss
922.26	all patterns like that.
924.26	Because, let's face it, some patterns are real.
926.26	Some conspiracies really are true.
930.26	Explains a lot, maybe.
932.26	And 9/11 has a conspiracy theory. It is a conspiracy.
935.26	We did a whole issue on it.
937.26	Nineteen members of Al Queda plotting to fly planes into buildings
939.26	constitutes a conspiracy.
941.26	"But that's not what the ""9/11 truthers"" think."
943.26	They think it was an inside job by the Bush administration.
946.26	Well, that's a whole other lecture.
948.26	You know how we know that 9/11
950.26	was not orchestrated by the Bush administration?
952.26	Because it worked.
954.26	(Laughter)
957.26	(Applause)
960.26	So we are natural-born dualists.
962.26	Our agenticity process comes from
964.26	the fact that we can enjoy movies like these.
966.26	Because we can imagine, in essence,
968.26	continuing on.
970.26	We know that if you stimulate the temporal lobe,
972.26	you can produce a feeling of out-of-body experiences,
974.26	near-death experiences,
976.26	which you can do by just touching an electrode to the temporal lobe there.
979.26	Or you can do it through loss of consciousness,
981.26	by accelerating in a centrifuge.
983.26	You get a hypoxia, or a lower oxygen.
986.26	And the brain then senses
988.26	that there's an out-of-body experience.
990.26	You can use -- which I did, went out and did --
992.26	Michael Persinger's God Helmet,
994.26	that bombards your temporal lobes with electromagnetic waves.
996.26	And you get a sense of out-of-body experience.
999.26	So I'm going to end here with a short video clip
1001.26	that sort of brings all this together.
1003.26	It's just a minute and a half.
1005.26	It ties together all this into the power of expectation and the power of belief.
1008.26	Go ahead and roll it.
1010.26	Narrator: This is the venue they chose for their fake auditions
1013.26	for an advert for lip balm.
1015.26	Woman: We're hoping we can use part of this
1017.26	in a national commercial, right?
1019.26	And this is test on some lip balms
1021.26	that we have over here.
1023.26	And these are our models who are going to help us,
1025.26	Roger and Matt.
1027.26	And we have our own lip balm,
1029.26	and we have a leading brand.
1031.26	Would you have any problem
1033.26	kissing our models to test it?
1035.26	Girl: No.
1037.26	Woman: You wouldn't? (Girl: No.) Woman: You'd think that was fine.
1039.26	Girl: That would be fine. (Woman: Okay.)
1041.26	So this is a blind test.
1044.26	I'm going to ask you to go ahead
1046.26	and put a blindfold on.
1049.26	Kay, now can you see anything? (Girl: No.)
1052.26	Pull it so you can't even see down. (Girl: Okay.)
1054.26	Woman: It's completely blind now, right?
1056.26	Girl: Yes. (Woman: Okay.)
1058.26	Now, what I'm going to be looking for in this test
1061.26	is how it protects your lips,
1064.26	the texture, right,
1066.26	and maybe if you can discern any flavor or not.
1069.26	Girl: Okay. (Woman: Have you ever done a kissing test before?)
1072.26	Girl: No.
1074.26	Woman: Take a step here.
1076.26	Okay, now I'm going to ask you to pucker up.
1078.26	Pucker up big and lean in just a little bit, okay?
1086.26	(Music)
1090.26	(Laughter)
1099.26	(Laughter)
1110.26	Woman: Okay.
1112.26	And, Jennifer, how did that feel?
1114.26	Jennifer: Good.
1116.26	(Laughter)
1123.26	Girl: Oh my God!
1125.26	(Laughter)
1130.26	Michael Shermer: Thank you very much. Thank you. Thanks.
