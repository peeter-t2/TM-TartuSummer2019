startsecond	text
15.26	I didn't always love unintended consequences,
18.26	but I've really learned to appreciate them.
20.26	I've learned that they're really the essence
22.26	of what makes for progress,
24.26	even when they seem to be terrible.
27.26	And I'd like to review
29.26	just how unintended consequences
32.26	play the part that they do.
35.26	Let's go to 40,000 years before the present,
40.26	to the time of the cultural explosion,
44.26	when music, art, technology,
49.26	so many of the things that we're enjoying today,
51.26	so many of the things that are being demonstrated at TED
54.26	were born.
56.26	And the anthropologist Randall White
59.26	has made a very interesting observation:
62.26	that if our ancestors
66.26	had been able to see
69.26	what they had done,
71.26	they wouldn't have really understood it.
73.26	They were responding
75.26	to immediate concerns.
78.26	They were making it possible for us
80.26	to do what they do,
82.26	and yet, they didn't really understand
84.26	how they did it.
86.26	Now let's advance to 10,000 years before the present.
91.26	And this is when it really gets interesting.
93.26	What about the domestication of grains?
96.26	What about the origins of agriculture?
99.26	What would our ancestors 10,000 years ago
102.26	have said
104.26	if they really had technology assessment?
106.26	And I could just imagine the committees
108.26	reporting back to them
110.26	on where agriculture was going to take humanity,
113.26	at least in the next few hundred years.
116.26	It was really bad news.
118.26	First of all, worse nutrition,
120.26	maybe shorter life spans.
122.26	It was simply awful for women.
124.26	The skeletal remains from that period
126.26	have shown that they were grinding grain morning, noon and night.
131.26	And politically, it was awful.
134.26	It was the beginning of a much higher degree
137.26	of inequality among people.
140.26	If there had been rational technology assessment then,
143.26	I think they very well might have said,
145.26	"""Let's call the whole thing off."""
148.26	Even now, our choices are having unintended effects.
152.26	Historically, for example,
154.26	chopsticks -- according to one Japanese anthropologist
157.26	who wrote a dissertation about it
159.26	at the University of Michigan --
161.26	resulted in long-term changes
164.26	in the dentition, in the teeth,
166.26	of the Japanese public.
168.26	And we are also changing our teeth right now.
171.26	There is evidence
173.26	that the human mouth and teeth
175.26	are growing smaller all the time.
177.26	That's not necessarily a bad unintended consequence.
180.26	But I think from the point of view of a Neanderthal,
182.26	there would have been a lot of disapproval
184.26	of the wimpish choppers that we now have.
187.26	So these things are kind of relative
190.26	to where you or your ancestors happen to stand.
194.26	In the ancient world
196.26	there was a lot of respect for unintended consequences,
199.26	and there was a very healthy sense of caution,
202.26	reflected in the Tree of Knowledge,
204.26	in Pandora's Box,
206.26	and especially in the myth of Prometheus
208.26	that's been so important
210.26	in recent metaphors about technology.
212.26	And that's all very true.
215.26	The physicians of the ancient world --
217.26	especially the Egyptians,
219.26	who started medicine as we know it --
221.26	were very conscious
223.26	of what they could and couldn't treat.
225.26	And the translations of the surviving texts say,
230.26	"""This I will not treat. This I cannot treat."""
232.26	They were very conscious.
234.26	So were the followers of Hippocrates.
236.26	The Hippocratic manuscripts also --
238.26	repeatedly, according to recent studies --
241.26	show how important it is not to do harm.
244.26	More recently,
246.26	Harvey Cushing,
248.26	who really developed neurosurgery as we know it,
250.26	who changed it from a field of medicine
253.26	that had a majority of deaths resulting from surgery
257.26	to one in which there was a hopeful outlook,
260.26	he was very conscious
262.26	that he was not always going to do the right thing.
265.26	But he did his best,
267.26	and he kept meticulous records
269.26	that let him transform that branch of medicine.
272.26	Now if we look forward a bit
275.26	to the 19th century,
277.26	we find a new style of technology.
279.26	What we find is,
281.26	no longer simple tools,
284.26	but systems.
286.26	We find more and more
288.26	complex arrangements of machines
290.26	that make it harder and harder
292.26	to diagnose what's going on.
294.26	And the first people who saw that
296.26	were the telegraphers of the mid-19th century,
299.26	who were the original hackers.
301.26	Thomas Edison would have been very, very comfortable
304.26	in the atmosphere of a software firm today.
307.26	And these hackers had a word
310.26	for those mysterious bugs in telegraph systems
313.26	that they called bugs.
315.26	"That was the origin of the word ""bug."""
319.26	This consciousness, though,
321.26	was a little slow to seep through the general population,
324.26	even people who were very, very well informed.
327.26	Samuel Clemens, Mark Twain,
329.26	was a big investor
331.26	in the most complex machine of all times --
334.26	at least until 1918 --
336.26	registered with the U.S. Patent Office.
338.26	That was the Paige typesetter.
340.26	The Paige typesetter
342.26	had 18,000 parts.
344.26	The patent had 64 pages of text
347.26	and 271 figures.
351.26	It was such a beautiful machine
353.26	because it did everything that a human being did
356.26	in setting type --
358.26	including returning the type to its place,
360.26	which was a very difficult thing.
362.26	And Mark Twain, who knew all about typesetting,
364.26	really was smitten by this machine.
367.26	Unfortunately, he was smitten in more ways than one,
370.26	because it made him bankrupt,
372.26	and he had to tour the world speaking
374.26	to recoup his money.
377.26	And this was an important thing
379.26	about 19th century technology,
381.26	that all these relationships among parts
383.26	could make the most brilliant idea fall apart,
387.26	even when judged by the most expert people.
389.26	Now there is something else, though, in the early 20th century
392.26	that made things even more complicated.
395.26	And that was that safety technology itself
398.26	could be a source of danger.
400.26	The lesson of the Titanic, for a lot of the contemporaries,
403.26	was that you must have enough lifeboats
405.26	for everyone on the ship.
407.26	And this was the result
410.26	of the tragic loss of lives
412.26	of people who could not get into them.
414.26	However, there was another case, the Eastland,
417.26	a ship that capsized in Chicago Harbor in 1915,
421.26	and it killed 841 people --
424.26	that was 14 more
426.26	than the passenger toll of the Titanic.
429.26	The reason for it, in part, was
431.26	the extra life boats that were added
434.26	that made this already unstable ship
437.26	even more unstable.
439.26	And that again proves
441.26	that when you're talking about unintended consequences,
444.26	it's not that easy to know
446.26	the right lessons to draw.
448.26	It's really a question of the system, how the ship was loaded,
451.26	the ballast and many other things.
455.26	So the 20th century, then,
458.26	saw how much more complex reality was,
460.26	but it also saw a positive side.
463.26	It saw that invention
466.26	could actually benefit from emergencies.
468.26	It could benefit
470.26	from tragedies.
473.26	And my favorite example of that --
475.26	which is not really widely known
477.26	as a technological miracle,
479.26	but it may be one of the greatest of all times,
482.26	was the scaling up of penicillin in the Second World War.
486.26	Penicillin was discovered in 1928,
489.26	but even by 1940,
491.26	no commercially and medically useful quantities of it
494.26	were being produced.
496.26	A number of pharmaceutical companies were working on it.
499.26	They were working on it independently,
501.26	and they weren't getting anywhere.
503.26	And the Government Research Bureau
505.26	brought representatives together
507.26	and told them that this is something
509.26	that has to be done.
511.26	And not only did they do it,
513.26	but within two years,
515.26	they scaled up penicillin
517.26	from preparation in one-liter flasks
520.26	to 10,000-gallon vats.
524.26	That was how quickly penicillin was produced
528.26	and became one of the greatest medical advances of all time.
532.26	In the Second World War, too,
534.26	the existence
536.26	of solar radiation
538.26	was demonstrated by studies of interference
541.26	that was detected by the radar stations of Great Britain.
545.26	So there were benefits in calamities --
548.26	benefits to pure science,
550.26	as well as to applied science
552.26	and medicine.
555.26	Now when we come to the period after the Second World War,
558.26	unintended consequences get even more interesting.
562.26	And my favorite example of that
564.26	occurred beginning in 1976,
567.26	when it was discovered
569.26	that the bacteria causing Legionnaires disease
572.26	had always been present in natural waters,
575.26	but it was the precise temperature of the water
579.26	in heating, ventilating and air conditioning systems
582.26	that raised the right temperature
586.26	for the maximum reproduction
589.26	of Legionella bacillus.
591.26	Well, technology to the rescue.
593.26	So chemists got to work,
595.26	and they developed a bactericide
597.26	that became widely used in those systems.
600.26	But something else happened in the early 1980s,
604.26	and that was that there was a mysterious epidemic
606.26	of failures of tape drives
609.26	all over the United States.
611.26	And IBM, which made them,
614.26	just didn't know what to do.
617.26	They commissioned a group of their best scientists
620.26	to investigate,
622.26	and what they found was
624.26	that all these tape drives
626.26	were located near ventilation ducts.
629.26	What happened was the bactericide was formulated
632.26	with minute traces of tin.
634.26	And these tin particles were deposited on the tape heads
637.26	and were crashing the tape heads.
640.26	So they reformulated the bactericide.
643.26	But what's interesting to me
645.26	is that this was the first case
647.26	of a mechanical device
649.26	suffering, at least indirectly, from a human disease.
652.26	So it shows that we're really all in this together.
655.26	(Laughter)
657.26	In fact, it also shows something interesting,
660.26	that although our capabilities and technology
663.26	have been expanding geometrically,
665.26	unfortunately, our ability to model their long-term behavior,
668.26	which has also been increasing,
670.26	has been increasing only arithmetically.
673.26	So one of the characteristic problems of our time
676.26	is how to close this gap
678.26	between capabilities and foresight.
681.26	One other very positive consequence
684.26	of 20th century technology, though,
687.26	was the way in which other kinds of calamities
691.26	could lead to positive advances.
694.26	There are two historians of business
697.26	at the University of Maryland,
699.26	Brent Goldfarb and David Kirsch,
701.26	who have done some extremely interesting work,
703.26	much of it still unpublished,
706.26	on the history of major innovations.
708.26	They have combined the list of major innovations,
711.26	and they've discovered that the greatest number, the greatest decade,
714.26	for fundamental innovations,
716.26	as reflected in all of the lists that others have made --
720.26	a number of lists that they have merged --
722.26	was the Great Depression.
725.26	And nobody knows just why this was so,
728.26	but one story can reflect something of it.
731.26	It was the origin of the Xerox copier,
734.26	which celebrated its 50th anniversary
737.26	last year.
739.26	And Chester Carlson, the inventor,
744.26	was a patent attorney.
747.26	He really was not intending
750.26	to work in patent research,
752.26	but he couldn't really find an alternative technical job.
756.26	So this was the best job he could get.
758.26	He was upset by the low quality and high cost
762.26	of existing patent reproductions,
765.26	and so he started to develop
768.26	a system of dry photocopying,
771.26	which he patented in the late 1930s --
774.26	and which became the first dry photocopier
778.26	that was commercially practical
780.26	in 1960.
782.26	So we see that sometimes,
784.26	as a result of these dislocations,
786.26	as a result of people
788.26	leaving their original intended career
791.26	and going into something else
793.26	where their creativity could make a difference,
795.26	that depressions
797.26	and all kinds of other unfortunate events
800.26	can have a paradoxically stimulating effect
803.26	on creativity.
805.26	What does this mean?
807.26	It means, I think,
809.26	that we're living in a time of unexpected possibilities.
811.26	Think of the financial world, for example.
814.26	The mentor of Warren Buffett, Benjamin Graham,
817.26	developed his system of value investing
822.26	as a result of his own losses
824.26	in the 1929 crash.
826.26	And he published that book
828.26	in the early 1930s,
831.26	and the book still exists in further editions
833.26	and is still a fundamental textbook.
835.26	So many important creative things can happen
839.26	when people learn from disasters.
842.26	Now think of the large and small plagues that we have now --
846.26	bed bugs, killer bees, spam --
851.26	and it's very possible that the solutions to those
854.26	will really extend well beyond the immediate question.
857.26	If we think, for example, of Louis Pasteur,
860.26	who in the 1860s
862.26	was asked to study
864.26	the diseases of silk worms for the silk industry,
868.26	and his discoveries were really the beginning
871.26	of the germ theory of disease.
873.26	So very often, some kind of disaster --
876.26	sometimes the consequence, for example,
879.26	of over-cultivation of silk worms,
882.26	which was a problem in Europe at the time --
884.26	can be the key to something much bigger.
886.26	So this means
888.26	that we need to take a different view
890.26	of unintended consequences.
892.26	We need to take a really positive view.
895.26	We need to see what they can do for us.
898.26	We need to learn
900.26	from those figures that I mentioned.
902.26	We need to learn, for example, from Dr. Cushing,
905.26	who killed patients
907.26	in the course of his early operations.
909.26	He had to have some errors. He had to have some mistakes.
912.26	And he learned meticulously from his mistakes.
915.26	And as a result,
917.26	"when we say, ""This isn't brain surgery,"""
920.26	that pays tribute to how difficult it was
923.26	for anyone to learn from their mistakes
925.26	in a field of medicine
927.26	that was considered so discouraging in its prospects.
930.26	And we can also remember
933.26	how the pharmaceutical companies
935.26	were willing to pool their knowledge,
937.26	to share their knowledge,
939.26	in the face of an emergency,
941.26	which they hadn't really been for years and years.
944.26	They might have been able to do it earlier.
947.26	The message, then, for me,
950.26	about unintended consequences
952.26	is chaos happens;
955.26	let's make better use of it.
957.26	Thank you very much.
959.26	(Applause)
